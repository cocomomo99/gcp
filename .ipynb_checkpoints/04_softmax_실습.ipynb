{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실습 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "      0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n0    1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  0.0   \n1    1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0   \n2    0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0   \n3    1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  0.0   \n4    1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0   \n..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n96   1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  2.0  1.0   \n97   1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  6.0  0.0   \n98   1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0   \n99   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n100  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  2.0  1.0   \n\n      14   15   16  \n0    0.0  1.0  0.0  \n1    0.0  1.0  0.0  \n2    0.0  0.0  3.0  \n3    0.0  1.0  0.0  \n4    0.0  1.0  0.0  \n..   ...  ...  ...  \n96   0.0  1.0  0.0  \n97   0.0  0.0  5.0  \n98   0.0  1.0  0.0  \n99   0.0  0.0  6.0  \n100  0.0  0.0  1.0  \n\n[101 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/HOME/PycharmProjects/ai/.ipynb_checkpoints/data_set/data-04-zoo.csv', skiprows=19, header= None, dtype= float)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "(     0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n 0   1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  0.0  0.0   \n 1   1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0  0.0   \n 2   0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0   \n 3   1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  0.0  0.0   \n 4   1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0  0.0   \n ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n 66  0.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0   \n 67  1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0  0.0   \n 68  1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0  1.0   \n 69  1.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0  0.0   \n 70  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  4.0  1.0  1.0   \n \n      15  \n 0   1.0  \n 1   1.0  \n 2   0.0  \n 3   1.0  \n 4   1.0  \n ..  ...  \n 66  1.0  \n 67  1.0  \n 68  1.0  \n 69  1.0  \n 70  1.0  \n \n [71 rows x 16 columns],\n     0.0  1.0  2.0  3.0  4.0  5.0  6.0\n 0     1    0    0    0    0    0    0\n 1     1    0    0    0    0    0    0\n 2     0    0    0    1    0    0    0\n 3     1    0    0    0    0    0    0\n 4     1    0    0    0    0    0    0\n ..  ...  ...  ...  ...  ...  ...  ...\n 66    1    0    0    0    0    0    0\n 67    1    0    0    0    0    0    0\n 68    1    0    0    0    0    0    0\n 69    1    0    0    0    0    0    0\n 70    1    0    0    0    0    0    0\n \n [71 rows x 7 columns])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = df.iloc[:71, :-1]\n",
    "train_y = df.iloc[:71, -1]\n",
    "train_y = pd.get_dummies(train_y)\n",
    "# train_y = tf.one_hot(train_y, 7) or use tf.one_hot\n",
    "# train_y = tf.reshape(train_y, [-1, 7])\n",
    "\n",
    "test_x = df.iloc[71:, :-1]\n",
    "test_y = df.iloc[71:, -1]\n",
    "test_y = pd.get_dummies(test_y)\n",
    "\n",
    "train_x, train_y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Variable 'weight:0' shape=(16, 7) dtype=float64, numpy=\n array([[-1.53041681e+00, -2.49398221e+00,  2.30843875e-03,\n         -1.56194314e-01,  1.72655660e-01, -3.83629687e-01,\n          1.15179948e+00],\n        [-1.90277942e+00,  1.51582538e+00,  9.55277315e-02,\n         -7.75336229e-01,  1.28274352e+00,  1.17108276e+00,\n         -1.56122821e+00],\n        [ 2.31856205e+00, -7.23131442e-01, -6.90928948e-01,\n          8.75636167e-01,  5.54551723e-02,  1.53635934e-01,\n         -1.73715502e+00],\n        [ 7.79058041e-01,  2.04551547e+00, -7.33865109e-01,\n          8.27377770e-01, -3.32300229e-01, -7.79485729e-01,\n         -1.52697224e+00],\n        [ 1.14062314e+00, -9.11771800e-01,  1.27721261e+00,\n         -1.18053281e+00,  3.64621084e-01, -5.38354628e-01,\n         -5.19371142e-01],\n        [ 6.05109617e-01, -2.56479241e-01,  4.20803825e-01,\n         -1.26748386e+00, -1.27438262e+00,  1.22992008e-01,\n         -3.22140514e-01],\n        [-3.11671800e-01,  7.91397576e-01, -8.57995758e-01,\n          2.63978382e-01, -1.27917036e+00,  1.03585034e-01,\n          2.97349259e-01],\n        [-1.35557824e+00,  2.30110793e+00,  1.18111633e+00,\n         -6.47920393e-02,  7.30580629e-01,  1.37562730e+00,\n          1.51475587e+00],\n        [ 1.20729683e+00, -9.47953626e-01,  5.26080647e-01,\n         -1.85975818e-01,  6.24344539e-02, -7.60905792e-01,\n         -9.47320831e-01],\n        [ 1.16503251e+00, -2.82524112e-01,  1.65681636e+00,\n          9.51459654e-01, -2.83747877e-01,  7.71418897e-01,\n         -2.81185701e-01],\n        [ 4.59123173e-01, -1.23202117e+00,  8.44723484e-02,\n          1.97371764e+00, -6.34485114e-01, -1.60842441e+00,\n         -5.79829269e-01],\n        [-4.36104517e-01, -5.71432230e-01,  1.15752360e+00,\n          9.46679191e-01,  1.29547794e+00, -5.75879161e-01,\n          8.68925330e-01],\n        [ 5.33587473e-01,  1.82019409e+00, -1.01832747e+00,\n          5.25000637e-01, -3.33669306e-01,  1.04165559e+00,\n         -9.28161535e-02],\n        [-3.87960910e-02, -9.10201458e-01, -1.67083080e+00,\n         -1.67296502e+00,  1.68891469e+00, -1.16800074e+00,\n         -2.77623072e-01],\n        [-6.98533579e-01, -1.31030390e+00,  6.61877571e-01,\n         -1.33330871e+00, -6.15048757e-01,  3.96613034e-01,\n         -9.24275413e-01],\n        [ 6.14253117e-01, -6.20630498e-01,  7.42598983e-01,\n          7.26506337e-01, -5.38299611e-01, -6.60633888e-02,\n          1.88573224e-02]])>,\n <tf.Variable 'bias:0' shape=(7,) dtype=float64, numpy=\n array([ 0.2405818 ,  0.02824563, -2.09153955, -0.40275379, -2.27566445,\n         0.14321251,  0.95169091])>)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.normal([16,7], dtype= tf.float64), name= 'weight')\n",
    "b = tf.Variable(tf.random.normal([7], dtype= tf.float64), name = 'bias')\n",
    "\n",
    "w, b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return tf.matmul(x, w) + b\n",
    "\n",
    "\n",
    "def cost(x):\n",
    "    return tf.nn.softmax(logit(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(71, 7), dtype=float64, numpy=\narray([[5.45660040e-03, 9.49440779e-01, 7.49237909e-06, 1.66686441e-02,\n        1.79227703e-06, 2.77796046e-02, 6.45087107e-04],\n       [3.75450741e-02, 9.06974778e-01, 1.74073383e-05, 1.25840039e-02,\n        1.82620908e-04, 4.07948909e-02, 1.90122472e-03],\n       [7.30175332e-01, 5.88762735e-02, 1.03616800e-02, 1.73954427e-02,\n        2.90068062e-02, 4.28691365e-02, 1.11315329e-01],\n       [5.45660040e-03, 9.49440779e-01, 7.49237909e-06, 1.66686441e-02,\n        1.79227703e-06, 2.77796046e-02, 6.45087107e-04],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [3.75450741e-02, 9.06974778e-01, 1.74073383e-05, 1.25840039e-02,\n        1.82620908e-04, 4.07948909e-02, 1.90122472e-03],\n       [5.68956283e-02, 7.45474283e-01, 1.02819943e-04, 1.01080048e-02,\n        3.00838510e-04, 1.84819521e-01, 2.29890461e-03],\n       [7.07813191e-01, 1.02727422e-02, 6.76092635e-02, 5.02627156e-03,\n        8.04317824e-02, 8.20178933e-02, 4.68288563e-02],\n       [7.30175332e-01, 5.88762735e-02, 1.03616800e-02, 1.73954427e-02,\n        2.90068062e-02, 4.28691365e-02, 1.11315329e-01],\n       [7.72619431e-03, 8.31896077e-01, 6.28069716e-05, 6.28798885e-03,\n        2.29843480e-05, 1.53284986e-01, 7.18962151e-04],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [8.86937614e-01, 1.08828191e-02, 1.01630465e-03, 6.80339859e-04,\n        6.69246116e-03, 9.37494330e-02, 4.10285004e-05],\n       [7.30175332e-01, 5.88762735e-02, 1.03616800e-02, 1.73954427e-02,\n        2.90068062e-02, 4.28691365e-02, 1.11315329e-01],\n       [6.38703268e-01, 7.43274022e-02, 1.77092794e-03, 1.41009701e-01,\n        2.03926264e-03, 1.00725743e-01, 4.14236957e-02],\n       [9.77938230e-02, 8.26118933e-01, 4.54169337e-07, 3.20691465e-03,\n        1.48474888e-06, 7.26735637e-02, 2.04826885e-04],\n       [8.78616766e-03, 9.72888227e-01, 1.83117429e-09, 2.83215509e-04,\n        2.35424362e-08, 1.80371067e-02, 5.25760245e-06],\n       [8.87143292e-01, 6.04766225e-02, 1.51021951e-04, 2.28300913e-03,\n        2.34018545e-03, 4.75113062e-02, 9.45625688e-05],\n       [3.75450741e-02, 9.06974778e-01, 1.74073383e-05, 1.25840039e-02,\n        1.82620908e-04, 4.07948909e-02, 1.90122472e-03],\n       [8.38521677e-01, 1.96663748e-02, 1.35287357e-02, 2.23497968e-02,\n        1.05205819e-02, 2.49329788e-02, 7.04798552e-02],\n       [5.60784674e-01, 2.29798119e-01, 6.60798769e-02, 5.36341801e-02,\n        5.22784062e-03, 2.06281507e-02, 6.38471583e-02],\n       [8.86937614e-01, 1.08828191e-02, 1.01630465e-03, 6.80339859e-04,\n        6.69246116e-03, 9.37494330e-02, 4.10285004e-05],\n       [9.68111814e-01, 9.25292507e-03, 2.36697851e-04, 2.15367756e-04,\n        1.02590749e-03, 2.11350825e-02, 2.22053134e-05],\n       [3.75450741e-02, 9.06974778e-01, 1.74073383e-05, 1.25840039e-02,\n        1.82620908e-04, 4.07948909e-02, 1.90122472e-03],\n       [9.72134967e-01, 6.39676266e-03, 3.24921351e-04, 1.57394552e-03,\n        2.13115513e-03, 1.74071754e-02, 3.10728050e-05],\n       [4.34262148e-02, 8.88128747e-01, 3.07305020e-08, 4.13591234e-03,\n        4.71019576e-07, 6.43002126e-02, 8.41125452e-06],\n       [9.07823214e-02, 8.09341539e-01, 4.40870166e-06, 2.17027342e-03,\n        8.29746471e-07, 9.76090431e-02, 9.15849130e-05],\n       [3.46228945e-01, 5.68904359e-01, 1.15601645e-05, 3.76406019e-02,\n        1.06013082e-06, 4.70898856e-02, 1.23587547e-04],\n       [4.76140689e-01, 3.87440104e-01, 4.95987854e-03, 1.42443760e-02,\n        1.91230154e-02, 6.89878607e-02, 2.91040757e-02],\n       [3.75450741e-02, 9.06974778e-01, 1.74073383e-05, 1.25840039e-02,\n        1.82620908e-04, 4.07948909e-02, 1.90122472e-03],\n       [6.32585327e-02, 4.55453514e-01, 7.54417842e-03, 1.04202067e-01,\n        1.27981963e-04, 3.48527298e-01, 2.08864278e-02],\n       [2.55613921e-01, 6.71374216e-01, 2.07358688e-07, 2.38967384e-03,\n        1.27602174e-06, 7.06112918e-02, 9.41384289e-06],\n       [5.68956283e-02, 7.45474283e-01, 1.02819943e-04, 1.01080048e-02,\n        3.00838510e-04, 1.84819521e-01, 2.29890461e-03],\n       [1.15578933e-01, 5.09137583e-01, 6.10685969e-03, 2.01982404e-01,\n        5.66018496e-04, 1.40616565e-01, 2.60116370e-02],\n       [9.40864457e-01, 2.70980183e-02, 1.33208021e-04, 3.72206474e-04,\n        3.78905105e-04, 3.11135268e-02, 3.96782889e-05],\n       [7.74672706e-01, 2.07288147e-02, 1.89839575e-02, 1.03782681e-02,\n        8.09786063e-02, 3.00256267e-02, 6.42320209e-02],\n       [1.89715711e-02, 8.54594719e-01, 3.01551751e-05, 3.01258206e-03,\n        3.17618008e-04, 1.21683010e-01, 1.39034461e-03],\n       [1.15468447e-02, 9.58978141e-01, 4.70871956e-06, 3.45922051e-03,\n        1.77831277e-04, 2.47727283e-02, 1.06052502e-03],\n       [8.87143292e-01, 6.04766225e-02, 1.51021951e-04, 2.28300913e-03,\n        2.34018545e-03, 4.75113062e-02, 9.45625688e-05],\n       [7.30175332e-01, 5.88762735e-02, 1.03616800e-02, 1.73954427e-02,\n        2.90068062e-02, 4.28691365e-02, 1.11315329e-01],\n       [6.58641507e-01, 6.59804059e-02, 6.63057540e-06, 5.86571765e-02,\n        6.57455855e-06, 2.16607601e-01, 1.00104483e-04],\n       [3.43732614e-01, 3.44452834e-01, 1.29125672e-06, 1.26996606e-02,\n        9.42170038e-06, 2.98919134e-01, 1.85043962e-04],\n       [5.40386792e-01, 2.86841693e-01, 8.02474009e-05, 1.41671934e-02,\n        3.09723842e-03, 1.55123895e-01, 3.02939964e-04],\n       [1.06953208e-01, 8.46507701e-01, 5.02419016e-08, 1.77807321e-03,\n        2.02902828e-07, 4.47535222e-02, 7.24220382e-06],\n       [9.37454605e-01, 2.12073820e-02, 2.75589096e-04, 1.35663315e-03,\n        6.50707834e-03, 3.31443642e-02, 5.43477101e-05],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [8.78616766e-03, 9.72888227e-01, 1.83117429e-09, 2.83215509e-04,\n        2.35424362e-08, 1.80371067e-02, 5.25760245e-06],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [3.03948937e-02, 9.34795321e-01, 6.78690177e-06, 2.78491016e-03,\n        8.57759957e-06, 3.08898767e-02, 1.11963376e-03],\n       [3.91813056e-03, 9.80575936e-01, 9.25236858e-07, 2.08735119e-03,\n        2.29321323e-05, 1.27330713e-02, 6.61654062e-04],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [3.43732614e-01, 3.44452834e-01, 1.29125672e-06, 1.26996606e-02,\n        9.42170038e-06, 2.98919134e-01, 1.85043962e-04],\n       [1.96737772e-01, 7.33789941e-01, 1.86815758e-06, 9.17678104e-04,\n        1.01196883e-05, 6.83863105e-02, 1.56310864e-04],\n       [2.34696143e-03, 9.90828717e-01, 2.49574300e-11, 8.31986004e-05,\n        3.50526544e-10, 6.74090165e-03, 2.21222769e-07],\n       [3.91813056e-03, 9.80575936e-01, 9.25236858e-07, 2.08735119e-03,\n        2.29321323e-05, 1.27330713e-02, 6.61654062e-04],\n       [3.75450741e-02, 9.06974778e-01, 1.74073383e-05, 1.25840039e-02,\n        1.82620908e-04, 4.07948909e-02, 1.90122472e-03],\n       [8.55482167e-01, 4.38317116e-02, 2.49426499e-04, 1.41103997e-02,\n        4.07486167e-03, 8.21076232e-02, 1.43810704e-04],\n       [8.86937614e-01, 1.08828191e-02, 1.01630465e-03, 6.80339859e-04,\n        6.69246116e-03, 9.37494330e-02, 4.10285004e-05],\n       [8.62032269e-01, 5.62308501e-02, 1.21044953e-04, 3.88683908e-03,\n        2.38228128e-04, 7.73853548e-02, 1.05414085e-04],\n       [9.37454605e-01, 2.12073820e-02, 2.75589096e-04, 1.35663315e-03,\n        6.50707834e-03, 3.31443642e-02, 5.43477101e-05],\n       [8.38521677e-01, 1.96663748e-02, 1.35287357e-02, 2.23497968e-02,\n        1.05205819e-02, 2.49329788e-02, 7.04798552e-02],\n       [7.30175332e-01, 5.88762735e-02, 1.03616800e-02, 1.73954427e-02,\n        2.90068062e-02, 4.28691365e-02, 1.11315329e-01],\n       [8.49014046e-01, 8.04012659e-03, 3.30923199e-03, 1.21247109e-01,\n        3.07665402e-03, 7.92224189e-03, 7.39059060e-03],\n       [9.51013759e-01, 3.60606355e-02, 8.28666815e-07, 5.66188819e-03,\n        3.46648899e-06, 7.22502553e-03, 3.43966660e-05],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [5.68956283e-02, 7.45474283e-01, 1.02819943e-04, 1.01080048e-02,\n        3.00838510e-04, 1.84819521e-01, 2.29890461e-03],\n       [5.60784674e-01, 2.29798119e-01, 6.60798769e-02, 5.36341801e-02,\n        5.22784062e-03, 2.06281507e-02, 6.38471583e-02],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [2.18355554e-02, 8.62134359e-01, 2.28505796e-05, 6.89846528e-03,\n        4.38772587e-05, 1.07442706e-01, 1.62218649e-03],\n       [1.31351278e-02, 9.56166429e-01, 3.52653523e-06, 7.82892043e-03,\n        2.42802162e-05, 2.16187643e-02, 1.22295162e-03],\n       [5.68956283e-02, 7.45474283e-01, 1.02819943e-04, 1.01080048e-02,\n        3.00838510e-04, 1.84819521e-01, 2.29890461e-03]])>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(train_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def cost():\n",
    "   return tf.nn.softmax_cross_entropy_with_logits(logits= logit(train_x), labels = train_y, axis= 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 \n",
      " cost :\n",
      " 3.8373191121699803 ] \n",
      "  W :\n",
      " [[-1.48041682 -2.5439822  -0.04768338 -0.20619407  0.12266254 -0.43362765\n",
      "   1.10180084]\n",
      " [-1.95277941  1.56582536  0.04555904 -0.82533261  1.23274677  1.12108295\n",
      "  -1.61108033]\n",
      " [ 2.26856205 -0.6731315  -0.64092914  0.92563615  0.10545511  0.20363589\n",
      "  -1.68715505]\n",
      " [ 0.82905804  1.99551547 -0.78386407  0.777378   -0.3822955  -0.82948566\n",
      "  -1.57697159]\n",
      " [ 1.09062315 -0.86177182  1.22722913 -1.23053143  0.3146237  -0.48835467\n",
      "  -0.56936589]\n",
      " [ 0.55510963 -0.30647921  0.37080435 -1.21748388 -1.22438268  0.07299218\n",
      "  -0.27214056]\n",
      " [-0.26167183  0.74139758 -0.80799596  0.31397836 -1.22917042  0.05358521\n",
      "   0.34734922]\n",
      " [-1.30557825  2.25110794  1.2311161  -0.01479206  0.78058057  1.32562735\n",
      "   1.46475602]\n",
      " [ 1.25729681 -0.99795362  0.57608041 -0.13597584  0.11243439 -0.81090575\n",
      "  -0.99732068]\n",
      " [ 1.2150325  -0.3325241   1.70681618  0.90145982 -0.23374793  0.8214188\n",
      "  -0.33118508]\n",
      " [ 0.40912326 -1.28202093  0.13447219  1.92371836 -0.58448527 -1.55842463\n",
      "  -0.62980851]\n",
      " [-0.48610449 -0.62143204  1.10752413  0.99667917  1.24547841 -0.62587878\n",
      "   0.8189255 ]\n",
      " [ 0.58358747  1.77019409 -1.06832432  0.4750007  -0.28366932  1.09165558\n",
      "  -0.04281616]\n",
      " [ 0.01120389 -0.96020145 -1.62083103 -1.62296504  1.73891442 -1.21800068\n",
      "  -0.32762292]\n",
      " [-0.64853362 -1.36030385  0.61187958 -1.28330891 -0.66504721  0.34661318\n",
      "  -0.97427346]\n",
      " [ 0.66425311 -0.67063049  0.69259989  0.77650622 -0.58829577 -0.11606332\n",
      "   0.06885708]] \n",
      "  b :\n",
      " [ 0.29058179 -0.02175437 -2.04153978 -0.35275381 -2.22566451  0.19321236\n",
      "  1.00169087]\n",
      "0500 \n",
      " cost :\n",
      " 0.0017756768489753058 ] \n",
      "  W :\n",
      " [[ 0.01716034 -3.83016236 -1.59720098 -1.57781374 -3.657218   -1.52818114\n",
      "  -1.03005302]\n",
      " [-3.85217019  3.75070926 -2.24134113 -2.85561616 -1.51789709 -1.51899822\n",
      "  -5.04220503]\n",
      " [ 0.43200832  1.29911463  0.7098835   2.28659777  0.37361072  0.95350911\n",
      "   0.73119309]\n",
      " [ 2.67746545  0.68800564 -3.52074609 -2.70672589 -4.12096225 -2.22959539\n",
      "  -3.63904933]\n",
      " [-0.33552812  0.8020203  -0.83402563 -2.5547157  -2.1168179   0.99040474\n",
      "  -4.71767787]\n",
      " [-0.80361953 -0.74920874 -2.59908114  0.12179719  1.292844   -2.08579059\n",
      "   1.05388668]\n",
      " [-0.45537131 -0.28428901  0.31959996  0.09238194  0.25914533 -1.57646989\n",
      "   2.83375409]\n",
      " [ 0.29496247  0.72535656  2.26192199  1.2080786   3.11557445 -0.32228434\n",
      "  -1.57651153]\n",
      " [ 0.93380654 -0.38440702  1.53347122  1.04596877  0.14090609 -2.75171325\n",
      "  -4.06273713]\n",
      " [ 1.28163827  0.07298747  3.80273398 -2.27228651  1.16425366  1.6503687\n",
      "  -3.96346953]\n",
      " [-1.09069563 -2.72728484  2.46296665 -0.26045116  0.96394654 -0.54344366\n",
      "  -2.95406254]\n",
      " [-0.57818696 -3.47284121 -1.86580454  2.37725091 -1.77587748 -1.30971919\n",
      "  -1.44749582]\n",
      " [ 0.6938838   0.77444191 -3.17033764 -1.08791976  1.64097941  2.06375974\n",
      "   1.29070885]\n",
      " [-0.46174775  0.11925575 -0.65113497 -0.39076775 -0.65301942 -2.9482463\n",
      "  -2.85561843]\n",
      " [-0.33426427 -0.7321422  -1.25845123  0.25320064 -2.62930043 -1.51094888\n",
      "  -2.56265742]\n",
      " [ 1.40370367 -0.57475134 -2.06218314 -0.67647545 -3.63780446 -1.40912514\n",
      "   0.48487987]] \n",
      "  b :\n",
      " [-0.36776922 -0.02520171 -1.48529549 -0.01350719 -2.9772502  -0.81245613\n",
      "  3.40135748]\n",
      "1000 \n",
      " cost :\n",
      " 0.0006287170512921504 ] \n",
      "  W :\n",
      " [[ 0.18305493 -3.96843119 -1.64061521 -1.57822348 -4.16607355 -1.76600276\n",
      "  -1.07854715]\n",
      " [-4.03907229  3.98985708 -2.58390333 -2.96117529 -1.84274718 -1.95735959\n",
      "  -5.42634161]\n",
      " [ 0.22183196  1.48959534  0.7991828   2.48317024  0.22010909  1.03706946\n",
      "   1.06852864]\n",
      " [ 2.93127416  0.54069425 -3.81222151 -3.36965514 -4.61525162 -2.3872663\n",
      "  -3.68422476]\n",
      " [-0.36299867  0.868874   -0.99391202 -2.59778571 -2.34190784  1.04147033\n",
      "  -5.50963361]\n",
      " [-0.93193038 -0.78253977 -2.94509044  0.284419    1.6688006  -2.39749453\n",
      "   1.10578604]\n",
      " [-0.49082564 -0.36868514  0.33203696 -0.03027067  0.2879977  -1.78520282\n",
      "   3.24609755]\n",
      " [ 0.4610692   0.52716237  2.39151397  1.37984166  3.5823816  -0.53119752\n",
      "  -1.97907432]\n",
      " [ 0.90447553 -0.33038464  1.6475889   1.21487855  0.24100153 -3.02673751\n",
      "  -4.48007928]\n",
      " [ 1.37271647  0.11657854  4.06902117 -2.80692788  1.32269521  1.87673784\n",
      "  -4.6143739 ]\n",
      " [-1.15851427 -2.76876128  2.75469805 -0.4058122   0.88750058 -0.49710925\n",
      "  -3.01752416]\n",
      " [-0.50942259 -4.09143099 -2.21344662  2.54029483 -2.20658707 -1.30988577\n",
      "  -1.81321693]\n",
      " [ 0.69605117  0.70849654 -3.4039128  -1.10288521  1.72200256  2.22471441\n",
      "   1.33732832]\n",
      " [-0.48522659  0.20905971 -0.53903725 -0.23125116 -0.90909366 -3.16811486\n",
      "  -3.16324612]\n",
      " [-0.25413812 -0.71943113 -1.28937845  0.34734935 -2.66474257 -1.75046148\n",
      "  -2.56544056]\n",
      " [ 1.37670001 -0.43612966 -2.35702765 -0.85995211 -3.92454263 -1.52216484\n",
      "   0.3999706 ]] \n",
      "  b :\n",
      " [-0.41065391 -0.02016102 -1.51903257 -0.06448822 -3.29393606 -0.90138326\n",
      "  3.76500228]\n",
      "1500 \n",
      " cost :\n",
      " 0.0003241773443162769 ] \n",
      "  W :\n",
      " [[ 0.29232614 -4.05999216 -1.66953179 -1.57839384 -4.48985277 -1.91691621\n",
      "  -1.12432928]\n",
      " [-4.16070203  4.14655328 -2.84039884 -3.0433828  -2.05887801 -2.24436748\n",
      "  -5.66673052]\n",
      " [ 0.08620832  1.61203343  0.86163309  2.61407213  0.11811144  1.0934409\n",
      "   1.28118422]\n",
      " [ 3.09885529  0.44320902 -4.01103453 -3.80540698 -4.93178199 -2.49094025\n",
      "  -3.72864439]\n",
      " [-0.37913787  0.91185846 -1.0994977  -2.63319202 -2.4891831   1.06868367\n",
      "  -5.99883599]\n",
      " [-1.01044468 -0.82163819 -3.16147956  0.3878347   1.90832313 -2.60238366\n",
      "   1.14442705]\n",
      " [-0.51465001 -0.42245986  0.33692257 -0.10298202  0.30082541 -1.92677863\n",
      "   3.51247713]\n",
      " [ 0.5646578   0.40013416  2.47880479  1.48986365  3.88975511 -0.6655926\n",
      "  -2.22511483]\n",
      " [ 0.88575038 -0.29536626  1.72320963  1.32261644  0.3045835  -3.20497489\n",
      "  -4.74362988]\n",
      " [ 1.4351353   0.14523245  4.23315912 -3.1576418   1.42192125  2.03483019\n",
      "  -5.05955087]\n",
      " [-1.20440697 -2.7948443   2.94033998 -0.4931859   0.83541132 -0.45541279\n",
      "  -3.05696482]\n",
      " [-0.46871846 -4.45355897 -2.43090879  2.64426015 -2.48323784 -1.30993385\n",
      "  -2.03727348]\n",
      " [ 0.6977481   0.66711099 -3.57714826 -1.11445044  1.77381509  2.32531285\n",
      "   1.36617393]\n",
      " [-0.50178706  0.26377565 -0.46477485 -0.12951174 -1.05735104 -3.31165969\n",
      "  -3.36134719]\n",
      " [-0.21609203 -0.70264072 -1.30542635  0.39916969 -2.68470818 -1.89381803\n",
      "  -2.56658737]\n",
      " [ 1.36372149 -0.35464391 -2.55255361 -0.96341694 -4.1092873  -1.60040771\n",
      "   0.35209399]] \n",
      "  b :\n",
      " [-0.43755979 -0.01614582 -1.54013476 -0.0961334  -3.5000434  -0.95823642\n",
      "  3.99449557]\n",
      "2000 \n",
      " cost :\n",
      " 0.00019562031879174777 ] \n",
      "  W :\n",
      " [[ 0.37815706 -4.13219685 -1.69128345 -1.57849114 -4.7372132  -2.03076595\n",
      "  -1.17104279]\n",
      " [-4.25543447  4.26880351 -3.04923949 -3.11518233 -2.22840823 -2.46654181\n",
      "  -5.84736717]\n",
      " [-0.01751286  1.70523852  0.91112748  2.71530973  0.03857872  1.13804261\n",
      "   1.44287315]\n",
      " [ 3.22983538  0.36643419 -4.16747095 -4.1418892  -5.17443384 -2.5715478\n",
      "  -3.77465491]\n",
      " [-0.39092974  0.94495994 -1.17771352 -2.6646742  -2.60424704  1.08753439\n",
      "  -6.36245519]\n",
      " [-1.06769424 -0.8623178  -3.32474202  0.46657927  2.09006819 -2.76082902\n",
      "   1.1754835 ]\n",
      " [-0.53311763 -0.463724    0.33916414 -0.1565455   0.30801252 -2.03775003\n",
      "   3.71755686]\n",
      " [ 0.64169442  0.30363     2.54721054  1.57406671  4.12831194 -0.76862845\n",
      "  -2.40703025]\n",
      " [ 0.87149747 -0.26808076  1.78209039  1.40479356  0.35205591 -3.3421911\n",
      "  -4.94491151]\n",
      " [ 1.48415503  0.16777653  4.35616411 -3.42836663  1.4963932   2.16089004\n",
      "  -5.41260435]\n",
      " [-1.24091061 -2.81465259  3.08169916 -0.55725483  0.7943949  -0.41752004\n",
      "  -3.08640628]\n",
      " [-0.43907266 -4.71562147 -2.59500888  2.72360902 -2.6951209  -1.30995525\n",
      "  -2.20444253]\n",
      " [ 0.69949067  0.63563031 -3.71739008 -1.12454433  1.81390237  2.40104165\n",
      "   1.38763931]\n",
      " [-0.51506549  0.3046025  -0.40696249 -0.0519122  -1.16385435 -3.42240245\n",
      "  -3.51635532]\n",
      " [-0.19254458 -0.6862605  -1.31616373  0.43481292 -2.69895247 -1.9986682\n",
      "  -2.56722716]\n",
      " [ 1.3563351  -0.29610444 -2.7040148  -1.03568959 -4.25226046 -1.66286225\n",
      "   0.31553944]] \n",
      "  b :\n",
      " [-0.45798856 -0.01259107 -1.55629892 -0.12040331 -3.65924698 -1.00156245\n",
      "  4.16912108]\n",
      "2500 \n",
      " cost :\n",
      " 0.00012851556859359202 ] \n",
      "  W :\n",
      " [[ 0.45157919 -4.19422654 -1.70893145 -1.57855573 -4.94331725 -2.12418418\n",
      "  -1.21909889]\n",
      " [-4.33592553  4.37262016 -3.22933814 -3.1815314  -2.37249152 -2.65331518\n",
      "  -5.99552466]\n",
      " [-0.10377092  1.78232446  0.95318838  2.80006325 -0.02869177  1.17616624\n",
      "   1.57729621]\n",
      " [ 3.341085    0.30058816 -4.30000454 -4.42374652 -5.37706379 -2.63955593\n",
      "  -3.82231878]\n",
      " [-0.40049635  0.97279322 -1.24016028 -2.69387508 -2.70215078  1.10233359\n",
      "  -6.65888744]\n",
      " [-1.11318377 -0.90411853 -3.4595958   0.53200051  2.24032009 -2.89380834\n",
      "   1.20194829]\n",
      " [-0.54852807 -0.49834932  0.34014795 -0.20011615  0.31252942 -2.13158536\n",
      "   3.88934854]\n",
      " [ 0.70397207  0.22402935  2.60511805  1.644313    4.32931816 -0.85470076\n",
      "  -2.55447835]\n",
      " [ 0.85959802 -0.24486159  1.83177426  1.47314796  0.39075738 -3.45713345\n",
      "  -5.1130446 ]\n",
      " [ 1.52552175  0.18711268  4.45739797 -3.65518939  1.55749309  2.26878955\n",
      "  -5.7141854 ]\n",
      " [-1.27232898 -2.83112666  3.19917156 -0.60897357  0.75964864 -0.38216058\n",
      "  -3.11045678]\n",
      " [-0.41529917 -4.92484428 -2.73057096  2.78967688 -2.87191762 -1.30996691\n",
      "  -2.34120192]\n",
      " [ 0.70137291  0.60935682 -3.83783771 -1.13388593  1.84771441  2.46342988\n",
      "   1.40520065]\n",
      " [-0.52651333  0.33816646 -0.35818671  0.01263352 -1.24864099 -3.51518011\n",
      "  -3.64874516]\n",
      " [-0.17606859 -0.67063621 -1.32425768  0.46212812 -2.71029748 -2.0831171\n",
      "  -2.56763611]\n",
      " [ 1.35205011 -0.2498667  -2.83097137 -1.09177924 -4.37300949 -1.71649213\n",
      "   0.28418074]] \n",
      "  b :\n",
      " [-0.47504721 -0.00923382 -1.56983361 -0.14079296 -3.79295973 -1.03755419\n",
      "  4.314385  ]\n",
      "3000 \n",
      " cost :\n",
      " 8.894052201979772e-05 ] \n",
      "  W :\n",
      " [[ 0.51764786 -4.2503118  -1.72398039 -1.57860256 -5.12411923 -2.2047916\n",
      "  -1.26839072]\n",
      " [-4.40795302  4.46535843 -3.39080803 -3.24496959 -2.50096725 -2.81828944\n",
      "  -6.12363648]\n",
      " [-0.17921882  1.84933404  0.99054328  2.87456692 -0.08844313  1.21031723\n",
      "   1.69512107]\n",
      " [ 3.44040963  0.24116069 -4.41753132 -4.67180769 -5.55510062 -2.69982047\n",
      "  -3.87139257]\n",
      " [-0.40874891  0.99745039 -1.29255871 -2.72169412 -2.78977095  1.11484291\n",
      "  -6.91440123]\n",
      " [-1.15125093 -0.94705544 -3.57715256  0.58924402  2.37108665 -3.0110773\n",
      "   1.225437  ]\n",
      " [-0.56201412 -0.52896157  0.34041515 -0.23766055  0.31556736 -2.21472594\n",
      "   4.04068432]\n",
      " [ 0.75685327  0.1550832   2.65649502  1.70600117  4.50726945 -0.93040239\n",
      "  -2.68075865]\n",
      " [ 0.84907611 -0.22404129  1.87577333  1.53301296  0.42405727 -3.5584194\n",
      "  -5.26098205]\n",
      " [ 1.56200386  0.2045717   4.54546047 -3.85490781  1.6103651   2.3652979\n",
      "  -5.98356773]\n",
      " [-1.30067435 -2.84559143  3.30202809 -0.65317393  0.72887209 -0.34844977\n",
      "  -3.13120336]\n",
      " [-0.39511913 -5.10172846 -2.8487558   2.84760945 -3.02718808 -1.30997405\n",
      "  -2.45933168]\n",
      " [ 0.70341349  0.58619107 -3.94548677 -1.14283964  1.87772037  2.51768052\n",
      "   1.42042088]\n",
      " [-0.53685643  0.36739379 -0.31499623  0.06916224 -1.32038211 -3.596857\n",
      "  -3.76748389]\n",
      " [-0.16368176 -0.65565441 -1.33080134  0.48444661 -2.71993375 -2.1551516\n",
      "  -2.56791868]\n",
      " [ 1.34979498 -0.21125531 -2.94264629 -1.1381494  -4.4804058  -1.76464575\n",
      "   0.25585702]] \n",
      "  b :\n",
      " [-0.490136   -0.00593145 -1.58176592 -0.15883881 -3.91102345 -1.0690291\n",
      "  4.44177178]\n",
      "3500 \n",
      " cost :\n",
      " 6.369848258651316e-05 ] \n",
      "  W :\n",
      " [[ 0.57910733 -4.30275925 -1.73726582 -1.57863851 -5.28822465 -2.2767112\n",
      "  -1.31873704]\n",
      " [-4.47464658  4.55101535 -3.53958278 -3.30701135 -2.61921887 -2.96886262\n",
      "  -6.23845041]\n",
      " [-0.24746641  1.90954562  1.02473448  2.94224722 -0.14325426  1.24189338\n",
      "   1.80205515]\n",
      " [ 3.53206613  0.18569176 -4.52501855 -4.89745645 -5.71689091 -2.75500037\n",
      "  -3.92162966]\n",
      " [-0.41615422  1.02005171 -1.33807358 -2.74868308 -2.87083403  1.12594149\n",
      "  -7.14298121]\n",
      " [-1.1842357  -0.99119206 -3.68334914  0.64107144  2.48884039 -3.11795479\n",
      "   1.24690157]\n",
      " [-0.57422924 -0.5569486   0.34021982 -0.27125145  0.31770451 -2.29074548\n",
      "   4.1785142 ]\n",
      " [ 0.80322418  0.09341288  2.703529    1.76203783  4.67005743 -0.99930543\n",
      "  -2.79297504]\n",
      " [ 0.83940484 -0.20471762  1.91600656  1.5872554   0.45376186 -3.6507256\n",
      "  -5.39559734]\n",
      " [ 1.59513972  0.22087919  4.62490767 -4.03669164  1.65776164  2.45421463\n",
      "  -6.23139942]\n",
      " [-1.32705354 -2.85875984  3.39525704 -0.6923945   0.70078537 -0.31579324\n",
      "  -3.14976621]\n",
      " [-0.37732392 -5.25698423 -2.95552724  2.90017204 -3.16825664 -1.30997876\n",
      "  -2.56512065]\n",
      " [ 0.7056126   0.56501638 -4.04441977 -1.15162238  1.905259    2.5665816\n",
      "   1.43413061]\n",
      " [-0.54651042  0.39383073 -0.27550555  0.12038127 -1.38358193 -3.67116914\n",
      "  -3.87729157]\n",
      " [-0.15390867 -0.64116449 -1.33633987  0.50346657 -2.72847071 -2.21898134\n",
      "  -2.56812401]\n",
      " [ 1.34901386 -0.17781376 -3.04411673 -1.17813625 -4.57923487 -1.80919132\n",
      "   0.22962699]] \n",
      "  b :\n",
      " [-5.04003438e-01 -2.59656755e-03 -1.59264541e+00 -1.75359413e-01\n",
      " -4.01877394e+00 -1.09750160e+00  4.55742742e+00]\n",
      "4000 \n",
      " cost :\n",
      " 4.671160032692981e-05 ] \n",
      "  W :\n",
      " [[ 0.63761228 -4.35296498 -1.74929349 -1.57866723 -5.44079608 -2.34241439\n",
      "  -1.36997263]\n",
      " [-4.537891    4.63200075 -3.67939478 -3.3686459  -2.7304991  -3.10948601\n",
      "  -6.34404175]\n",
      " [-0.31068167  1.96492662  1.05671511  3.00517781 -0.19467198  1.27175735\n",
      "   1.90149349]\n",
      " [ 3.61862659  0.1326921  -4.62551208 -5.10756463 -5.86745227 -2.80670933\n",
      "  -3.97282919]\n",
      " [-0.42297792  1.04126095 -1.37860845 -2.7752027  -2.94758249  1.13612666\n",
      "  -7.35290419]\n",
      " [-1.21354149 -1.03655962 -3.78171648  0.68912745  2.59744794 -3.21764563\n",
      "   1.26694139]\n",
      " [-0.58559084 -0.58312143  0.33969666 -0.30210239  0.31925925 -2.36182418\n",
      "   4.30700977]\n",
      " [ 0.84480801  0.03699694  2.74754809  1.81415905  4.82243039 -1.06355919\n",
      "  -2.89535646]\n",
      " [ 0.83027026 -0.18634752  1.95363271  1.63758495  0.4809438  -3.73686618\n",
      "  -5.52096167]\n",
      " [ 1.62586593  0.23647511  4.69843223 -4.2060726   1.7013205   2.53787251\n",
      "  -6.46415741]\n",
      " [-1.35213938 -2.87106146  3.48183916 -0.72812122  0.67460671 -0.28378692\n",
      "  -3.16681383]\n",
      " [-0.36119274 -5.39688416 -3.05443264  2.94901404 -3.29951356 -1.30998204\n",
      "  -2.66232361]\n",
      " [ 0.70796566  0.54517136 -4.13719577 -1.16037649  1.93113826  2.61179458\n",
      "   1.44682035]\n",
      " [-0.55573491  0.41839001 -0.23857624  0.1679051  -1.44085848 -3.74036571\n",
      "  -3.98095332]\n",
      " [-0.14591501 -0.62704365 -1.34118023  0.52015891 -2.73625991 -2.27708487\n",
      "  -2.56827852]\n",
      " [ 1.34938244 -0.14809834 -3.13846378 -1.21367077 -4.67236562 -1.85127305\n",
      "   0.20501793]] \n",
      "  b :\n",
      " [-5.17094245e-01  8.28778573e-04 -1.60279985e+00 -1.90843152e-01\n",
      " -4.11941575e+00 -1.12387515e+00  4.66500866e+00]\n",
      "4500 \n",
      " cost :\n",
      " 3.4835384548049444e-05 ] \n",
      "  W :\n",
      " [[ 0.69423249 -4.4018345  -1.76038938 -1.57869084 -5.5851601  -2.40348767\n",
      "  -1.42196141]\n",
      " [-4.59890457  4.70987139 -3.81271323 -3.430556   -2.83690484 -3.24302506\n",
      "  -6.44305455]\n",
      " [-0.3702586   2.01674004  1.08711178  3.06469899 -0.24368695  1.3004788\n",
      "   1.99560379]\n",
      " [ 3.70175551  0.08119552 -4.72100265 -5.30656854 -6.01002254 -2.85599692\n",
      "  -4.02483387]\n",
      " [-0.42938148  1.06149794 -1.41538125 -2.80149677 -3.02146187  1.14570509\n",
      "  -7.5494343 ]\n",
      " [-1.24007503 -1.08314307 -3.87451247  0.73446209  2.69938521 -3.31221613\n",
      "   1.28595235]\n",
      " [-0.59638558 -0.60798533  0.33892374 -0.33097975  0.32042372 -2.4293816\n",
      "   4.42885267]\n",
      " [ 0.88270891 -0.01545923  2.78941302  1.86347641  4.96744205 -1.12455187\n",
      "  -2.99061237]\n",
      " [ 0.82147312 -0.16858053  1.98940025  1.6850947   0.50628769 -3.81865649\n",
      "  -5.63967259]\n",
      " [ 1.6547894   0.25164537  4.7677475  -4.36662055  1.74209002  2.6177938\n",
      "  -6.68604548]\n",
      " [-1.37636882 -2.88277682  3.56368645 -0.76128911  0.64982775 -0.25215336\n",
      "  -3.18277494]\n",
      " [-0.34625923 -5.52540085 -3.14774056  2.99519038 -3.42378218 -1.30998441\n",
      "  -2.75335788]\n",
      " [ 0.71046715  0.52623498 -4.22550407 -1.16920136  1.95588121  2.654383\n",
      "   1.45880144]\n",
      " [-0.56470162  0.44165169 -0.20347302  0.21276598 -1.49385266 -3.80589555\n",
      "  -4.08024395]\n",
      " [-0.1391816  -0.61320218 -1.34551022  0.5351242  -2.74352118 -2.33103558\n",
      "  -2.56839777]\n",
      " [ 1.35069448 -0.12119199 -3.22768539 -1.24596306 -4.7616414  -1.89163691\n",
      "   0.18176513]] \n",
      "  b :\n",
      " [-5.29691685e-01  4.38464383e-03 -1.61243894e+00 -2.05603627e-01\n",
      " -4.21501010e+00 -1.14872808e+00  4.76685066e+00]\n",
      "5000 \n",
      " cost :\n",
      " 2.6297574922188642e-05 ] \n",
      "  W :\n",
      " [[ 0.74969312 -4.44998302 -1.77077369 -1.57871066 -5.72357146 -2.46099954\n",
      "  -1.47459233]\n",
      " [-4.65851397  4.78568156 -3.94123253 -3.49322691 -2.93984776 -3.3714138\n",
      "  -6.53729278]\n",
      " [-0.42713751  2.06583554  1.1163553   3.12171851 -0.29096295  1.3284521\n",
      "   2.0858406 ]\n",
      " [ 3.78258245  0.03054514 -4.81285178 -5.497471   -6.14679843 -2.90357996\n",
      "  -4.07751911]\n",
      " [-0.43546725  1.0810398  -1.44920887 -2.82773154 -3.09344785  1.15487799\n",
      "  -7.73609585]\n",
      " [-1.26445606 -1.13088346 -3.96325742  0.77777932  2.79631796 -3.40306399\n",
      "   1.30420498]\n",
      " [-0.60682114 -0.63186837  0.33794979 -0.35839383  0.32132219 -2.49438619\n",
      "   4.54585145]\n",
      " [ 0.91767188 -0.06482603  2.82970792  1.91073717  5.10714827 -1.18322648\n",
      "  -3.08057278]\n",
      " [ 0.812882   -0.15117997  2.02381621  1.7305187   0.53025446 -3.89732661\n",
      "  -5.75347747]\n",
      " [ 1.68232139  0.2665844   4.83400259 -4.5207511   1.78077792  2.69501514\n",
      "  -6.89991883]\n",
      " [-1.40003864 -2.89410084  3.64208871 -0.79251708  0.62610305 -0.22070245\n",
      "  -3.19793908]\n",
      " [-0.33220265 -5.64519985 -3.23697862  3.03940967 -3.54297121 -1.30998617\n",
      "  -2.83986599]\n",
      " [ 0.71311151  0.50792539 -4.31050268 -1.17816892  1.97984299  2.69506302\n",
      "   1.47028193]\n",
      " [-0.5735285   0.46400364 -0.16969783  0.25565702 -1.5436492  -3.86873751\n",
      "  -4.17635754]\n",
      " [-0.13336087 -0.5995781  -1.34945186  0.54875597 -2.75040011 -2.38188789\n",
      "  -2.56849158]\n",
      " [ 1.35280911 -0.09647748 -3.31313988 -1.27581714 -4.84830295 -1.93079071\n",
      "   0.15970612]] \n",
      "  b :\n",
      " [-0.54198469  0.00809888 -1.62170337 -0.21985251 -4.30694798 -1.17244965\n",
      "  4.86452055]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.05)\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    optimizer.minimize(loss=cost, var_list=[w, b])\n",
    "    if step % 500 == 0:\n",
    "        print('%04d' % step,'\\n', 'cost :\\n', tf.reduce_mean(cost()).numpy(), ']', '\\n',\n",
    "              ' W :\\n', w.numpy(),'\\n', ' b :\\n', b.numpy())\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return tf.argmax(tf.exp(logit(x)), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(71,), dtype=float64, numpy=\narray([1.00000219, 1.00000259, 1.0000228 , 1.00000219, 1.00000229,\n       1.00000259, 1.00000146, 1.00000356, 1.0000228 , 1.00002704,\n       1.00000229, 1.00000984, 1.0000228 , 1.00018422, 1.0000061 ,\n       1.00002714, 1.00000748, 1.00000259, 1.00007317, 1.00009364,\n       1.00000984, 1.00001561, 1.00000259, 1.00002239, 1.00008839,\n       1.00007197, 1.00001046, 1.00006724, 1.00000259, 1.00000075,\n       1.00000196, 1.00000146, 1.00000138, 1.00003059, 1.00001451,\n       1.00000736, 1.00002377, 1.00000748, 1.0000228 , 1.00001199,\n       1.00000427, 1.00005954, 1.00002569, 1.00001768, 1.00000229,\n       1.00000229, 1.00002714, 1.00000229, 1.00000426, 1.00002525,\n       1.00000229, 1.00000427, 1.00015918, 1.00001997, 1.00002525,\n       1.00000259, 1.00009505, 1.00000984, 1.00010103, 1.00001768,\n       1.00007317, 1.0000228 , 1.00003096, 1.00009366, 1.00000229,\n       1.00000146, 1.00009364, 1.00000229, 1.0000014 , 1.00000229,\n       1.00000146])>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(cost())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(pred_y, y), dtype= tf.float32)) *100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(30,), dtype=int64, numpy=\narray([1, 5, 3, 0, 0, 4, 6, 1, 1, 2, 2, 3, 1, 0, 6, 3, 1, 5, 4, 0, 4, 3,\n       0, 0, 1, 0, 5, 0, 2, 1], dtype=int64)>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred(test_x)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "80.0"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_pred, tf.argmax(test_y, axis= 1)).numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실습 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  \\\n0             1           5.1          3.5           1.4          0.2   \n1             2           4.9          3.0           1.4          0.2   \n2             3           4.7          3.2           1.3          0.2   \n3             4           4.6          3.1           1.5          0.2   \n4             5           5.0          3.6           1.4          0.2   \n..          ...           ...          ...           ...          ...   \n145         146           6.7          3.0           5.2          2.3   \n146         147           6.3          2.5           5.0          1.9   \n147         148           6.5          3.0           5.2          2.0   \n148         149           6.2          3.4           5.4          2.3   \n149         150           5.9          3.0           5.1          1.8   \n\n       Species  \n0       setosa  \n1       setosa  \n2       setosa  \n3       setosa  \n4       setosa  \n..         ...  \n145  virginica  \n146  virginica  \n147  virginica  \n148  virginica  \n149  virginica  \n\n[150 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>146</td>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>147</td>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>148</td>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>150</td>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/HOME/PycharmProjects/ai/.ipynb_checkpoints/data_set/iris.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "(     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n 22            4.6          3.6           1.0          0.2\n 31            5.4          3.4           1.5          0.4\n 9             4.9          3.1           1.5          0.1\n 145           6.7          3.0           5.2          2.3\n 67            5.8          2.7           4.1          1.0\n ..            ...          ...           ...          ...\n 103           6.3          2.9           5.6          1.8\n 17            5.1          3.5           1.4          0.3\n 56            6.3          3.3           4.7          1.6\n 52            6.9          3.1           4.9          1.5\n 93            5.0          2.3           3.3          1.0\n \n [105 rows x 4 columns],\n      setosa  versicolor  virginica\n 22        1           0          0\n 31        1           0          0\n 9         1           0          0\n 145       0           0          1\n 67        0           1          0\n ..      ...         ...        ...\n 103       0           0          1\n 17        1           0          0\n 56        0           1          0\n 52        0           1          0\n 93        0           1          0\n \n [105 rows x 3 columns],\n      Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n 12            4.8          3.0           1.4          0.1\n 18            5.7          3.8           1.7          0.3\n 20            5.4          3.4           1.7          0.2\n 21            5.1          3.7           1.5          0.4\n 25            5.0          3.0           1.6          0.2\n 28            5.2          3.4           1.4          0.2\n 29            4.7          3.2           1.6          0.2\n 35            5.0          3.2           1.2          0.2\n 36            5.5          3.5           1.3          0.2\n 40            5.0          3.5           1.3          0.3\n 41            4.5          2.3           1.3          0.3\n 43            5.0          3.5           1.6          0.6\n 46            5.1          3.8           1.6          0.2\n 48            5.3          3.7           1.5          0.2\n 57            4.9          2.4           3.3          1.0\n 58            6.6          2.9           4.6          1.3\n 62            6.0          2.2           4.0          1.0\n 63            6.1          2.9           4.7          1.4\n 70            5.9          3.2           4.8          1.8\n 72            6.3          2.5           4.9          1.5\n 73            6.1          2.8           4.7          1.2\n 78            6.0          2.9           4.5          1.5\n 80            5.5          2.4           3.8          1.1\n 84            5.4          3.0           4.5          1.5\n 85            6.0          3.4           4.5          1.6\n 89            5.5          2.5           4.0          1.3\n 91            6.1          3.0           4.6          1.4\n 98            5.1          2.5           3.0          1.1\n 100           6.3          3.3           6.0          2.5\n 101           5.8          2.7           5.1          1.9\n 106           4.9          2.5           4.5          1.7\n 108           6.7          2.5           5.8          1.8\n 110           6.5          3.2           5.1          2.0\n 115           6.4          3.2           5.3          2.3\n 116           6.5          3.0           5.5          1.8\n 119           6.0          2.2           5.0          1.5\n 122           7.7          2.8           6.7          2.0\n 124           6.7          3.3           5.7          2.1\n 125           7.2          3.2           6.0          1.8\n 126           6.2          2.8           4.8          1.8\n 132           6.4          2.8           5.6          2.2\n 136           6.3          3.4           5.6          2.4\n 141           6.9          3.1           5.1          2.3\n 148           6.2          3.4           5.4          2.3\n 149           5.9          3.0           5.1          1.8,\n 12         setosa\n 18         setosa\n 20         setosa\n 21         setosa\n 25         setosa\n 28         setosa\n 29         setosa\n 35         setosa\n 36         setosa\n 40         setosa\n 41         setosa\n 43         setosa\n 46         setosa\n 48         setosa\n 57     versicolor\n 58     versicolor\n 62     versicolor\n 63     versicolor\n 70     versicolor\n 72     versicolor\n 73     versicolor\n 78     versicolor\n 80     versicolor\n 84     versicolor\n 85     versicolor\n 89     versicolor\n 91     versicolor\n 98     versicolor\n 100     virginica\n 101     virginica\n 106     virginica\n 108     virginica\n 110     virginica\n 115     virginica\n 116     virginica\n 119     virginica\n 122     virginica\n 124     virginica\n 125     virginica\n 126     virginica\n 132     virginica\n 136     virginica\n 141     virginica\n 148     virginica\n 149     virginica\n Name: Species, dtype: object)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice = np.random.choice(np.arange(0, 150, 1), size = 105, replace= False)\n",
    "notchoice = np.setdiff1d(np.arange(0, 150, 1), choice)\n",
    "\n",
    "train_x = df.iloc[choice, 1:-1]\n",
    "train_y = df.iloc[choice, -1]\n",
    "train_y = pd.get_dummies(train_y)\n",
    "\n",
    "test_x = df.iloc[notchoice, 1:-1]\n",
    "test_y = df.iloc[notchoice, -1]\n",
    "train_x, train_y, test_x, test_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n 0            5.1          3.5           1.4          0.2\n 1            4.9          3.0           1.4          0.2\n 2            4.7          3.2           1.3          0.2\n 3            4.6          3.1           1.5          0.2\n 4            5.0          3.6           1.4          0.2\n ..           ...          ...           ...          ...\n 66           5.6          3.0           4.5          1.5\n 67           5.8          2.7           4.1          1.0\n 68           6.2          2.2           4.5          1.5\n 69           5.6          2.5           3.9          1.1\n 70           5.9          3.2           4.8          1.8\n \n [71 rows x 4 columns],\n     setosa  versicolor\n 0        1           0\n 1        1           0\n 2        1           0\n 3        1           0\n 4        1           0\n ..     ...         ...\n 66       0           1\n 67       0           1\n 68       0           1\n 69       0           1\n 70       0           1\n \n [71 rows x 2 columns])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_x = df.iloc[ :71, 1:-1 ]\n",
    "train_y = df.iloc[ :71, -1 ]\n",
    "train_y = pd.get_dummies(train_y)\n",
    "# train_y = tf.one_hot(train_y, 7) or use tf.one_hot\n",
    "# train_y = tf.reshape(train_y, [-1, 7])\n",
    "\n",
    "test_x = df.iloc[ 71:, 1:-1 ]\n",
    "test_y = df.iloc[ 71:, -1 ]\n",
    "\n",
    "train_x, train_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Variable 'weight:0' shape=(4, 3) dtype=float64, numpy=\n array([[ 0.18707434, -1.31031679, -0.43750407],\n        [ 1.19910924, -0.90414153, -0.67364865],\n        [ 0.21475923,  0.58170636,  1.04285366],\n        [-0.46046657, -0.16016982,  0.5653151 ]])>,\n <tf.Variable 'bias:0' shape=(3,) dtype=float64, numpy=array([-0.32323789, -1.32475676,  0.75088789])>)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.normal([ 4, 3 ], dtype=tf.float64), name='weight')\n",
    "b = tf.Variable(tf.random.normal([3], dtype=tf.float64), name='bias')\n",
    "\n",
    "w, b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return tf.matmul(x, w) + b\n",
    "\n",
    "\n",
    "def cost(x):\n",
    "    return tf.nn.softmax(logit(x))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(105, 3), dtype=float64, numpy=\narray([[9.99451116e-01, 2.95450842e-07, 5.48588694e-04],\n       [9.99100999e-01, 1.73195717e-07, 8.98827373e-04],\n       [9.98416829e-01, 6.28489307e-07, 1.58254256e-03],\n       [8.87297756e-01, 3.50270968e-07, 1.12701894e-01],\n       [9.60222948e-01, 1.23928708e-06, 3.97758127e-02],\n       [9.57116228e-01, 1.06947547e-06, 4.28827029e-02],\n       [8.65907481e-01, 1.43160445e-06, 1.34091087e-01],\n       [9.30662549e-01, 1.75508624e-07, 6.93372753e-02],\n       [8.81431477e-01, 2.36188776e-07, 1.18568287e-01],\n       [9.73055087e-01, 2.53885015e-07, 2.69446593e-02],\n       [9.99311824e-01, 1.78346281e-07, 6.87997736e-04],\n       [7.51566888e-01, 1.72731554e-06, 2.48431385e-01],\n       [8.74651423e-01, 1.07470153e-07, 1.25348470e-01],\n       [9.98842993e-01, 4.15396727e-07, 1.15659183e-03],\n       [9.98956406e-01, 3.53118959e-07, 1.04324115e-03],\n       [9.99583881e-01, 6.51485149e-08, 4.16053615e-04],\n       [8.72224914e-01, 2.51652075e-07, 1.27774834e-01],\n       [9.52617623e-01, 1.26628502e-06, 4.73811111e-02],\n       [9.52834343e-01, 3.25002415e-07, 4.71653323e-02],\n       [9.98291546e-01, 3.71137743e-07, 1.70808280e-03],\n       [9.99858345e-01, 2.51809112e-08, 1.41630111e-04],\n       [8.57063780e-01, 2.22883421e-07, 1.42935997e-01],\n       [9.46921286e-01, 4.84668479e-07, 5.30782294e-02],\n       [9.98603052e-01, 6.58061842e-07, 1.39628962e-03],\n       [8.89202164e-01, 3.17709273e-07, 1.10797519e-01],\n       [9.98246157e-01, 6.47538163e-07, 1.75319525e-03],\n       [8.60192761e-01, 3.28378330e-07, 1.39806911e-01],\n       [6.29750934e-01, 2.40704523e-07, 3.70248825e-01],\n       [9.98517259e-01, 4.63586044e-07, 1.48227751e-03],\n       [9.54637896e-01, 2.63708127e-08, 4.53620777e-02],\n       [8.10482501e-01, 1.37365437e-06, 1.89516126e-01],\n       [9.13381586e-01, 2.70258962e-06, 8.66157114e-02],\n       [9.99325654e-01, 1.99693820e-07, 6.74146728e-04],\n       [9.40804576e-01, 3.08798861e-06, 5.91923358e-02],\n       [9.69523204e-01, 3.93989435e-07, 3.04764020e-02],\n       [9.99428089e-01, 2.11878134e-07, 5.71698647e-04],\n       [9.65564038e-01, 6.79726415e-07, 3.44352821e-02],\n       [9.65607558e-01, 5.29405886e-07, 3.43919130e-02],\n       [9.04326456e-01, 4.40145809e-07, 9.56731036e-02],\n       [9.97551853e-01, 1.56887358e-06, 2.44657802e-03],\n       [8.66466705e-01, 1.29593123e-05, 1.33520335e-01],\n       [9.78883973e-01, 1.78179185e-07, 2.11158491e-02],\n       [9.41401992e-01, 1.17371185e-06, 5.85968343e-02],\n       [9.70268793e-01, 2.03174159e-07, 2.97310042e-02],\n       [9.74689370e-01, 2.40835001e-07, 2.53103891e-02],\n       [8.41759489e-01, 1.35915774e-07, 1.58240375e-01],\n       [8.74215210e-01, 2.30834316e-07, 1.25784559e-01],\n       [9.97885260e-01, 1.01438061e-06, 2.11372523e-03],\n       [9.97972471e-01, 7.80033878e-07, 2.02674905e-03],\n       [7.26277835e-01, 3.11503955e-06, 2.73719050e-01],\n       [9.99285935e-01, 1.35544938e-07, 7.13929500e-04],\n       [9.99059849e-01, 2.96865204e-07, 9.39854276e-04],\n       [9.99797997e-01, 4.90202419e-08, 2.01953816e-04],\n       [9.45034567e-01, 2.89507287e-07, 5.49651435e-02],\n       [9.99701168e-01, 5.62613604e-08, 2.98775870e-04],\n       [9.64873997e-01, 9.78201424e-07, 3.51250252e-02],\n       [9.22036800e-01, 7.71516558e-07, 7.79624287e-02],\n       [9.35137162e-01, 1.84841029e-06, 6.48609891e-02],\n       [9.81341243e-01, 1.03114349e-07, 1.86586538e-02],\n       [8.83135898e-01, 4.36999487e-06, 1.16859732e-01],\n       [9.98746572e-01, 3.26921022e-07, 1.25310154e-03],\n       [9.68658944e-01, 1.43789362e-06, 3.13396186e-02],\n       [8.39325234e-01, 2.29232187e-06, 1.60672474e-01],\n       [9.46558993e-01, 1.54325496e-06, 5.34394633e-02],\n       [8.07305844e-01, 1.97050050e-06, 1.92692185e-01],\n       [9.99537121e-01, 1.13607104e-07, 4.62765115e-04],\n       [9.20561293e-01, 6.87947264e-07, 7.94380187e-02],\n       [9.12334446e-01, 7.56882157e-07, 8.76647970e-02],\n       [8.24079846e-01, 5.30813475e-07, 1.75919623e-01],\n       [9.61300996e-01, 6.85084631e-07, 3.86983185e-02],\n       [9.99404724e-01, 1.87969263e-07, 5.95087800e-04],\n       [8.95561495e-01, 2.06711171e-07, 1.04438298e-01],\n       [8.64466180e-01, 2.20969016e-07, 1.35533599e-01],\n       [8.99430635e-01, 1.55567670e-06, 1.00567810e-01],\n       [8.22231629e-01, 1.63401482e-06, 1.77766737e-01],\n       [9.71799758e-01, 1.01203594e-06, 2.81992300e-02],\n       [9.11152934e-01, 4.38809431e-07, 8.88466274e-02],\n       [9.98315420e-01, 1.03094195e-06, 1.68354871e-03],\n       [9.98769138e-01, 5.36613751e-07, 1.23032532e-03],\n       [9.17976095e-01, 2.20572085e-07, 8.20236844e-02],\n       [9.98053352e-01, 7.70172821e-07, 1.94587775e-03],\n       [9.96795221e-01, 2.00695553e-06, 3.20277229e-03],\n       [7.98255035e-01, 8.20194549e-07, 2.01744145e-01],\n       [9.27502003e-01, 7.24348206e-08, 7.24979249e-02],\n       [9.28536477e-01, 3.08374386e-06, 7.14604395e-02],\n       [8.26065784e-01, 2.11076997e-06, 1.73932105e-01],\n       [8.37770365e-01, 8.96088385e-07, 1.62228739e-01],\n       [9.97704842e-01, 9.21529204e-07, 2.29423606e-03],\n       [8.82164299e-01, 9.18373271e-07, 1.17834783e-01],\n       [9.39768626e-01, 2.38636936e-06, 6.02289874e-02],\n       [9.58685102e-01, 1.22091841e-06, 4.13136774e-02],\n       [9.99885353e-01, 1.35006646e-08, 1.14633987e-04],\n       [9.74046570e-01, 1.68232712e-08, 2.59534133e-02],\n       [9.98384962e-01, 7.92755078e-07, 1.61424492e-03],\n       [9.99855261e-01, 2.27400235e-08, 1.44716245e-04],\n       [9.98005824e-01, 1.64400098e-06, 1.99253180e-03],\n       [9.35216672e-01, 1.43969450e-06, 6.47818887e-02],\n       [9.99582286e-01, 8.68228026e-08, 4.17627087e-04],\n       [9.99116746e-01, 2.55595474e-07, 8.82998892e-04],\n       [9.67556824e-01, 8.50154559e-07, 3.24423256e-02],\n       [8.59116946e-01, 7.59259409e-07, 1.40882295e-01],\n       [9.99252878e-01, 2.05766523e-07, 7.46916295e-04],\n       [9.70900872e-01, 2.50397772e-07, 2.90988775e-02],\n       [9.69071919e-01, 1.61861402e-07, 3.09279191e-02],\n       [9.30701596e-01, 6.88238325e-06, 6.92915218e-02]])>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(train_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def cost():\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(logits=logit(train_x), labels=train_y, axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 \n",
      " cost :\n",
      " 4.547324848904679 ] \n",
      "  W :\n",
      " [[ 0.13707434 -1.26031679 -0.38750407]\n",
      " [ 1.14910924 -0.85414153 -0.62364865]\n",
      " [ 0.16475923  0.63170636  1.09285366]\n",
      " [-0.51046656 -0.11016983  0.6153151 ]] \n",
      "  b :\n",
      " [-0.37323789 -1.27475677  0.80088788]\n",
      "0500 \n",
      " cost :\n",
      " 0.10550825096828144 ] \n",
      "  W :\n",
      " [[ 0.0346931  -0.02088242 -1.49814441]\n",
      " [ 2.60345258 -0.08409242 -2.14209651]\n",
      " [-1.8031944   0.47884247  2.62729391]\n",
      " [-3.00286343 -1.45135184  3.66685056]] \n",
      "  b :\n",
      " [ 0.3222328   1.38160918 -2.38794642]\n",
      "1000 \n",
      " cost :\n",
      " 0.06817545347614548 ] \n",
      "  W :\n",
      " [[ 0.20420551  0.28850088 -1.9420417 ]\n",
      " [ 3.54020235 -0.14684541 -2.62459334]\n",
      " [-2.59977918  0.0557898   3.53791632]\n",
      " [-4.0857332  -1.96916877  4.79299899]] \n",
      "  b :\n",
      " [ 0.90919079  2.80681329 -4.31118375]\n",
      "1500 \n",
      " cost :\n",
      " 0.056287864234523095 ] \n",
      "  W :\n",
      " [[ 0.32048546  0.47697965 -2.21995626]\n",
      " [ 4.14585765 -0.24893689 -2.8678321 ]\n",
      " [-3.12099165 -0.24571915  4.16046993]\n",
      " [-4.79964167 -2.23486182  5.45609991]] \n",
      "  b :\n",
      " [ 1.30462531  4.01319801 -5.87987234]\n",
      "2000 \n",
      " cost :\n",
      " 0.05068247461861973 ] \n",
      "  W :\n",
      " [[ 0.41066014  0.59392127 -2.40278136]\n",
      " [ 4.60343638 -0.36425767 -3.00890671]\n",
      " [-3.52038351 -0.46329819  4.62284994]\n",
      " [-5.34858355 -2.41939162  5.94527771]] \n",
      "  b :\n",
      " [ 1.61214022  5.1287734  -7.29670304]\n",
      "2500 \n",
      " cost :\n",
      " 0.047475163169879375 ] \n",
      "  W :\n",
      " [[ 0.48447144  0.65755842 -2.5165362 ]\n",
      " [ 4.97523338 -0.48787635 -3.09007629]\n",
      " [-3.84998967 -0.61557443  4.97477288]\n",
      " [-5.80274118 -2.57123845  6.34912559]] \n",
      "  b :\n",
      " [ 1.86778671  6.21218414 -8.64777567]\n",
      "3000 \n",
      " cost :\n",
      " 0.045383987462981515 ] \n",
      "  W :\n",
      " [[ 0.54670255  0.67871981 -2.57609446]\n",
      " [ 5.29010487 -0.61975501 -3.12840683]\n",
      " [-4.13360678 -0.71618418  5.24453198]\n",
      " [-6.1945556  -2.70671497  6.70221128]] \n",
      "  b :\n",
      " [ 2.08858689  7.29632102 -9.97948582]\n",
      "3500 \n",
      " cost :\n",
      " 0.043888611309202734 ] \n",
      "  W :\n",
      " [[ 0.60048442  0.6670097  -2.59400638]\n",
      " [ 5.56473413 -0.75947028 -3.13421594]\n",
      " [-4.38447639 -0.77890288  5.45459204]\n",
      " [-6.54226648 -2.83058115  7.0193554 ]] \n",
      "  b :\n",
      " [  2.28471594   8.397991   -11.31635689]\n",
      "4000 \n",
      " cost :\n",
      " 0.04276002742995142 ] \n",
      "  W :\n",
      " [[ 0.64845054  0.63330388 -2.58395756]\n",
      " [ 5.81092742 -0.90516489 -3.11654908]\n",
      " [-4.61142662 -0.819041    5.6265855 ]\n",
      " [-6.85816728 -2.94385316  7.30825471]] \n",
      "  b :\n",
      " [  2.46377243   9.52071412 -12.66662824]\n",
      "4500 \n",
      " cost :\n",
      " 0.04189255477955229 ] \n",
      "  W :\n",
      " [[ 0.69298013  0.58961457 -2.56075832]\n",
      " [ 6.03817022 -1.05435259 -3.08378683]\n",
      " [-4.82134495 -0.85178667  5.78091243]\n",
      " [-7.15190622 -3.04716728  7.57478131]] \n",
      "  b :\n",
      " [  2.63219562  10.65683382 -14.02543408]\n",
      "5000 \n",
      " cost :\n",
      " 0.041229321582692616 ] \n",
      "  W :\n",
      " [[ 0.73593016  0.54663242 -2.53743935]\n",
      " [ 6.25396077 -1.20527364 -3.04232448]\n",
      " [-5.01999935 -0.88851963  5.93320073]\n",
      " [-7.43149814 -3.14138589  7.82416231]] \n",
      "  b :\n",
      " [  2.79521765  11.79146026 -15.37918107]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.05)\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    optimizer.minimize(loss=cost, var_list=[ w, b ])\n",
    "    if step % 500 == 0:\n",
    "        print('%04d' % step, '\\n', 'cost :\\n', tf.reduce_mean(cost()).numpy(), ']', '\\n',\n",
    "              ' W :\\n', w.numpy(), '\\n', ' b :\\n', b.numpy())\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    # 변환할 라벨\n",
    "    labels = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "    data = tf.argmax(tf.exp(logit(x)), axis=1)\n",
    "    # 변환 수행\n",
    "    result = [labels[x] for x in data]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def accuracy(pred_y, y):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(pred_y, y), dtype=tf.float32)) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "97.77778"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred(test_x)\n",
    "y_pred\n",
    "accuracy(y_pred, test_y).numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "        pred_y      real_y  equal\n0       setosa      setosa   True\n1       setosa      setosa   True\n2       setosa      setosa   True\n3       setosa      setosa   True\n4       setosa      setosa   True\n5       setosa      setosa   True\n6       setosa      setosa   True\n7       setosa      setosa   True\n8       setosa      setosa   True\n9       setosa      setosa   True\n10      setosa      setosa   True\n11      setosa      setosa   True\n12      setosa      setosa   True\n13      setosa      setosa   True\n14  versicolor  versicolor   True\n15  versicolor  versicolor   True\n16  versicolor  versicolor   True\n17  versicolor  versicolor   True\n18  versicolor   virginica  False\n19  versicolor  versicolor   True\n20  versicolor  versicolor   True\n21  versicolor  versicolor   True\n22  versicolor  versicolor   True\n23  versicolor  versicolor   True\n24  versicolor  versicolor   True\n25  versicolor  versicolor   True\n26  versicolor  versicolor   True\n27  versicolor  versicolor   True\n28   virginica   virginica   True\n29   virginica   virginica   True\n30   virginica   virginica   True\n31   virginica   virginica   True\n32   virginica   virginica   True\n33   virginica   virginica   True\n34   virginica   virginica   True\n35   virginica   virginica   True\n36   virginica   virginica   True\n37   virginica   virginica   True\n38   virginica   virginica   True\n39   virginica   virginica   True\n40   virginica   virginica   True\n41   virginica   virginica   True\n42   virginica   virginica   True\n43   virginica   virginica   True\n44   virginica   virginica   True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_y</th>\n      <th>real_y</th>\n      <th>equal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>setosa</td>\n      <td>setosa</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>versicolor</td>\n      <td>virginica</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>versicolor</td>\n      <td>versicolor</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>virginica</td>\n      <td>virginica</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = pd.DataFrame(pred(test_x), test_y).reset_index()\n",
    "acc.columns = ['pred_y','real_y']\n",
    "acc = acc.assign(equal =  acc['pred_y'] == acc['real_y'])\n",
    "acc"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
