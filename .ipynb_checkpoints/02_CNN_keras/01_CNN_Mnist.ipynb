{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mnist_cnn\n",
    "MNIST and Convolutional Neural Network\n",
    "L1,L2 : conv2d + relu + max_pool\n",
    "L3 : FC(Fully Connected Layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      " [5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "print(x_train,'\\n', y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], shape=(60000, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nb_class = 10\n",
    "\n",
    "y_one_hot = tf.one_hot(y_train, nb_class)\n",
    "print(y_one_hot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "x_train_img = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test_img = x_test.reshape(-1, 28, 28, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "x_train_img = tf.cast(x_train_img, tf.float32)\n",
    "x_test_img = tf.cast(x_test_img, tf.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([60000, 28, 28, 1]), (60000,))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_img.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Layer 1 : conv2d - relu - max_pool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# conv2d\n",
    "L1 input image shape : (60000, 28, 28, 1)\n",
    "filter : (3,3,1,32), 필터 32개\n",
    "strides : (1,1,1,1), padding='SAME'\n",
    "출력 이미지 : (28+2 - 3)/1 + 1 = 28\n",
    "(?, 28, 28, 1) --> (?, 28, 28, 32)\n",
    "\n",
    "# max_pool\n",
    "input image : (?, 28, 28, 32)\n",
    "ksize : (1,2,2,1), strides : (1,2,2,1), padding='SAME'\n",
    "출력 이미지 : (28+1 - 2)/2 + 1 = 14\n",
    "(?, 28, 28, 32) -->  (?, 14, 14, 32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "w1 = tf.Variable(np.random.random([3, 3, 1, 32]), dtype=tf.float32, name='weight1')\n",
    "\n",
    "def layer1_conv2d(x):\n",
    "    output = tf.nn.conv2d(x, filters= w1, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer1_relu(x):\n",
    "    output = tf.nn.relu(layer1_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer1_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer1_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Layer 2 : conv2d - relu - max_pool\n",
    "# conv2d\n",
    "L1\n",
    "input\n",
    "image\n",
    "shape: (60000, 14, 14, 32)\n",
    "filter: (3, 3, 32, 64), 필터 64개\n",
    "strides: (1, 1, 1, 1), padding='SAME'\n",
    "출력\n",
    "(?, 14, 14, 32) --> (?, 14, 14, 64)\n",
    "\n",
    "\n",
    "# max_pool\n",
    "input\n",
    "image: (?, 14, 14, 64)\n",
    "ksize: (1, 2, 2, 1), strides: (1, 2, 2, 1), padding='SAME'\n",
    "출력\n",
    "(?, 14, 14, 64) -->  (?, 7, 7, 64)\n",
    "\n",
    "# flatten layer\n",
    "(?, 7, 7, 64) --> (?, 7 * 7 * 64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "w2 = tf.Variable(np.random.random([3, 3, 32, 64]), dtype=tf.float32, name='weight2')\n",
    "\n",
    "def layer2_conv2d(x):\n",
    "    output = tf.nn.conv2d(layer1_max_pool(x), filters= w2, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer2_relu(x):\n",
    "    output = tf.nn.relu(layer2_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer2_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer2_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output\n",
    "\n",
    "def layer2_flat(x):\n",
    "    output = tf.reshape(layer2_max_pool(x), [-1,7*7*64])\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# layer 3 : fully connected layer, 출력층\n",
    "(?, 7 * 7 *64) --> (7 * 7 * 64, 10) = (?. 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "w3 = tf.Variable(np.random.random([7*7*64, 10]), dtype=tf.float32, name='weight3')\n",
    "b3 = tf.Variable(np.random.random([10]), dtype=tf.float32, name='bias3')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def logits(x):\n",
    "    output = tf.matmul(layer2_flat(x), w3) + b3\n",
    "    return output\n",
    "\n",
    "def hyp(x):\n",
    "    return tf.nn.softmax(logits(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "epoch : 1 cost : 65410.28257086337 \n",
      "\n",
      "epoch : 2 cost : 1634.7244681333877 \n",
      "\n",
      "epoch : 3 cost : 550.7029661520934 \n",
      "\n",
      "epoch : 4 cost : 256.6352612422066 \n",
      "\n",
      "epoch : 5 cost : 135.04888909494778 \n",
      "\n",
      "epoch : 6 cost : 71.25615511185086 \n",
      "\n",
      "epoch : 7 cost : 38.98600306877725 \n",
      "\n",
      "epoch : 8 cost : 20.605115870125275 \n",
      "\n",
      "epoch : 9 cost : 11.732631138247301 \n",
      "\n",
      "epoch : 10 cost : 7.39674729363531 \n",
      "\n",
      "epoch : 11 cost : 5.017719980743189 \n",
      "\n",
      "epoch : 12 cost : 3.655754891598326 \n",
      "\n",
      "epoch : 13 cost : 3.5618619597875174 \n",
      "\n",
      "epoch : 14 cost : 2.969856640212556 \n",
      "\n",
      "epoch : 15 cost : 2.6797691502122793 \n",
      "\n",
      "epoch : 16 cost : 2.500251399146186 \n",
      "\n",
      "epoch : 17 cost : 2.3945851743730726 \n",
      "\n",
      "epoch : 18 cost : 2.3357717012747727 \n",
      "\n",
      "epoch : 19 cost : 2.3058437638812594 \n",
      "\n",
      "epoch : 20 cost : 2.2965343507946048 \n",
      "\n",
      "epoch : 21 cost : 2.2957005663814694 \n",
      "\n",
      "epoch : 22 cost : 2.295732230202764 \n",
      "\n",
      "epoch : 23 cost : 2.2957499312539382 \n",
      "\n",
      "epoch : 24 cost : 2.2957652063451257 \n",
      "\n",
      "epoch : 25 cost : 2.2957850592768105 \n",
      "\n",
      "epoch : 26 cost : 2.2957839884309696 \n",
      "\n",
      "epoch : 27 cost : 2.2975787698713126 \n",
      "\n",
      "epoch : 28 cost : 2.2979310995493165 \n",
      "\n",
      "epoch : 29 cost : 2.297921049289214 \n",
      "\n",
      "epoch : 30 cost : 2.297924793683566 \n",
      "\n",
      "epoch : 31 cost : 2.2979416867606646 \n",
      "\n",
      "epoch : 32 cost : 2.297968593418088 \n",
      "\n",
      "epoch : 33 cost : 2.298662785790924 \n",
      "\n",
      "epoch : 34 cost : 2.3013410435782555 \n",
      "\n",
      "epoch : 35 cost : 2.301340803121907 \n",
      "\n",
      "epoch : 36 cost : 2.301340924368964 \n",
      "\n",
      "epoch : 37 cost : 2.3013410323705443 \n",
      "\n",
      "epoch : 38 cost : 2.301341110824518 \n",
      "\n",
      "epoch : 39 cost : 2.301341190297379 \n",
      "\n",
      "epoch : 40 cost : 2.301341245317053 \n",
      "\n",
      "epoch : 41 cost : 2.3013412728268885 \n",
      "\n",
      "epoch : 42 cost : 2.301341300336723 \n",
      "\n",
      "epoch : 43 cost : 2.3013413451675686 \n",
      "\n",
      "epoch : 44 cost : 2.3013413522997475 \n",
      "\n",
      "epoch : 45 cost : 2.3013413543375143 \n",
      "\n",
      "epoch : 46 cost : 2.301341382866233 \n",
      "\n",
      "epoch : 47 cost : 2.3013413981494737 \n",
      "\n",
      "epoch : 48 cost : 2.3013413981494737 \n",
      "\n",
      "epoch : 49 cost : 2.3013414164893637 \n",
      "\n",
      "epoch : 50 cost : 2.301341417508246 \n",
      "\n",
      "epoch : 51 cost : 2.301341434829254 \n",
      "\n",
      "epoch : 52 cost : 2.3013414185271293 \n",
      "\n",
      "epoch : 53 cost : 2.3013414175082465 \n",
      "\n",
      "epoch : 54 cost : 2.30134142973484 \n",
      "\n",
      "epoch : 55 cost : 2.301341414451598 \n",
      "\n",
      "epoch : 56 cost : 2.3013414266781917 \n",
      "\n",
      "epoch : 57 cost : 2.3013414215837793 \n",
      "\n",
      "epoch : 58 cost : 2.3013414338103724 \n",
      "\n",
      "epoch : 59 cost : 2.301341442980318 \n",
      "\n",
      "epoch : 60 cost : 2.3013414276970745 \n",
      "\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.01)\n",
    "training_epoch = 60\n",
    "batch_size = 256\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(x_train.shape[0]/batch_size)\n",
    "    for k in range(total_batch):\n",
    "        batch_xs = x_train[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "        batch_ys = y_one_hot[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "\n",
    "        # 비용함수\n",
    "        def cost_func_batch():\n",
    "            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(batch_xs), labels= batch_ys)\n",
    "            cost = tf.reduce_mean(cost_i)\n",
    "            return cost\n",
    "\n",
    "        optimizer.minimize(loss=cost_func_batch, var_list=[w1, w2, w3, b3])\n",
    "        avg_cost += cost_func_batch().numpy() / total_batch\n",
    "    print('epoch :',epoch + 1,'cost :',avg_cost,'\\n', )\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return tf.argmax(logits(x),  axis=1)\n",
    "\n",
    "def accuracy(pred, real_y):\n",
    "    return pd.DataFrame(pred, real_y).assign(equal = pred == real_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[60000,28,28,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpred\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train_img\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m, in \u001B[0;36mpred\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpred\u001B[39m(x):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39margmax(\u001B[43mlogits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m,  axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m, in \u001B[0;36mlogits\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlogits\u001B[39m(x):\n\u001B[1;32m----> 2\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmatmul(\u001B[43mlayer2_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, w3) \u001B[38;5;241m+\u001B[39m b3\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 16\u001B[0m, in \u001B[0;36mlayer2_flat\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_flat\u001B[39m(x):\n\u001B[1;32m---> 16\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreshape(\u001B[43mlayer2_max_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m7\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m7\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m64\u001B[39m])\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 12\u001B[0m, in \u001B[0;36mlayer2_max_pool\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_max_pool\u001B[39m(x):\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mmax_pool(\u001B[43mlayer2_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, ksize\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], strides\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], padding\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAME\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m, in \u001B[0;36mlayer2_relu\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_relu\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mrelu(\u001B[43mlayer2_conv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m, in \u001B[0;36mlayer2_conv2d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_conv2d\u001B[39m(x):\n\u001B[1;32m----> 4\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mconv2d(\u001B[43mlayer1_max_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, filters\u001B[38;5;241m=\u001B[39m w2, strides\u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m], padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAME\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[8], line 12\u001B[0m, in \u001B[0;36mlayer1_max_pool\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer1_max_pool\u001B[39m(x):\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mmax_pool(\u001B[43mlayer1_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, ksize\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], strides\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], padding\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAME\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[8], line 8\u001B[0m, in \u001B[0;36mlayer1_relu\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer1_relu\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mrelu(\u001B[43mlayer1_conv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m, in \u001B[0;36mlayer1_conv2d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer1_conv2d\u001B[39m(x):\n\u001B[1;32m----> 4\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mw1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSAME\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7208\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7209\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: {{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[60000,28,28,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "pred(x_train_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred(x_test_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(pred(x_train_img), tf.argmax(y_train, axis=1))[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(pred(x_test), y_test)[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실습 과제\n",
    "mnist_cnn_deep\n",
    "MNIST and Convolutional Neural Network\n",
    "L1,L2,L3 : conv2d + relu + max_pool\n",
    "L4,L5 : FC(Fully Connected Layer)\n",
    "\n",
    "출력 size : 32(L1) --> 64(L2)-->128(L3) --> 512(L4) --> 10(L5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      " [5 0 4 ... 5 6 8]\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], shape=(60000, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(TensorShape([60000, 28, 28, 1]), (60000,))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "print(x_train, '\\n', y_train)\n",
    "nb_class = 10\n",
    "\n",
    "y_one_hot = tf.one_hot(y_train, nb_class)\n",
    "print(y_one_hot)\n",
    "x_train_img = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test_img = x_test.reshape(-1, 28, 28, 1)\n",
    "x_train_img = tf.cast(x_train_img, tf.float32)\n",
    "x_test_img = tf.cast(x_test_img, tf.float32)\n",
    "x_train_img.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "w1 = tf.Variable(np.random.random([3, 3, 1, 32]), dtype=tf.float32, name='weight1')\n",
    "\n",
    "def layer1_conv2d(x):\n",
    "    output = tf.nn.conv2d(x, filters= w1, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer1_relu(x):\n",
    "    output = tf.nn.relu(layer1_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer1_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer1_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "w2 = tf.Variable(np.random.random([3, 3, 32, 64]), dtype=tf.float32, name='weight2')\n",
    "\n",
    "def layer2_conv2d(x):\n",
    "    output = tf.nn.conv2d(layer1_max_pool(x), filters= w2, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer2_relu(x):\n",
    "    output = tf.nn.relu(layer2_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer2_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer2_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 7, 7, 64])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_max_pool(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "w3 = tf.Variable(np.random.random([3, 3, 64, 128]), dtype=tf.float32, name='weight3')\n",
    "\n",
    "def layer3_conv2d(x):\n",
    "    output = tf.nn.conv2d(layer2_max_pool(x), filters= w3, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer3_relu(x):\n",
    "    output = tf.nn.relu(layer3_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer3_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer3_relu(x), ksize=[1,1,1,1], strides=[1,1,1,1], padding= 'SAME')\n",
    "    return output\n",
    "\n",
    "def layer3_flat(x):\n",
    "    output = tf.reshape(layer3_max_pool(x), [-1,7*7*128])\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 7, 7, 128])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3_max_pool(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "w4 = tf.Variable(np.random.random([7*7*128, 512]), dtype=tf.float32, name='weight4')\n",
    "b4 = tf.Variable(np.random.random([512]), dtype=tf.float32, name='bias4')\n",
    "\n",
    "def layer4_fully_connect(x):\n",
    "    output = tf.matmul(layer3_flat(x), w4) + b4\n",
    "    return output\n",
    "\n",
    "def layer4_relu(x):\n",
    "    output = tf.nn.relu(layer4_fully_connect(x))\n",
    "    return output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 512])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer4_fully_connect(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "w5 = tf.Variable(np.random.random([512, 10]), dtype=tf.float32, name='weight5')\n",
    "b5 = tf.Variable(np.random.random([10]), dtype=tf.float32, name='bias5')\n",
    "\n",
    "def logits(x):\n",
    "    output = tf.matmul(layer4_relu(x), w5) + b5\n",
    "    return output\n",
    "\n",
    "# def layer5_relu(x):\n",
    "#     output = tf.nn.relu(layer5_fully_connect(x))\n",
    "#     return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 10])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "epoch : 1 cost : 14130306410.529915 \n",
      "\n",
      "epoch : 2 cost : 29287983.99999999 \n",
      "\n",
      "epoch : 3 cost : 24089001.50427352 \n",
      "\n",
      "epoch : 4 cost : 13025165.880341878 \n",
      "\n",
      "epoch : 5 cost : 9743788.068376062 \n",
      "\n",
      "epoch : 6 cost : 5081791.623931625 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.01)\n",
    "training_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(x_train.shape[0]/batch_size)\n",
    "    for k in range(total_batch):\n",
    "        batch_xs = x_train[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "        batch_ys = y_one_hot[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "\n",
    "        # 비용함수\n",
    "        def cost_func_batch():\n",
    "            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(batch_xs), labels= batch_ys)\n",
    "            cost = tf.reduce_mean(cost_i)\n",
    "            return cost\n",
    "\n",
    "        optimizer.minimize(loss=cost_func_batch, var_list=[w1, w2, w3, w4, w5, b4, b5])\n",
    "        avg_cost += cost_func_batch().numpy() / total_batch\n",
    "    print('epoch :',epoch + 1,'cost :',avg_cost,'\\n', )\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return tf.argmax(logits(x), axis=1)\n",
    "\n",
    "\n",
    "def accuracy(pred, real_y):\n",
    "    return pd.DataFrame(pred, real_y).assign(equal=pred == real_y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred(x_test_img[:500])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ArgMax_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected dimension in the range [-1, 1), but got 1 [Op:ArgMax]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m accuracy(pred(x_train_img[:\u001B[38;5;241m500\u001B[39m]), \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m)[ \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mequal\u001B[39m\u001B[38;5;124m'\u001B[39m ]\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7208\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7209\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__ArgMax_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected dimension in the range [-1, 1), but got 1 [Op:ArgMax]"
     ]
    }
   ],
   "source": [
    "accuracy(pred(x_train_img[:500]), tf.argmax(y_train[:500], axis=1))[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(pred(x_test), y_test)[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
