{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mnist_cnn\n",
    "MNIST and Convolutional Neural Network\n",
    "L1,L2 : conv2d + relu + max_pool\n",
    "L3 : FC(Fully Connected Layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      " [5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "print(x_train,'\\n', y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], shape=(60000, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nb_class = 10\n",
    "\n",
    "y_one_hot = tf.one_hot(y_train, nb_class)\n",
    "print(y_one_hot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "x_train_img = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test_img = x_test.reshape(-1, 28, 28, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "x_train_img = tf.cast(x_train_img, tf.float32)\n",
    "x_test_img = tf.cast(x_test_img, tf.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([60000, 28, 28, 1]), (60000,))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_img.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Layer 1 : conv2d - relu - max_pool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# conv2d\n",
    "L1 input image shape : (60000, 28, 28, 1)\n",
    "filter : (3,3,1,32), 필터 32개\n",
    "strides : (1,1,1,1), padding='SAME'\n",
    "출력 이미지 : (28+2 - 3)/1 + 1 = 28\n",
    "(?, 28, 28, 1) --> (?, 28, 28, 32)\n",
    "\n",
    "# max_pool\n",
    "input image : (?, 28, 28, 32)\n",
    "ksize : (1,2,2,1), strides : (1,2,2,1), padding='SAME'\n",
    "출력 이미지 : (28+1 - 2)/2 + 1 = 14\n",
    "(?, 28, 28, 32) -->  (?, 14, 14, 32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "w1 = tf.Variable(np.random.random([3, 3, 1, 32]), dtype=tf.float32, name='weight1')\n",
    "\n",
    "def layer1_conv2d(x):\n",
    "    output = tf.nn.conv2d(x, filters= w1, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer1_relu(x):\n",
    "    output = tf.nn.relu(layer1_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer1_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer1_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Layer 2 : conv2d - relu - max_pool\n",
    "# conv2d\n",
    "L1\n",
    "input\n",
    "image\n",
    "shape: (60000, 14, 14, 32)\n",
    "filter: (3, 3, 32, 64), 필터 64개\n",
    "strides: (1, 1, 1, 1), padding='SAME'\n",
    "출력\n",
    "(?, 14, 14, 32) --> (?, 14, 14, 64)\n",
    "\n",
    "\n",
    "# max_pool\n",
    "input\n",
    "image: (?, 14, 14, 64)\n",
    "ksize: (1, 2, 2, 1), strides: (1, 2, 2, 1), padding='SAME'\n",
    "출력\n",
    "(?, 14, 14, 64) -->  (?, 7, 7, 64)\n",
    "\n",
    "# flatten layer\n",
    "(?, 7, 7, 64) --> (?, 7 * 7 * 64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "w2 = tf.Variable(np.random.random([3, 3, 32, 64]), dtype=tf.float32, name='weight2')\n",
    "\n",
    "def layer2_conv2d(x):\n",
    "    output = tf.nn.conv2d(layer1_max_pool(x), filters= w2, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer2_relu(x):\n",
    "    output = tf.nn.relu(layer2_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer2_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer2_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output\n",
    "\n",
    "def layer2_flat(x):\n",
    "    output = tf.reshape(layer2_max_pool(x), [-1,7*7*64])\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# layer 3 : fully connected layer, 출력층\n",
    "(?, 7 * 7 *64) --> (7 * 7 * 64, 10) = (?. 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "w3 = tf.Variable(np.random.random([7*7*64, 10]), dtype=tf.float32, name='weight3')\n",
    "b3 = tf.Variable(np.random.random([10]), dtype=tf.float32, name='bias3')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def logits(x):\n",
    "    output = tf.matmul(layer2_flat(x), w3) + b3\n",
    "    return output\n",
    "\n",
    "def hyp(x):\n",
    "    return tf.nn.softmax(logits(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "epoch : 1 cost : 65410.28257086337 \n",
      "\n",
      "epoch : 2 cost : 1634.7244681333877 \n",
      "\n",
      "epoch : 3 cost : 550.7029661520934 \n",
      "\n",
      "epoch : 4 cost : 256.6352612422066 \n",
      "\n",
      "epoch : 5 cost : 135.04888909494778 \n",
      "\n",
      "epoch : 6 cost : 71.25615511185086 \n",
      "\n",
      "epoch : 7 cost : 38.98600306877725 \n",
      "\n",
      "epoch : 8 cost : 20.605115870125275 \n",
      "\n",
      "epoch : 9 cost : 11.732631138247301 \n",
      "\n",
      "epoch : 10 cost : 7.39674729363531 \n",
      "\n",
      "epoch : 11 cost : 5.017719980743189 \n",
      "\n",
      "epoch : 12 cost : 3.655754891598326 \n",
      "\n",
      "epoch : 13 cost : 3.5618619597875174 \n",
      "\n",
      "epoch : 14 cost : 2.969856640212556 \n",
      "\n",
      "epoch : 15 cost : 2.6797691502122793 \n",
      "\n",
      "epoch : 16 cost : 2.500251399146186 \n",
      "\n",
      "epoch : 17 cost : 2.3945851743730726 \n",
      "\n",
      "epoch : 18 cost : 2.3357717012747727 \n",
      "\n",
      "epoch : 19 cost : 2.3058437638812594 \n",
      "\n",
      "epoch : 20 cost : 2.2965343507946048 \n",
      "\n",
      "epoch : 21 cost : 2.2957005663814694 \n",
      "\n",
      "epoch : 22 cost : 2.295732230202764 \n",
      "\n",
      "epoch : 23 cost : 2.2957499312539382 \n",
      "\n",
      "epoch : 24 cost : 2.2957652063451257 \n",
      "\n",
      "epoch : 25 cost : 2.2957850592768105 \n",
      "\n",
      "epoch : 26 cost : 2.2957839884309696 \n",
      "\n",
      "epoch : 27 cost : 2.2975787698713126 \n",
      "\n",
      "epoch : 28 cost : 2.2979310995493165 \n",
      "\n",
      "epoch : 29 cost : 2.297921049289214 \n",
      "\n",
      "epoch : 30 cost : 2.297924793683566 \n",
      "\n",
      "epoch : 31 cost : 2.2979416867606646 \n",
      "\n",
      "epoch : 32 cost : 2.297968593418088 \n",
      "\n",
      "epoch : 33 cost : 2.298662785790924 \n",
      "\n",
      "epoch : 34 cost : 2.3013410435782555 \n",
      "\n",
      "epoch : 35 cost : 2.301340803121907 \n",
      "\n",
      "epoch : 36 cost : 2.301340924368964 \n",
      "\n",
      "epoch : 37 cost : 2.3013410323705443 \n",
      "\n",
      "epoch : 38 cost : 2.301341110824518 \n",
      "\n",
      "epoch : 39 cost : 2.301341190297379 \n",
      "\n",
      "epoch : 40 cost : 2.301341245317053 \n",
      "\n",
      "epoch : 41 cost : 2.3013412728268885 \n",
      "\n",
      "epoch : 42 cost : 2.301341300336723 \n",
      "\n",
      "epoch : 43 cost : 2.3013413451675686 \n",
      "\n",
      "epoch : 44 cost : 2.3013413522997475 \n",
      "\n",
      "epoch : 45 cost : 2.3013413543375143 \n",
      "\n",
      "epoch : 46 cost : 2.301341382866233 \n",
      "\n",
      "epoch : 47 cost : 2.3013413981494737 \n",
      "\n",
      "epoch : 48 cost : 2.3013413981494737 \n",
      "\n",
      "epoch : 49 cost : 2.3013414164893637 \n",
      "\n",
      "epoch : 50 cost : 2.301341417508246 \n",
      "\n",
      "epoch : 51 cost : 2.301341434829254 \n",
      "\n",
      "epoch : 52 cost : 2.3013414185271293 \n",
      "\n",
      "epoch : 53 cost : 2.3013414175082465 \n",
      "\n",
      "epoch : 54 cost : 2.30134142973484 \n",
      "\n",
      "epoch : 55 cost : 2.301341414451598 \n",
      "\n",
      "epoch : 56 cost : 2.3013414266781917 \n",
      "\n",
      "epoch : 57 cost : 2.3013414215837793 \n",
      "\n",
      "epoch : 58 cost : 2.3013414338103724 \n",
      "\n",
      "epoch : 59 cost : 2.301341442980318 \n",
      "\n",
      "epoch : 60 cost : 2.3013414276970745 \n",
      "\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.01)\n",
    "training_epoch = 60\n",
    "batch_size = 256\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(x_train.shape[0]/batch_size)\n",
    "    for k in range(total_batch):\n",
    "        batch_xs = x_train[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "        batch_ys = y_one_hot[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "\n",
    "        # 비용함수\n",
    "        def cost_func_batch():\n",
    "            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(batch_xs), labels= batch_ys)\n",
    "            cost = tf.reduce_mean(cost_i)\n",
    "            return cost\n",
    "\n",
    "        optimizer.minimize(loss=cost_func_batch, var_list=[w1, w2, w3, b3])\n",
    "        avg_cost += cost_func_batch().numpy() / total_batch\n",
    "    print('epoch :',epoch + 1,'cost :',avg_cost,'\\n', )\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return tf.argmax(logits(x),  axis=1)\n",
    "\n",
    "def accuracy(pred, real_y):\n",
    "    return pd.DataFrame(pred, real_y).assign(equal = pred == real_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[60000,28,28,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpred\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train_img\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m, in \u001B[0;36mpred\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpred\u001B[39m(x):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39margmax(\u001B[43mlogits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m,  axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m, in \u001B[0;36mlogits\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlogits\u001B[39m(x):\n\u001B[1;32m----> 2\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmatmul(\u001B[43mlayer2_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, w3) \u001B[38;5;241m+\u001B[39m b3\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 16\u001B[0m, in \u001B[0;36mlayer2_flat\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_flat\u001B[39m(x):\n\u001B[1;32m---> 16\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreshape(\u001B[43mlayer2_max_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m7\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m7\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m64\u001B[39m])\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 12\u001B[0m, in \u001B[0;36mlayer2_max_pool\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_max_pool\u001B[39m(x):\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mmax_pool(\u001B[43mlayer2_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, ksize\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], strides\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], padding\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAME\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m, in \u001B[0;36mlayer2_relu\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_relu\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mrelu(\u001B[43mlayer2_conv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m, in \u001B[0;36mlayer2_conv2d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer2_conv2d\u001B[39m(x):\n\u001B[1;32m----> 4\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mconv2d(\u001B[43mlayer1_max_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, filters\u001B[38;5;241m=\u001B[39m w2, strides\u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m], padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAME\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[8], line 12\u001B[0m, in \u001B[0;36mlayer1_max_pool\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer1_max_pool\u001B[39m(x):\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mmax_pool(\u001B[43mlayer1_relu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m, ksize\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], strides\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m], padding\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAME\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[8], line 8\u001B[0m, in \u001B[0;36mlayer1_relu\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer1_relu\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     output \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mrelu(\u001B[43mlayer1_conv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m, in \u001B[0;36mlayer1_conv2d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlayer1_conv2d\u001B[39m(x):\n\u001B[1;32m----> 4\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mw1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSAME\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7208\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7209\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: {{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[60000,28,28,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "pred(x_train_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred(x_test_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(pred(x_train_img), tf.argmax(y_train, axis=1))[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(pred(x_test), y_test)[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실습 과제\n",
    "mnist_cnn_deep\n",
    "MNIST and Convolutional Neural Network\n",
    "L1,L2,L3 : conv2d + relu + max_pool\n",
    "L4,L5 : FC(Fully Connected Layer)\n",
    "\n",
    "출력 size : 32(L1) --> 64(L2)-->128(L3) --> 512(L4) --> 10(L5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      " [5 0 4 ... 5 6 8]\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], shape=(60000, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(TensorShape([60000, 28, 28, 1]), (60000,))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "print(x_train, '\\n', y_train)\n",
    "nb_class = 10\n",
    "\n",
    "y_one_hot = tf.one_hot(y_train, nb_class)\n",
    "print(y_one_hot)\n",
    "x_train_img = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test_img = x_test.reshape(-1, 28, 28, 1)\n",
    "x_train_img = tf.cast(x_train_img, tf.float32)\n",
    "x_test_img = tf.cast(x_test_img, tf.float32)\n",
    "x_train_img.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "w1 = tf.Variable(np.random.random([3, 3, 1, 32]), dtype=tf.float32, name='weight1')\n",
    "\n",
    "def layer1_conv2d(x):\n",
    "    output = tf.nn.conv2d(x, filters= w1, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer1_relu(x):\n",
    "    output = tf.nn.relu(layer1_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer1_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer1_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "w2 = tf.Variable(np.random.random([3, 3, 32, 64]), dtype=tf.float32, name='weight2')\n",
    "\n",
    "def layer2_conv2d(x):\n",
    "    output = tf.nn.conv2d(layer1_max_pool(x), filters= w2, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer2_relu(x):\n",
    "    output = tf.nn.relu(layer2_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer2_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer2_relu(x), ksize=[1,2,2,1], strides=[1,2,2,1], padding= 'SAME')\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 7, 7, 64])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_max_pool(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "w3 = tf.Variable(np.random.random([3, 3, 64, 128]), dtype=tf.float32, name='weight3')\n",
    "\n",
    "def layer3_conv2d(x):\n",
    "    output = tf.nn.conv2d(layer2_max_pool(x), filters= w3, strides= [1,1,1,1], padding='SAME')\n",
    "    return output\n",
    "\n",
    "def layer3_relu(x):\n",
    "    output = tf.nn.relu(layer3_conv2d(x))\n",
    "    return output\n",
    "\n",
    "def layer3_max_pool(x):\n",
    "    output = tf.nn.max_pool(layer3_relu(x), ksize=[1,1,1,1], strides=[1,1,1,1], padding= 'SAME')\n",
    "    return output\n",
    "\n",
    "def layer3_flat(x):\n",
    "    output = tf.reshape(layer3_max_pool(x), [-1,7*7*128])\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 7, 7, 128])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3_max_pool(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "w4 = tf.Variable(np.random.random([7*7*128, 512]), dtype=tf.float32, name='weight4')\n",
    "b4 = tf.Variable(np.random.random([512]), dtype=tf.float32, name='bias4')\n",
    "\n",
    "def layer4_fully_connect(x):\n",
    "    output = tf.matmul(layer3_flat(x), w4) + b4\n",
    "    return output\n",
    "\n",
    "def layer4_relu(x):\n",
    "    output = tf.nn.relu(layer4_fully_connect(x))\n",
    "    return output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 512])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer4_fully_connect(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "w5 = tf.Variable(np.random.random([512, 10]), dtype=tf.float32, name='weight5')\n",
    "b5 = tf.Variable(np.random.random([10]), dtype=tf.float32, name='bias5')\n",
    "\n",
    "def logits(x):\n",
    "    output = tf.matmul(layer4_relu(x), w5) + b5\n",
    "    return output\n",
    "\n",
    "# def layer5_relu(x):\n",
    "#     output = tf.nn.relu(layer5_fully_connect(x))\n",
    "#     return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([5, 10])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits(x_train_img[:5]).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "epoch : 1 cost : 0.14331184269494215 \n",
      "\n",
      "epoch : 2 cost : 0.16853582968091604 \n",
      "\n",
      "epoch : 3 cost : 0.14209339129300708 \n",
      "\n",
      "epoch : 4 cost : 0.14827416227477752 \n",
      "\n",
      "epoch : 5 cost : 0.12255807986689946 \n",
      "\n",
      "epoch : 6 cost : 0.11139280690003632 \n",
      "\n",
      "epoch : 7 cost : 0.1015262903653595 \n",
      "\n",
      "epoch : 8 cost : 0.08718080681243227 \n",
      "\n",
      "epoch : 9 cost : 0.08266444206556191 \n",
      "\n",
      "epoch : 10 cost : 0.0788774233486535 \n",
      "\n",
      "epoch : 11 cost : 0.07563783867189135 \n",
      "\n",
      "epoch : 12 cost : 0.09196425098766625 \n",
      "\n",
      "epoch : 13 cost : 0.09271291689549252 \n",
      "\n",
      "epoch : 14 cost : 0.07714217371191892 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 21\u001B[0m\n\u001B[0;32m     18\u001B[0m         cost \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_mean(cost_i)\n\u001B[0;32m     19\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cost\n\u001B[1;32m---> 21\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcost_func_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mw1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw4\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw5\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb4\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb5\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m     avg_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m cost_func_batch()\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;241m/\u001B[39m total_batch\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch :\u001B[39m\u001B[38;5;124m'\u001B[39m,epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcost :\u001B[39m\u001B[38;5;124m'\u001B[39m,avg_cost,\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:579\u001B[0m, in \u001B[0;36mOptimizerV2.minimize\u001B[1;34m(self, loss, var_list, grad_loss, name, tape)\u001B[0m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001B[39;00m\n\u001B[0;32m    547\u001B[0m \n\u001B[0;32m    548\u001B[0m \u001B[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    574\u001B[0m \n\u001B[0;32m    575\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    576\u001B[0m grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_gradients(\n\u001B[0;32m    577\u001B[0m     loss, var_list\u001B[38;5;241m=\u001B[39mvar_list, grad_loss\u001B[38;5;241m=\u001B[39mgrad_loss, tape\u001B[38;5;241m=\u001B[39mtape\n\u001B[0;32m    578\u001B[0m )\n\u001B[1;32m--> 579\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrads_and_vars\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:730\u001B[0m, in \u001B[0;36mOptimizerV2.apply_gradients\u001B[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m experimental_aggregate_gradients\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m strategy\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    722\u001B[0m     )\n\u001B[0;32m    723\u001B[0m ):\n\u001B[0;32m    724\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    725\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`experimental_aggregate_gradients=False is not supported \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    726\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor ParameterServerStrategy and CentralStorageStrategy. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    727\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsed: strategy=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstrategy\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    728\u001B[0m     )\n\u001B[1;32m--> 730\u001B[0m apply_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m experimental_aggregate_gradients:\n\u001B[0;32m    732\u001B[0m     grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_unaggregated_gradients(\n\u001B[0;32m    733\u001B[0m         grads_and_vars\n\u001B[0;32m    734\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:1097\u001B[0m, in \u001B[0;36mOptimizerV2._prepare\u001B[1;34m(self, var_list)\u001B[0m\n\u001B[0;32m   1095\u001B[0m     apply_state[(var_device, var_dtype)] \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1096\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mdevice(var_device):\n\u001B[1;32m-> 1097\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapply_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m apply_state\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:134\u001B[0m, in \u001B[0;36mAdam._prepare_local\u001B[1;34m(self, var_device, var_dtype, apply_state)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_prepare_local\u001B[39m(\u001B[38;5;28mself\u001B[39m, var_device, var_dtype, apply_state):\n\u001B[1;32m--> 134\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapply_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m     local_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterations \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, var_dtype)\n\u001B[0;32m    137\u001B[0m     beta_1_t \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39midentity(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_hyper(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbeta_1\u001B[39m\u001B[38;5;124m\"\u001B[39m, var_dtype))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:1103\u001B[0m, in \u001B[0;36mOptimizerV2._prepare_local\u001B[1;34m(self, var_device, var_dtype, apply_state)\u001B[0m\n\u001B[0;32m   1101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_prepare_local\u001B[39m(\u001B[38;5;28mself\u001B[39m, var_device, var_dtype, apply_state):\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hyper:\n\u001B[1;32m-> 1103\u001B[0m         lr_t \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midentity\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decayed_lr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1104\u001B[0m         apply_state[(var_device, var_dtype)][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr_t\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m lr_t\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\array_ops.py:293\u001B[0m, in \u001B[0;36midentity\u001B[1;34m(input, name)\u001B[0m\n\u001B[0;32m    289\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mmap_structure(identity, \u001B[38;5;28minput\u001B[39m, expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    291\u001B[0m   \u001B[38;5;66;03m# Make sure we get an input with handle data attached from resource\u001B[39;00m\n\u001B[0;32m    292\u001B[0m   \u001B[38;5;66;03m# variables. Variables have correct handle data when graph building.\u001B[39;00m\n\u001B[1;32m--> 293\u001B[0m   \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    294\u001B[0m ret \u001B[38;5;241m=\u001B[39m gen_array_ops\u001B[38;5;241m.\u001B[39midentity(\u001B[38;5;28minput\u001B[39m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m    295\u001B[0m \u001B[38;5;66;03m# Propagate handle data for happier shape inference for resource variables.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    181\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[0;32m   1629\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1630\u001B[0m           _add_error_prefix(\n\u001B[0;32m   1631\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConversion function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconversion_func\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1634\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1635\u001B[0m               name\u001B[38;5;241m=\u001B[39mname))\n\u001B[0;32m   1637\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1638\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1640\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m   1641\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2105\u001B[0m, in \u001B[0;36m_dense_var_to_tensor\u001B[1;34m(var, dtype, name, as_ref)\u001B[0m\n\u001B[0;32m   2104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_dense_var_to_tensor\u001B[39m(var, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, as_ref\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m-> 2105\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dense_var_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1467\u001B[0m, in \u001B[0;36mBaseResourceVariable._dense_var_to_tensor\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   1465\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_value()\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1466\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1467\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:582\u001B[0m, in \u001B[0;36mBaseResourceVariable.value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    580\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_value\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28;01mNone\u001B[39;00m, ignore_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 582\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_variable_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[1;34m(self, no_copy)\u001B[0m\n\u001B[0;32m    702\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle(no_copy)\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mread_and_set_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mno_copy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m    707\u001B[0m   \u001B[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[0;32m    708\u001B[0m   \u001B[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[0;32m    709\u001B[0m   tape\u001B[38;5;241m.\u001B[39mrecord_operation(\n\u001B[0;32m    710\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, [result], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle],\n\u001B[0;32m    711\u001B[0m       backward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x],\n\u001B[0;32m    712\u001B[0m       forward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[1;34m(no_copy)\u001B[0m\n\u001B[0;32m    692\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m no_copy \u001B[38;5;129;01mand\u001B[39;00m forward_compat\u001B[38;5;241m.\u001B[39mforward_compatible(\u001B[38;5;241m2022\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m    693\u001B[0m   gen_resource_variable_ops\u001B[38;5;241m.\u001B[39mdisable_copy_on_read(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle)\n\u001B[1;32m--> 694\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_resource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_variable_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    696\u001B[0m _maybe_set_handle_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, result)\n\u001B[0;32m    697\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:524\u001B[0m, in \u001B[0;36mread_variable_op\u001B[1;34m(resource, dtype, name)\u001B[0m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m    523\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 524\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadVariableOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    526\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m    527\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.01)\n",
    "training_epoch = 20\n",
    "batch_size = 256\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(x_train.shape[0]/batch_size)\n",
    "    for k in range(total_batch):\n",
    "        batch_xs = x_train[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "        batch_ys = y_one_hot[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "\n",
    "        # 비용함수\n",
    "        def cost_func_batch():\n",
    "            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(batch_xs), labels= batch_ys)\n",
    "            cost = tf.reduce_mean(cost_i)\n",
    "            return cost\n",
    "\n",
    "        optimizer.minimize(loss=cost_func_batch, var_list=[w1, w2, w3, w4, w5, b4, b5])\n",
    "        avg_cost += cost_func_batch().numpy() / total_batch\n",
    "    print('epoch :',epoch + 1,'cost :',avg_cost,'\\n', )\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return tf.argmax(logits(x), axis=1)\n",
    "\n",
    "\n",
    "def accuracy(pred, real_y):\n",
    "    return pd.DataFrame(pred, real_y).assign(equal=pred == real_y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(500,), dtype=int64, numpy=\narray([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 8, 4, 7, 6,\n       6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2,\n       3, 0, 1, 2, 9, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 1,\n       6, 4, 3, 0, 7, 0, 2, 9, 1, 4, 3, 2, 9, 7, 9, 6, 2, 7, 8, 4, 7, 3,\n       6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 4, 4,\n       8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 4, 0, 5, 3, 5, 6, 6,\n       5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1, 7, 1, 8, 2, 0, 4, 4, 9, 5, 5,\n       1, 5, 6, 0, 3, 4, 8, 6, 5, 4, 6, 5, 4, 3, 1, 4, 4, 7, 2, 3, 2, 7,\n       1, 8, 1, 8, 1, 8, 5, 0, 3, 9, 2, 5, 0, 1, 1, 1, 0, 9, 0, 3, 1, 6,\n       4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 4, 4, 5, 9, 3, 8, 0, 3, 6, 5, 5,\n       7, 3, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1, 5, 0,\n       8, 7, 1, 3, 0, 6, 4, 2, 4, 1, 9, 5, 7, 1, 2, 8, 2, 6, 8, 5, 7, 7,\n       4, 1, 9, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 1, 5, 9, 2,\n       6, 4, 1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2, 4, 0, 2, 7,\n       4, 3, 3, 0, 0, 3, 1, 9, 6, 5, 2, 5, 9, 2, 9, 3, 0, 4, 2, 0, 7, 1,\n       1, 2, 1, 5, 3, 3, 4, 7, 3, 0, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5,\n       5, 6, 1, 8, 5, 1, 7, 9, 4, 6, 7, 2, 5, 0, 6, 3, 6, 3, 7, 2, 0, 8,\n       8, 5, 4, 1, 1, 4, 0, 3, 3, 7, 6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5,\n       2, 5, 7, 4, 2, 8, 3, 8, 2, 4, 5, 0, 3, 1, 7, 7, 3, 7, 9, 7, 1, 4,\n       2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8, 4, 5, 9, 8, 8, 3, 7, 6,\n       0, 0, 3, 0, 2, 0, 6, 4, 9, 3, 3, 3, 2, 3, 9, 1, 2, 6, 8, 0, 9, 6,\n       6, 6, 3, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9, 1, 9, 7, 5,\n       4, 0, 8, 9, 9, 1, 0, 9, 2, 3, 7, 8, 9, 9, 0, 6], dtype=int64)>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(x_test_img[:500])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.956"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred(x_train_img[:500]), (y_train[:500]))[ 'equal' ].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
