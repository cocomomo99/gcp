{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Keras DNN 실습과제"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import  tqdm\n",
    "\n",
    "tf.random.set_seed(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM    ZN  INDUS    NOX     RM   AGE     DIS  TAX  PTRATIO  MEDV\n",
      "0     2.30040   0.0  19.58  0.605  6.319  96.1  2.1000  403     14.7  23.8\n",
      "1    13.35980   0.0  18.10  0.693  5.887  94.7  1.7821  666     20.2  12.7\n",
      "2     0.12744   0.0   6.91  0.448  6.770   2.9  5.7209  233     17.9  26.6\n",
      "3     0.15876   0.0  10.81  0.413  5.961  17.5  5.2873  305     19.2  21.7\n",
      "4     0.03768  80.0   1.52  0.404  7.274  38.3  7.3090  329     12.6  34.6\n",
      "..        ...   ...    ...    ...    ...   ...     ...  ...      ...   ...\n",
      "395   0.23912   0.0   9.69  0.585  6.019  65.3  2.4091  391     19.2  21.2\n",
      "396   0.04560   0.0  13.89  0.550  5.888  56.0  3.1121  276     16.4  23.3\n",
      "397   1.38799   0.0   8.14  0.538  5.950  82.0  3.9900  307     21.0  13.2\n",
      "398   7.36711   0.0  18.10  0.679  6.193  78.1  1.9356  666     20.2  11.0\n",
      "399   0.14150   0.0   6.91  0.448  6.169   6.6  5.7209  233     17.9  25.3\n",
      "\n",
      "[400 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\ai\\\\.ipynb_checkpoints\\\\01_tensorflow_basic\\\\data_set\\\\boston_train.csv')\n",
    "print(train_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "        CRIM    ZN  INDUS    NOX     RM   AGE     DIS  TAX  PTRATIO  MEDV\n0    0.13587   0.0  10.59  0.489  6.064  59.1  4.2392  277     18.6  24.4\n1    0.08664  45.0   3.44  0.437  7.178  26.3  6.4798  398     15.2  36.4\n2    0.26938   0.0   9.90  0.544  6.266  82.8  3.2628  304     18.4  21.6\n3    0.05302   0.0   3.41  0.489  7.079  63.1  3.4145  270     17.8  28.7\n4    0.06860   0.0   2.89  0.445  7.416  62.5  3.4952  276     18.0  33.2\n..       ...   ...    ...    ...    ...   ...     ...  ...      ...   ...\n95   0.13262   0.0   8.56  0.520  5.851  96.7  2.1069  384     20.9  19.5\n96   6.80117   0.0  18.10  0.713  6.081  84.4  2.7175  666     20.2  20.0\n97  12.80230   0.0  18.10  0.740  5.854  96.6  1.8956  666     20.2  10.8\n98  10.23300   0.0  18.10  0.614  6.185  96.7  2.1705  666     20.2  14.6\n99   0.35809   0.0   6.20  0.507  6.951  88.5  2.8617  307     17.4  26.7\n\n[100 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.13587</td>\n      <td>0.0</td>\n      <td>10.59</td>\n      <td>0.489</td>\n      <td>6.064</td>\n      <td>59.1</td>\n      <td>4.2392</td>\n      <td>277</td>\n      <td>18.6</td>\n      <td>24.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.08664</td>\n      <td>45.0</td>\n      <td>3.44</td>\n      <td>0.437</td>\n      <td>7.178</td>\n      <td>26.3</td>\n      <td>6.4798</td>\n      <td>398</td>\n      <td>15.2</td>\n      <td>36.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.26938</td>\n      <td>0.0</td>\n      <td>9.90</td>\n      <td>0.544</td>\n      <td>6.266</td>\n      <td>82.8</td>\n      <td>3.2628</td>\n      <td>304</td>\n      <td>18.4</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05302</td>\n      <td>0.0</td>\n      <td>3.41</td>\n      <td>0.489</td>\n      <td>7.079</td>\n      <td>63.1</td>\n      <td>3.4145</td>\n      <td>270</td>\n      <td>17.8</td>\n      <td>28.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06860</td>\n      <td>0.0</td>\n      <td>2.89</td>\n      <td>0.445</td>\n      <td>7.416</td>\n      <td>62.5</td>\n      <td>3.4952</td>\n      <td>276</td>\n      <td>18.0</td>\n      <td>33.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.13262</td>\n      <td>0.0</td>\n      <td>8.56</td>\n      <td>0.520</td>\n      <td>5.851</td>\n      <td>96.7</td>\n      <td>2.1069</td>\n      <td>384</td>\n      <td>20.9</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>6.80117</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.713</td>\n      <td>6.081</td>\n      <td>84.4</td>\n      <td>2.7175</td>\n      <td>666</td>\n      <td>20.2</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>12.80230</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.740</td>\n      <td>5.854</td>\n      <td>96.6</td>\n      <td>1.8956</td>\n      <td>666</td>\n      <td>20.2</td>\n      <td>10.8</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>10.23300</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.614</td>\n      <td>6.185</td>\n      <td>96.7</td>\n      <td>2.1705</td>\n      <td>666</td>\n      <td>20.2</td>\n      <td>14.6</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.35809</td>\n      <td>0.0</td>\n      <td>6.20</td>\n      <td>0.507</td>\n      <td>6.951</td>\n      <td>88.5</td>\n      <td>2.8617</td>\n      <td>307</td>\n      <td>17.4</td>\n      <td>26.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\ai\\\\.ipynb_checkpoints\\\\01_tensorflow_basic\\\\data_set\\\\boston_test.csv')\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "((400, 9), (400,))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_df.iloc[:,:-1].to_numpy()\n",
    "y_train = train_df.iloc[:, -1].to_numpy()\n",
    "x_train.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[1] Boston 주택 가격 회귀 예측 모델을 Kears로  2층 신경망모델을 구현하여 MSE를 구하고\n",
    "   3층신경망 모델과 비교하여 보세요. 2층보다 3층이 MSE가 낮아지도록 구현한다\n",
    "   하나의 소스에 2층과 3층 두개 모델을 구현하여 MSE를비교하여 보세요. 학습 결과 시각화도 구현한다\n",
    "\n",
    "* 파라메터 설정 예시\n",
    "  [2층 신경망]\n",
    "  첫번째 층 출력 : [None,20],   활성화 함수 : 'relu',\n",
    "  optimizer='adam', loss: 'mean_squared_error'\n",
    "   학습 epoch : 700\n",
    "\n",
    "  [3층 신경망]\n",
    "  첫번째 층 출력 : [Non,20],   활성화 함수 : 'relu',\n",
    "  두번째 층 출력 : [Non,10],   활성화 함수 : 'relu',\n",
    "  optimizer='adam', loss: 'mean_squared_error'\n",
    "  학습 epoch : 700"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 20)                200       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential(layers = [\n",
    "    tf.keras.layers.Dense(units = 20, activation= 'relu', use_bias= True, input_shape= (9,) ),\n",
    "    tf.keras.layers.Dense(units = 1, activation= 'relu', use_bias= True)\n",
    "])\n",
    "\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 39075.0234 - val_loss: 30508.4492\n",
      "Epoch 2/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 28549.6660 - val_loss: 21728.0098\n",
      "Epoch 3/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 20057.8008 - val_loss: 14854.4688\n",
      "Epoch 4/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 13571.0889 - val_loss: 9707.5625\n",
      "Epoch 5/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8768.9414 - val_loss: 6095.2798\n",
      "Epoch 6/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5441.6123 - val_loss: 3686.2180\n",
      "Epoch 7/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3319.6465 - val_loss: 2138.2759\n",
      "Epoch 8/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1980.5339 - val_loss: 1229.6796\n",
      "Epoch 9/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1170.6372 - val_loss: 757.5817\n",
      "Epoch 10/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 748.4841 - val_loss: 530.7350\n",
      "Epoch 11/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 568.9779 - val_loss: 422.8171\n",
      "Epoch 12/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 468.4644 - val_loss: 380.0897\n",
      "Epoch 13/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 433.0190 - val_loss: 360.9296\n",
      "Epoch 14/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 410.6053 - val_loss: 349.7526\n",
      "Epoch 15/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 398.5864 - val_loss: 340.2166\n",
      "Epoch 16/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 390.5027 - val_loss: 328.8123\n",
      "Epoch 17/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 380.1718 - val_loss: 317.0760\n",
      "Epoch 18/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 371.7350 - val_loss: 305.1793\n",
      "Epoch 19/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 362.7479 - val_loss: 295.7480\n",
      "Epoch 20/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 354.7687 - val_loss: 287.5179\n",
      "Epoch 21/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 348.1205 - val_loss: 280.4394\n",
      "Epoch 22/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 341.2400 - val_loss: 276.0839\n",
      "Epoch 23/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 336.3583 - val_loss: 273.3027\n",
      "Epoch 24/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 331.8620 - val_loss: 270.4077\n",
      "Epoch 25/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 328.3517 - val_loss: 268.2969\n",
      "Epoch 26/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 324.7725 - val_loss: 266.5234\n",
      "Epoch 27/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 321.6710 - val_loss: 264.8426\n",
      "Epoch 28/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 318.3541 - val_loss: 262.3198\n",
      "Epoch 29/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 315.1568 - val_loss: 259.1259\n",
      "Epoch 30/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 312.0061 - val_loss: 256.8272\n",
      "Epoch 31/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 308.5446 - val_loss: 253.9271\n",
      "Epoch 32/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 305.4659 - val_loss: 250.5657\n",
      "Epoch 33/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 302.1702 - val_loss: 246.7672\n",
      "Epoch 34/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 299.0889 - val_loss: 244.0225\n",
      "Epoch 35/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 295.6352 - val_loss: 240.9267\n",
      "Epoch 36/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 292.4564 - val_loss: 237.7725\n",
      "Epoch 37/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 289.1243 - val_loss: 234.0023\n",
      "Epoch 38/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 285.7320 - val_loss: 230.6019\n",
      "Epoch 39/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 282.8240 - val_loss: 227.7876\n",
      "Epoch 40/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 278.8617 - val_loss: 223.6091\n",
      "Epoch 41/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 275.5004 - val_loss: 220.2006\n",
      "Epoch 42/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 271.5597 - val_loss: 216.9123\n",
      "Epoch 43/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 267.4884 - val_loss: 213.4624\n",
      "Epoch 44/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 263.4337 - val_loss: 209.1354\n",
      "Epoch 45/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 258.6305 - val_loss: 205.6655\n",
      "Epoch 46/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 253.5836 - val_loss: 201.4651\n",
      "Epoch 47/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 247.2155 - val_loss: 196.3308\n",
      "Epoch 48/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 240.7826 - val_loss: 191.4064\n",
      "Epoch 49/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 232.8411 - val_loss: 184.8260\n",
      "Epoch 50/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 224.9639 - val_loss: 180.3094\n",
      "Epoch 51/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 217.5113 - val_loss: 175.1551\n",
      "Epoch 52/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 210.4568 - val_loss: 169.3313\n",
      "Epoch 53/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 203.4543 - val_loss: 165.1581\n",
      "Epoch 54/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 195.1926 - val_loss: 158.7281\n",
      "Epoch 55/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 188.4453 - val_loss: 153.7989\n",
      "Epoch 56/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 180.1258 - val_loss: 148.0184\n",
      "Epoch 57/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 173.1399 - val_loss: 142.4164\n",
      "Epoch 58/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 166.5901 - val_loss: 136.5452\n",
      "Epoch 59/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 157.7927 - val_loss: 131.7966\n",
      "Epoch 60/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 151.8630 - val_loss: 126.1966\n",
      "Epoch 61/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 145.3332 - val_loss: 120.7680\n",
      "Epoch 62/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 139.4424 - val_loss: 116.3774\n",
      "Epoch 63/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 134.1017 - val_loss: 111.8544\n",
      "Epoch 64/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 129.4959 - val_loss: 108.1729\n",
      "Epoch 65/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 124.8737 - val_loss: 104.6786\n",
      "Epoch 66/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 120.4135 - val_loss: 101.1666\n",
      "Epoch 67/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 116.8006 - val_loss: 97.9114\n",
      "Epoch 68/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 113.3556 - val_loss: 95.7071\n",
      "Epoch 69/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 110.5567 - val_loss: 92.9328\n",
      "Epoch 70/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 107.8723 - val_loss: 90.5607\n",
      "Epoch 71/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 105.7455 - val_loss: 88.8577\n",
      "Epoch 72/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 102.9814 - val_loss: 87.1805\n",
      "Epoch 73/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 101.2845 - val_loss: 85.7095\n",
      "Epoch 74/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 99.7648 - val_loss: 84.3806\n",
      "Epoch 75/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 98.3661 - val_loss: 83.1565\n",
      "Epoch 76/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 96.5276 - val_loss: 82.3509\n",
      "Epoch 77/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 95.4592 - val_loss: 81.3997\n",
      "Epoch 78/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 94.5679 - val_loss: 80.3475\n",
      "Epoch 79/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 93.3392 - val_loss: 79.9631\n",
      "Epoch 80/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 92.2775 - val_loss: 79.0504\n",
      "Epoch 81/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 91.5156 - val_loss: 78.2819\n",
      "Epoch 82/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 90.8934 - val_loss: 77.8047\n",
      "Epoch 83/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 90.2940 - val_loss: 77.4595\n",
      "Epoch 84/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 89.6510 - val_loss: 77.0441\n",
      "Epoch 85/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 88.9668 - val_loss: 76.3118\n",
      "Epoch 86/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 88.8263 - val_loss: 75.9066\n",
      "Epoch 87/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 87.9402 - val_loss: 75.2626\n",
      "Epoch 88/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 87.5794 - val_loss: 74.9168\n",
      "Epoch 89/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 87.1522 - val_loss: 74.6727\n",
      "Epoch 90/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 86.6678 - val_loss: 74.4176\n",
      "Epoch 91/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 85.9551 - val_loss: 73.7485\n",
      "Epoch 92/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 85.8934 - val_loss: 73.3388\n",
      "Epoch 93/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 85.5625 - val_loss: 73.4874\n",
      "Epoch 94/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 85.5569 - val_loss: 72.5906\n",
      "Epoch 95/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 84.3702 - val_loss: 72.4641\n",
      "Epoch 96/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 84.3222 - val_loss: 72.1330\n",
      "Epoch 97/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 83.9868 - val_loss: 71.6502\n",
      "Epoch 98/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 83.7661 - val_loss: 71.8142\n",
      "Epoch 99/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 83.0622 - val_loss: 71.0493\n",
      "Epoch 100/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 83.3076 - val_loss: 70.8669\n",
      "Epoch 101/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 82.4643 - val_loss: 70.5791\n",
      "Epoch 102/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 82.2982 - val_loss: 70.1757\n",
      "Epoch 103/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 82.1438 - val_loss: 69.8567\n",
      "Epoch 104/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 81.7398 - val_loss: 69.6418\n",
      "Epoch 105/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 81.3986 - val_loss: 69.7019\n",
      "Epoch 106/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 81.0340 - val_loss: 69.0682\n",
      "Epoch 107/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 81.0485 - val_loss: 68.7627\n",
      "Epoch 108/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 80.7069 - val_loss: 68.5713\n",
      "Epoch 109/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 80.5190 - val_loss: 68.7531\n",
      "Epoch 110/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 80.3294 - val_loss: 67.9860\n",
      "Epoch 111/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 80.0947 - val_loss: 67.8481\n",
      "Epoch 112/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 79.4149 - val_loss: 67.4650\n",
      "Epoch 113/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 79.3135 - val_loss: 67.3141\n",
      "Epoch 114/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 78.8727 - val_loss: 67.0083\n",
      "Epoch 115/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 78.7093 - val_loss: 66.7891\n",
      "Epoch 116/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 78.7736 - val_loss: 66.5426\n",
      "Epoch 117/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 80.1589 - val_loss: 67.0887\n",
      "Epoch 118/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 78.2321 - val_loss: 66.0636\n",
      "Epoch 119/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 78.0848 - val_loss: 65.7936\n",
      "Epoch 120/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.8556 - val_loss: 65.6008\n",
      "Epoch 121/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.4952 - val_loss: 65.3989\n",
      "Epoch 122/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.2554 - val_loss: 65.3589\n",
      "Epoch 123/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.2498 - val_loss: 65.1969\n",
      "Epoch 124/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.9260 - val_loss: 64.7831\n",
      "Epoch 125/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 77.1810 - val_loss: 64.5648\n",
      "Epoch 126/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.3254 - val_loss: 64.7593\n",
      "Epoch 127/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 76.8953 - val_loss: 64.5807\n",
      "Epoch 128/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.8908 - val_loss: 64.2648\n",
      "Epoch 129/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.0878 - val_loss: 64.1082\n",
      "Epoch 130/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.4710 - val_loss: 63.9823\n",
      "Epoch 131/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.0089 - val_loss: 63.9602\n",
      "Epoch 132/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.6168 - val_loss: 63.2294\n",
      "Epoch 133/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.2604 - val_loss: 63.1101\n",
      "Epoch 134/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.1863 - val_loss: 62.8920\n",
      "Epoch 135/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 74.8307 - val_loss: 62.7533\n",
      "Epoch 136/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 74.7604 - val_loss: 62.6163\n",
      "Epoch 137/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.8278 - val_loss: 62.6541\n",
      "Epoch 138/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.7294 - val_loss: 62.4773\n",
      "Epoch 139/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 74.5260 - val_loss: 62.2606\n",
      "Epoch 140/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.5982 - val_loss: 62.0813\n",
      "Epoch 141/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.0400 - val_loss: 61.9279\n",
      "Epoch 142/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.9389 - val_loss: 61.8930\n",
      "Epoch 143/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.8123 - val_loss: 61.7761\n",
      "Epoch 144/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.0108 - val_loss: 61.5411\n",
      "Epoch 145/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.6713 - val_loss: 61.2878\n",
      "Epoch 146/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.3122 - val_loss: 61.0934\n",
      "Epoch 147/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.4732 - val_loss: 61.0270\n",
      "Epoch 148/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.5939 - val_loss: 60.9811\n",
      "Epoch 149/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.4559 - val_loss: 61.1217\n",
      "Epoch 150/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.5417 - val_loss: 60.5863\n",
      "Epoch 151/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.2372 - val_loss: 60.6342\n",
      "Epoch 152/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.7705 - val_loss: 60.2709\n",
      "Epoch 153/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.1197 - val_loss: 60.3797\n",
      "Epoch 154/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 72.0897 - val_loss: 60.0444\n",
      "Epoch 155/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.4351 - val_loss: 59.9306\n",
      "Epoch 156/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.9852 - val_loss: 59.6494\n",
      "Epoch 157/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 72.0810 - val_loss: 59.8780\n",
      "Epoch 158/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.7940 - val_loss: 59.3922\n",
      "Epoch 159/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.7616 - val_loss: 59.3089\n",
      "Epoch 160/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.5692 - val_loss: 59.0492\n",
      "Epoch 161/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.6129 - val_loss: 59.5875\n",
      "Epoch 162/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.8111 - val_loss: 59.0215\n",
      "Epoch 163/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.2117 - val_loss: 59.0735\n",
      "Epoch 164/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.9731 - val_loss: 58.8925\n",
      "Epoch 165/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.7607 - val_loss: 58.7645\n",
      "Epoch 166/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.7544 - val_loss: 58.7923\n",
      "Epoch 167/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.7061 - val_loss: 58.3916\n",
      "Epoch 168/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.4366 - val_loss: 58.3670\n",
      "Epoch 169/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.5453 - val_loss: 58.1900\n",
      "Epoch 170/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.4148 - val_loss: 58.4201\n",
      "Epoch 171/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.1619 - val_loss: 57.9416\n",
      "Epoch 172/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.6591 - val_loss: 57.8810\n",
      "Epoch 173/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 70.4832 - val_loss: 58.4090\n",
      "Epoch 174/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.7790 - val_loss: 57.5275\n",
      "Epoch 175/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 70.0207 - val_loss: 57.4745\n",
      "Epoch 176/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.4943 - val_loss: 57.6765\n",
      "Epoch 177/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.5136 - val_loss: 57.7196\n",
      "Epoch 178/700\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 69.5093 - val_loss: 57.0906\n",
      "Epoch 179/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.1763 - val_loss: 56.9639\n",
      "Epoch 180/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.2763 - val_loss: 56.7826\n",
      "Epoch 181/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.0961 - val_loss: 56.8707\n",
      "Epoch 182/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.0960 - val_loss: 56.5844\n",
      "Epoch 183/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.7809 - val_loss: 56.8678\n",
      "Epoch 184/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.7647 - val_loss: 56.6546\n",
      "Epoch 185/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.8322 - val_loss: 56.5134\n",
      "Epoch 186/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 68.4556 - val_loss: 56.2872\n",
      "Epoch 187/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 68.4044 - val_loss: 56.4573\n",
      "Epoch 188/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.2952 - val_loss: 56.0343\n",
      "Epoch 189/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.3899 - val_loss: 56.2867\n",
      "Epoch 190/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.9993 - val_loss: 56.1101\n",
      "Epoch 191/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 68.1230 - val_loss: 56.0563\n",
      "Epoch 192/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.8346 - val_loss: 55.8648\n",
      "Epoch 193/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.8070 - val_loss: 55.7326\n",
      "Epoch 194/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.6882 - val_loss: 55.6135\n",
      "Epoch 195/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.4544 - val_loss: 55.6968\n",
      "Epoch 196/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.5421 - val_loss: 55.5299\n",
      "Epoch 197/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.2602 - val_loss: 55.4346\n",
      "Epoch 198/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.7082 - val_loss: 55.0064\n",
      "Epoch 199/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.3894 - val_loss: 55.7340\n",
      "Epoch 200/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.4070 - val_loss: 54.7277\n",
      "Epoch 201/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.2528 - val_loss: 54.8807\n",
      "Epoch 202/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.7046 - val_loss: 55.0214\n",
      "Epoch 203/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 66.7266 - val_loss: 54.6081\n",
      "Epoch 204/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 66.6737 - val_loss: 54.5747\n",
      "Epoch 205/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.3544 - val_loss: 54.4897\n",
      "Epoch 206/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.4850 - val_loss: 54.5790\n",
      "Epoch 207/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.4463 - val_loss: 54.5996\n",
      "Epoch 208/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.1904 - val_loss: 54.3657\n",
      "Epoch 209/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.9876 - val_loss: 54.2566\n",
      "Epoch 210/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.1768 - val_loss: 53.9454\n",
      "Epoch 211/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.2315 - val_loss: 54.0303\n",
      "Epoch 212/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.0657 - val_loss: 53.7125\n",
      "Epoch 213/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.5722 - val_loss: 53.9672\n",
      "Epoch 214/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.5916 - val_loss: 53.9909\n",
      "Epoch 215/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.5267 - val_loss: 53.7700\n",
      "Epoch 216/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.4870 - val_loss: 53.8812\n",
      "Epoch 217/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.1684 - val_loss: 53.4634\n",
      "Epoch 218/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.2812 - val_loss: 53.0623\n",
      "Epoch 219/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.9221 - val_loss: 53.4057\n",
      "Epoch 220/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.0159 - val_loss: 53.3245\n",
      "Epoch 221/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.9916 - val_loss: 53.4022\n",
      "Epoch 222/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.0166 - val_loss: 53.3450\n",
      "Epoch 223/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.7666 - val_loss: 52.9701\n",
      "Epoch 224/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.4874 - val_loss: 53.1503\n",
      "Epoch 225/700\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 64.5258 - val_loss: 52.9941\n",
      "Epoch 226/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.6269 - val_loss: 52.7973\n",
      "Epoch 227/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.1930 - val_loss: 52.6249\n",
      "Epoch 228/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.0735 - val_loss: 52.6314\n",
      "Epoch 229/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.0092 - val_loss: 52.4594\n",
      "Epoch 230/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 63.9904 - val_loss: 52.3254\n",
      "Epoch 231/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.1253 - val_loss: 52.1655\n",
      "Epoch 232/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.7109 - val_loss: 52.4757\n",
      "Epoch 233/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.6217 - val_loss: 52.2302\n",
      "Epoch 234/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.0944 - val_loss: 51.9866\n",
      "Epoch 235/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 63.2002 - val_loss: 51.7303\n",
      "Epoch 236/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.5645 - val_loss: 51.8451\n",
      "Epoch 237/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.2710 - val_loss: 51.4953\n",
      "Epoch 238/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 63.3589 - val_loss: 51.3886\n",
      "Epoch 239/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 63.2085 - val_loss: 51.7623\n",
      "Epoch 240/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.9409 - val_loss: 51.3311\n",
      "Epoch 241/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 62.8702 - val_loss: 51.5512\n",
      "Epoch 242/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.9562 - val_loss: 51.3189\n",
      "Epoch 243/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.6339 - val_loss: 51.1918\n",
      "Epoch 244/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.3763 - val_loss: 51.0638\n",
      "Epoch 245/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 62.3206 - val_loss: 51.1592\n",
      "Epoch 246/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.3294 - val_loss: 50.9239\n",
      "Epoch 247/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.0978 - val_loss: 51.1588\n",
      "Epoch 248/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.8868 - val_loss: 50.6411\n",
      "Epoch 249/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.8753 - val_loss: 50.5153\n",
      "Epoch 250/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.8852 - val_loss: 50.5332\n",
      "Epoch 251/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.7846 - val_loss: 50.4801\n",
      "Epoch 252/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.6639 - val_loss: 50.1630\n",
      "Epoch 253/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.4042 - val_loss: 50.3024\n",
      "Epoch 254/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.2625 - val_loss: 50.2287\n",
      "Epoch 255/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.4501 - val_loss: 50.0036\n",
      "Epoch 256/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.2082 - val_loss: 49.9013\n",
      "Epoch 257/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.9075 - val_loss: 49.7801\n",
      "Epoch 258/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.8863 - val_loss: 49.7885\n",
      "Epoch 259/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.7686 - val_loss: 49.5747\n",
      "Epoch 260/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.7219 - val_loss: 49.5604\n",
      "Epoch 261/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.6940 - val_loss: 49.4746\n",
      "Epoch 262/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 60.3911 - val_loss: 49.6019\n",
      "Epoch 263/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 60.3855 - val_loss: 49.0575\n",
      "Epoch 264/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.9885 - val_loss: 49.6810\n",
      "Epoch 265/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.6672 - val_loss: 49.2550\n",
      "Epoch 266/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.1110 - val_loss: 48.6871\n",
      "Epoch 267/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.4761 - val_loss: 48.6440\n",
      "Epoch 268/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.2541 - val_loss: 48.9157\n",
      "Epoch 269/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 59.5475 - val_loss: 48.8698\n",
      "Epoch 270/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 59.9221 - val_loss: 48.4247\n",
      "Epoch 271/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.5816 - val_loss: 48.6017\n",
      "Epoch 272/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.7549 - val_loss: 48.3966\n",
      "Epoch 273/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.3659 - val_loss: 48.4138\n",
      "Epoch 274/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.1527 - val_loss: 48.0632\n",
      "Epoch 275/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.6710 - val_loss: 48.1186\n",
      "Epoch 276/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 59.7456 - val_loss: 48.4126\n",
      "Epoch 277/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.6846 - val_loss: 48.2980\n",
      "Epoch 278/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 58.9730 - val_loss: 47.9069\n",
      "Epoch 279/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 59.2591 - val_loss: 47.6578\n",
      "Epoch 280/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.7108 - val_loss: 47.7676\n",
      "Epoch 281/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 58.3891 - val_loss: 47.6088\n",
      "Epoch 282/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 58.4725 - val_loss: 47.7952\n",
      "Epoch 283/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 58.4586 - val_loss: 47.2771\n",
      "Epoch 284/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 58.1582 - val_loss: 47.0434\n",
      "Epoch 285/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 58.3455 - val_loss: 47.0413\n",
      "Epoch 286/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 58.0854 - val_loss: 47.6168\n",
      "Epoch 287/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.9394 - val_loss: 46.9446\n",
      "Epoch 288/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.9418 - val_loss: 46.8230\n",
      "Epoch 289/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.9409 - val_loss: 47.0101\n",
      "Epoch 290/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.3737 - val_loss: 46.5236\n",
      "Epoch 291/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.6756 - val_loss: 46.2802\n",
      "Epoch 292/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.2902 - val_loss: 46.4604\n",
      "Epoch 293/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.0359 - val_loss: 46.2852\n",
      "Epoch 294/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.0382 - val_loss: 46.1677\n",
      "Epoch 295/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.7532 - val_loss: 45.9795\n",
      "Epoch 296/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 58.1649 - val_loss: 46.1410\n",
      "Epoch 297/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.5138 - val_loss: 46.1198\n",
      "Epoch 298/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.9923 - val_loss: 46.0131\n",
      "Epoch 299/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.4604 - val_loss: 45.7245\n",
      "Epoch 300/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.4529 - val_loss: 45.5914\n",
      "Epoch 301/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.5816 - val_loss: 45.5151\n",
      "Epoch 302/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.2626 - val_loss: 46.0062\n",
      "Epoch 303/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.1911 - val_loss: 45.2559\n",
      "Epoch 304/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.1397 - val_loss: 45.3680\n",
      "Epoch 305/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.9047 - val_loss: 45.1824\n",
      "Epoch 306/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.9640 - val_loss: 44.9763\n",
      "Epoch 307/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.5526 - val_loss: 45.0120\n",
      "Epoch 308/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.8456 - val_loss: 44.8400\n",
      "Epoch 309/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.5699 - val_loss: 44.6703\n",
      "Epoch 310/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.2886 - val_loss: 44.4971\n",
      "Epoch 311/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.5767 - val_loss: 44.7531\n",
      "Epoch 312/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.1676 - val_loss: 45.0832\n",
      "Epoch 313/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.9774 - val_loss: 44.3839\n",
      "Epoch 314/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.0053 - val_loss: 45.8221\n",
      "Epoch 315/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 55.5068 - val_loss: 44.2234\n",
      "Epoch 316/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.1284 - val_loss: 44.1492\n",
      "Epoch 317/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.8050 - val_loss: 44.0565\n",
      "Epoch 318/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.6958 - val_loss: 43.8617\n",
      "Epoch 319/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 54.4893 - val_loss: 43.8928\n",
      "Epoch 320/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 54.5646 - val_loss: 43.8250\n",
      "Epoch 321/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 54.3640 - val_loss: 44.5289\n",
      "Epoch 322/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.4402 - val_loss: 43.4765\n",
      "Epoch 323/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.3454 - val_loss: 43.2169\n",
      "Epoch 324/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.1685 - val_loss: 44.0906\n",
      "Epoch 325/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.7594 - val_loss: 43.6649\n",
      "Epoch 326/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.5850 - val_loss: 44.2122\n",
      "Epoch 327/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.7060 - val_loss: 43.4436\n",
      "Epoch 328/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.6632 - val_loss: 44.1157\n",
      "Epoch 329/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.3295 - val_loss: 43.5840\n",
      "Epoch 330/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.9811 - val_loss: 43.3277\n",
      "Epoch 331/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.5562 - val_loss: 42.8076\n",
      "Epoch 332/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.4020 - val_loss: 43.3629\n",
      "Epoch 333/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 53.6549 - val_loss: 42.6588\n",
      "Epoch 334/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.9987 - val_loss: 42.3472\n",
      "Epoch 335/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.3452 - val_loss: 42.8388\n",
      "Epoch 336/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.0761 - val_loss: 42.7654\n",
      "Epoch 337/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.7813 - val_loss: 42.4674\n",
      "Epoch 338/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.9342 - val_loss: 41.9204\n",
      "Epoch 339/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.7974 - val_loss: 41.9825\n",
      "Epoch 340/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.5251 - val_loss: 42.2136\n",
      "Epoch 341/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.3987 - val_loss: 42.4084\n",
      "Epoch 342/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.2476 - val_loss: 41.8838\n",
      "Epoch 343/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.4559 - val_loss: 41.7245\n",
      "Epoch 344/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 52.3770 - val_loss: 41.6901\n",
      "Epoch 345/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.8370 - val_loss: 41.4333\n",
      "Epoch 346/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.1032 - val_loss: 41.4211\n",
      "Epoch 347/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 51.8210 - val_loss: 41.6421\n",
      "Epoch 348/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.3353 - val_loss: 42.2635\n",
      "Epoch 349/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.6051 - val_loss: 40.9962\n",
      "Epoch 350/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 52.4324 - val_loss: 41.1245\n",
      "Epoch 351/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.0665 - val_loss: 40.7367\n",
      "Epoch 352/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.0740 - val_loss: 40.9250\n",
      "Epoch 353/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.3508 - val_loss: 40.9305\n",
      "Epoch 354/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 51.2365 - val_loss: 40.9750\n",
      "Epoch 355/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.9691 - val_loss: 40.6752\n",
      "Epoch 356/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.4340 - val_loss: 40.7757\n",
      "Epoch 357/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.1764 - val_loss: 40.9675\n",
      "Epoch 358/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.8636 - val_loss: 40.5524\n",
      "Epoch 359/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.8207 - val_loss: 40.2760\n",
      "Epoch 360/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.4461 - val_loss: 40.1450\n",
      "Epoch 361/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.6036 - val_loss: 40.2943\n",
      "Epoch 362/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.5292 - val_loss: 40.1692\n",
      "Epoch 363/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.4164 - val_loss: 39.8834\n",
      "Epoch 364/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.0442 - val_loss: 39.9162\n",
      "Epoch 365/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.2728 - val_loss: 39.9329\n",
      "Epoch 366/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.1208 - val_loss: 39.8345\n",
      "Epoch 367/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.2714 - val_loss: 39.6736\n",
      "Epoch 368/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 49.7542 - val_loss: 39.3580\n",
      "Epoch 369/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.9521 - val_loss: 39.3273\n",
      "Epoch 370/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.6020 - val_loss: 39.3344\n",
      "Epoch 371/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.6556 - val_loss: 39.4602\n",
      "Epoch 372/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.3420 - val_loss: 39.0867\n",
      "Epoch 373/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.6000 - val_loss: 39.5289\n",
      "Epoch 374/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.8927 - val_loss: 38.9942\n",
      "Epoch 375/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 49.5336 - val_loss: 39.0520\n",
      "Epoch 376/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 48.6926 - val_loss: 38.7053\n",
      "Epoch 377/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.3876 - val_loss: 38.8253\n",
      "Epoch 378/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 48.7717 - val_loss: 38.6352\n",
      "Epoch 379/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.5340 - val_loss: 38.7425\n",
      "Epoch 380/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.5415 - val_loss: 38.6003\n",
      "Epoch 381/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.5272 - val_loss: 38.2414\n",
      "Epoch 382/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 48.6797 - val_loss: 38.1780\n",
      "Epoch 383/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.2254 - val_loss: 38.3450\n",
      "Epoch 384/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.9739 - val_loss: 38.0421\n",
      "Epoch 385/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 48.6498 - val_loss: 38.0022\n",
      "Epoch 386/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.9662 - val_loss: 37.7822\n",
      "Epoch 387/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.3377 - val_loss: 37.8810\n",
      "Epoch 388/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.5252 - val_loss: 37.7490\n",
      "Epoch 389/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.4512 - val_loss: 37.9823\n",
      "Epoch 390/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 47.4537 - val_loss: 37.6996\n",
      "Epoch 391/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.7659 - val_loss: 37.3553\n",
      "Epoch 392/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.0678 - val_loss: 37.6435\n",
      "Epoch 393/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.7661 - val_loss: 37.4675\n",
      "Epoch 394/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.3154 - val_loss: 37.1074\n",
      "Epoch 395/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.3297 - val_loss: 37.1278\n",
      "Epoch 396/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 47.3926 - val_loss: 37.3249\n",
      "Epoch 397/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.0006 - val_loss: 36.8095\n",
      "Epoch 398/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.2123 - val_loss: 37.2827\n",
      "Epoch 399/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.8460 - val_loss: 36.6428\n",
      "Epoch 400/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.7779 - val_loss: 36.9888\n",
      "Epoch 401/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.5209 - val_loss: 36.5475\n",
      "Epoch 402/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.0079 - val_loss: 36.8896\n",
      "Epoch 403/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.2614 - val_loss: 36.3865\n",
      "Epoch 404/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.0670 - val_loss: 37.1191\n",
      "Epoch 405/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.0703 - val_loss: 36.1786\n",
      "Epoch 406/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 47.7097 - val_loss: 36.2628\n",
      "Epoch 407/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.4702 - val_loss: 36.0552\n",
      "Epoch 408/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.3541 - val_loss: 36.8763\n",
      "Epoch 409/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.3111 - val_loss: 36.1906\n",
      "Epoch 410/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 46.1152 - val_loss: 36.5482\n",
      "Epoch 411/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.7373 - val_loss: 35.9612\n",
      "Epoch 412/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.5803 - val_loss: 35.6592\n",
      "Epoch 413/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.7394 - val_loss: 35.8169\n",
      "Epoch 414/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.5776 - val_loss: 35.5331\n",
      "Epoch 415/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.7390 - val_loss: 35.5500\n",
      "Epoch 416/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.7057 - val_loss: 35.3928\n",
      "Epoch 417/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.1305 - val_loss: 35.6181\n",
      "Epoch 418/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.2584 - val_loss: 35.0991\n",
      "Epoch 419/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.7645 - val_loss: 35.0775\n",
      "Epoch 420/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.9793 - val_loss: 35.7215\n",
      "Epoch 421/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.8214 - val_loss: 34.9027\n",
      "Epoch 422/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.0400 - val_loss: 35.1885\n",
      "Epoch 423/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.8204 - val_loss: 34.7848\n",
      "Epoch 424/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.1302 - val_loss: 35.0812\n",
      "Epoch 425/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.5037 - val_loss: 34.7642\n",
      "Epoch 426/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.2374 - val_loss: 35.3944\n",
      "Epoch 427/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.6834 - val_loss: 34.6636\n",
      "Epoch 428/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.1293 - val_loss: 34.9864\n",
      "Epoch 429/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.1341 - val_loss: 34.3006\n",
      "Epoch 430/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.9010 - val_loss: 34.7058\n",
      "Epoch 431/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.7726 - val_loss: 34.0504\n",
      "Epoch 432/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 43.8385 - val_loss: 34.0202\n",
      "Epoch 433/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 43.9038 - val_loss: 34.9808\n",
      "Epoch 434/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.0476 - val_loss: 33.8351\n",
      "Epoch 435/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.6620 - val_loss: 34.1088\n",
      "Epoch 436/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 43.3528 - val_loss: 33.7095\n",
      "Epoch 437/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.5468 - val_loss: 33.7338\n",
      "Epoch 438/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2507 - val_loss: 33.5691\n",
      "Epoch 439/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.8168 - val_loss: 33.4321\n",
      "Epoch 440/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.7198 - val_loss: 33.7775\n",
      "Epoch 441/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.0158 - val_loss: 33.2635\n",
      "Epoch 442/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.1363 - val_loss: 33.5214\n",
      "Epoch 443/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2540 - val_loss: 33.1945\n",
      "Epoch 444/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.5309 - val_loss: 33.1167\n",
      "Epoch 445/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.9584 - val_loss: 33.2789\n",
      "Epoch 446/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.6402 - val_loss: 32.8399\n",
      "Epoch 447/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.0415 - val_loss: 34.0819\n",
      "Epoch 448/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2010 - val_loss: 32.7108\n",
      "Epoch 449/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.3273 - val_loss: 34.1504\n",
      "Epoch 450/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.2013 - val_loss: 32.6004\n",
      "Epoch 451/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2371 - val_loss: 34.0515\n",
      "Epoch 452/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.8206 - val_loss: 32.7318\n",
      "Epoch 453/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.0777 - val_loss: 33.2991\n",
      "Epoch 454/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.5184 - val_loss: 32.2873\n",
      "Epoch 455/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.8507 - val_loss: 33.0580\n",
      "Epoch 456/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.4320 - val_loss: 32.7032\n",
      "Epoch 457/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 41.9844 - val_loss: 33.4134\n",
      "Epoch 458/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.4558 - val_loss: 32.6462\n",
      "Epoch 459/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.4642 - val_loss: 31.8996\n",
      "Epoch 460/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.1625 - val_loss: 32.6075\n",
      "Epoch 461/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.5456 - val_loss: 32.0830\n",
      "Epoch 462/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0088 - val_loss: 32.9617\n",
      "Epoch 463/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.6037 - val_loss: 31.5037\n",
      "Epoch 464/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.5100 - val_loss: 32.5630\n",
      "Epoch 465/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.0144 - val_loss: 31.6756\n",
      "Epoch 466/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.0203 - val_loss: 32.2712\n",
      "Epoch 467/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0505 - val_loss: 31.3926\n",
      "Epoch 468/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.9501 - val_loss: 32.8697\n",
      "Epoch 469/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.1423 - val_loss: 31.3191\n",
      "Epoch 470/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.4607 - val_loss: 31.3891\n",
      "Epoch 471/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.8012 - val_loss: 32.1615\n",
      "Epoch 472/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3642 - val_loss: 30.8932\n",
      "Epoch 473/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0921 - val_loss: 31.4779\n",
      "Epoch 474/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.6610 - val_loss: 31.9334\n",
      "Epoch 475/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.6078 - val_loss: 30.6642\n",
      "Epoch 476/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.3414 - val_loss: 31.4065\n",
      "Epoch 477/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.2089 - val_loss: 30.6519\n",
      "Epoch 478/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.3495 - val_loss: 30.6358\n",
      "Epoch 479/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.5400 - val_loss: 30.7655\n",
      "Epoch 480/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.0276 - val_loss: 30.5577\n",
      "Epoch 481/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.6962 - val_loss: 30.2502\n",
      "Epoch 482/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.0662 - val_loss: 31.9208\n",
      "Epoch 483/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.4178 - val_loss: 30.2898\n",
      "Epoch 484/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7537 - val_loss: 31.3047\n",
      "Epoch 485/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7740 - val_loss: 30.0713\n",
      "Epoch 486/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.1573 - val_loss: 30.0081\n",
      "Epoch 487/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.4413 - val_loss: 30.9062\n",
      "Epoch 488/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.6808 - val_loss: 30.1955\n",
      "Epoch 489/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.4876 - val_loss: 30.4323\n",
      "Epoch 490/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.1764 - val_loss: 29.8491\n",
      "Epoch 491/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.2319 - val_loss: 29.8650\n",
      "Epoch 492/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.1285 - val_loss: 29.9477\n",
      "Epoch 493/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.5413 - val_loss: 29.4203\n",
      "Epoch 494/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.3668 - val_loss: 29.6560\n",
      "Epoch 495/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.0951 - val_loss: 30.1543\n",
      "Epoch 496/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.0543 - val_loss: 29.4994\n",
      "Epoch 497/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.3931 - val_loss: 31.8911\n",
      "Epoch 498/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.3438 - val_loss: 29.5315\n",
      "Epoch 499/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.8900 - val_loss: 29.2927\n",
      "Epoch 500/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.1311 - val_loss: 29.2508\n",
      "Epoch 501/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.3894 - val_loss: 29.3475\n",
      "Epoch 502/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.8482 - val_loss: 28.8186\n",
      "Epoch 503/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7617 - val_loss: 29.3103\n",
      "Epoch 504/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.2411 - val_loss: 33.2622\n",
      "Epoch 505/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.7320 - val_loss: 28.5614\n",
      "Epoch 506/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.7723 - val_loss: 28.7302\n",
      "Epoch 507/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.7250 - val_loss: 34.2221\n",
      "Epoch 508/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.5302 - val_loss: 29.3530\n",
      "Epoch 509/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5365 - val_loss: 31.2459\n",
      "Epoch 510/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.3300 - val_loss: 28.4359\n",
      "Epoch 511/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.8137 - val_loss: 32.7748\n",
      "Epoch 512/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.8084 - val_loss: 28.6284\n",
      "Epoch 513/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.2864 - val_loss: 32.5105\n",
      "Epoch 514/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.0322 - val_loss: 28.6291\n",
      "Epoch 515/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.7032 - val_loss: 30.4715\n",
      "Epoch 516/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.9880 - val_loss: 28.5701\n",
      "Epoch 517/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.1170 - val_loss: 28.6680\n",
      "Epoch 518/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.1572 - val_loss: 30.4628\n",
      "Epoch 519/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7198 - val_loss: 28.8849\n",
      "Epoch 520/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.1677 - val_loss: 28.1722\n",
      "Epoch 521/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.2431 - val_loss: 28.7853\n",
      "Epoch 522/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3421 - val_loss: 28.6190\n",
      "Epoch 523/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7568 - val_loss: 29.8408\n",
      "Epoch 524/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.2343 - val_loss: 28.4091\n",
      "Epoch 525/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.3686 - val_loss: 28.6585\n",
      "Epoch 526/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.5239 - val_loss: 27.8321\n",
      "Epoch 527/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5078 - val_loss: 30.4220\n",
      "Epoch 528/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.4192 - val_loss: 27.9555\n",
      "Epoch 529/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7084 - val_loss: 27.7984\n",
      "Epoch 530/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3136 - val_loss: 32.3308\n",
      "Epoch 531/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.1581 - val_loss: 29.8479\n",
      "Epoch 532/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.3084 - val_loss: 29.5192\n",
      "Epoch 533/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8446 - val_loss: 27.9399\n",
      "Epoch 534/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.4125 - val_loss: 28.2936\n",
      "Epoch 535/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3967 - val_loss: 27.7499\n",
      "Epoch 536/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.0878 - val_loss: 29.8118\n",
      "Epoch 537/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.2413 - val_loss: 27.6343\n",
      "Epoch 538/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.7485 - val_loss: 30.9536\n",
      "Epoch 539/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.5893 - val_loss: 27.3929\n",
      "Epoch 540/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 37.6917 - val_loss: 27.2869\n",
      "Epoch 541/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.1155 - val_loss: 28.7319\n",
      "Epoch 542/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3701 - val_loss: 27.2207\n",
      "Epoch 543/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.4074 - val_loss: 27.6268\n",
      "Epoch 544/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.2857 - val_loss: 27.5024\n",
      "Epoch 545/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.7669 - val_loss: 34.5612\n",
      "Epoch 546/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.5274 - val_loss: 28.7232\n",
      "Epoch 547/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.8674 - val_loss: 27.3187\n",
      "Epoch 548/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.9522 - val_loss: 27.2945\n",
      "Epoch 549/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.2382 - val_loss: 28.8379\n",
      "Epoch 550/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.9753 - val_loss: 27.0179\n",
      "Epoch 551/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.9736 - val_loss: 29.7823\n",
      "Epoch 552/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3773 - val_loss: 28.2539\n",
      "Epoch 553/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7795 - val_loss: 29.5515\n",
      "Epoch 554/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.1806 - val_loss: 27.0376\n",
      "Epoch 555/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.8666 - val_loss: 27.2620\n",
      "Epoch 556/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.1657 - val_loss: 26.4881\n",
      "Epoch 557/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.4511 - val_loss: 26.9807\n",
      "Epoch 558/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.2002 - val_loss: 26.8696\n",
      "Epoch 559/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0825 - val_loss: 31.0024\n",
      "Epoch 560/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8222 - val_loss: 26.5343\n",
      "Epoch 561/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7574 - val_loss: 26.3149\n",
      "Epoch 562/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.9761 - val_loss: 28.2653\n",
      "Epoch 563/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8311 - val_loss: 26.9661\n",
      "Epoch 564/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.7877 - val_loss: 26.7994\n",
      "Epoch 565/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.9031 - val_loss: 30.6597\n",
      "Epoch 566/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.0337 - val_loss: 26.6322\n",
      "Epoch 567/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.4319 - val_loss: 26.7690\n",
      "Epoch 568/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.3220 - val_loss: 35.2386\n",
      "Epoch 569/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.9890 - val_loss: 26.6202\n",
      "Epoch 570/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6352 - val_loss: 26.6479\n",
      "Epoch 571/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.3134 - val_loss: 26.0445\n",
      "Epoch 572/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.4348 - val_loss: 27.1548\n",
      "Epoch 573/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5822 - val_loss: 27.7074\n",
      "Epoch 574/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.5080 - val_loss: 26.1660\n",
      "Epoch 575/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8061 - val_loss: 28.4874\n",
      "Epoch 576/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8452 - val_loss: 26.4547\n",
      "Epoch 577/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4530 - val_loss: 27.0879\n",
      "Epoch 578/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.7336 - val_loss: 26.7780\n",
      "Epoch 579/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.7180 - val_loss: 26.1836\n",
      "Epoch 580/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1817 - val_loss: 26.0797\n",
      "Epoch 581/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6676 - val_loss: 26.0953\n",
      "Epoch 582/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6639 - val_loss: 30.4359\n",
      "Epoch 583/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.4326 - val_loss: 28.6076\n",
      "Epoch 584/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.9324 - val_loss: 30.1057\n",
      "Epoch 585/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.9182 - val_loss: 26.4999\n",
      "Epoch 586/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.3216 - val_loss: 25.9256\n",
      "Epoch 587/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4994 - val_loss: 28.1442\n",
      "Epoch 588/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4197 - val_loss: 26.2655\n",
      "Epoch 589/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7192 - val_loss: 25.8223\n",
      "Epoch 590/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2950 - val_loss: 29.5678\n",
      "Epoch 591/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.3123 - val_loss: 25.8470\n",
      "Epoch 592/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1283 - val_loss: 26.0503\n",
      "Epoch 593/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.8985 - val_loss: 28.9598\n",
      "Epoch 594/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3808 - val_loss: 25.6885\n",
      "Epoch 595/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8071 - val_loss: 25.6590\n",
      "Epoch 596/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1437 - val_loss: 26.9602\n",
      "Epoch 597/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6908 - val_loss: 26.1924\n",
      "Epoch 598/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.4028 - val_loss: 28.0469\n",
      "Epoch 599/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.7722 - val_loss: 25.4815\n",
      "Epoch 600/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5539 - val_loss: 26.2999\n",
      "Epoch 601/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0949 - val_loss: 27.0735\n",
      "Epoch 602/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.5675 - val_loss: 25.9263\n",
      "Epoch 603/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0105 - val_loss: 26.4726\n",
      "Epoch 604/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0125 - val_loss: 27.2646\n",
      "Epoch 605/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.3882 - val_loss: 26.2729\n",
      "Epoch 606/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8416 - val_loss: 25.1615\n",
      "Epoch 607/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6211 - val_loss: 25.1751\n",
      "Epoch 608/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6211 - val_loss: 31.9123\n",
      "Epoch 609/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.5927 - val_loss: 25.1400\n",
      "Epoch 610/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3348 - val_loss: 25.7336\n",
      "Epoch 611/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.6422 - val_loss: 25.6755\n",
      "Epoch 612/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.1787 - val_loss: 30.0745\n",
      "Epoch 613/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.2650 - val_loss: 25.9575\n",
      "Epoch 614/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.8294 - val_loss: 26.8381\n",
      "Epoch 615/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.0409 - val_loss: 25.1578\n",
      "Epoch 616/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.1052 - val_loss: 25.5041\n",
      "Epoch 617/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.8303 - val_loss: 30.5204\n",
      "Epoch 618/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4309 - val_loss: 25.2650\n",
      "Epoch 619/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1221 - val_loss: 25.5855\n",
      "Epoch 620/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.1870 - val_loss: 24.9008\n",
      "Epoch 621/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.8920 - val_loss: 27.0807\n",
      "Epoch 622/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.6352 - val_loss: 25.1030\n",
      "Epoch 623/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4685 - val_loss: 27.9002\n",
      "Epoch 624/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.4378 - val_loss: 26.2703\n",
      "Epoch 625/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6827 - val_loss: 25.4996\n",
      "Epoch 626/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5229 - val_loss: 27.4032\n",
      "Epoch 627/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.6784 - val_loss: 25.2960\n",
      "Epoch 628/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.3997 - val_loss: 25.1876\n",
      "Epoch 629/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.2563 - val_loss: 27.4891\n",
      "Epoch 630/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.2897 - val_loss: 28.0638\n",
      "Epoch 631/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.7225 - val_loss: 24.9258\n",
      "Epoch 632/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.2545 - val_loss: 24.8076\n",
      "Epoch 633/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.9716 - val_loss: 25.7158\n",
      "Epoch 634/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.7285 - val_loss: 26.2453\n",
      "Epoch 635/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.4545 - val_loss: 24.7045\n",
      "Epoch 636/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.0098 - val_loss: 26.5230\n",
      "Epoch 637/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.8228 - val_loss: 24.9849\n",
      "Epoch 638/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.4026 - val_loss: 25.7446\n",
      "Epoch 639/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.5908 - val_loss: 24.9389\n",
      "Epoch 640/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.6741 - val_loss: 25.9220\n",
      "Epoch 641/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.1381 - val_loss: 25.3367\n",
      "Epoch 642/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.7900 - val_loss: 28.7247\n",
      "Epoch 643/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.9417 - val_loss: 27.3559\n",
      "Epoch 644/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0243 - val_loss: 25.2590\n",
      "Epoch 645/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.4362 - val_loss: 26.2497\n",
      "Epoch 646/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.1425 - val_loss: 24.8162\n",
      "Epoch 647/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.9623 - val_loss: 28.6628\n",
      "Epoch 648/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.6708 - val_loss: 25.6418\n",
      "Epoch 649/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.3452 - val_loss: 25.4323\n",
      "Epoch 650/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.5490 - val_loss: 26.4276\n",
      "Epoch 651/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.7822 - val_loss: 24.5582\n",
      "Epoch 652/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.4292 - val_loss: 24.9680\n",
      "Epoch 653/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.1941 - val_loss: 25.9802\n",
      "Epoch 654/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.8830 - val_loss: 30.2990\n",
      "Epoch 655/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.7098 - val_loss: 24.5764\n",
      "Epoch 656/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.9900 - val_loss: 25.1214\n",
      "Epoch 657/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.5129 - val_loss: 25.1578\n",
      "Epoch 658/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.0799 - val_loss: 24.7042\n",
      "Epoch 659/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.0218 - val_loss: 27.6049\n",
      "Epoch 660/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.2757 - val_loss: 39.1026\n",
      "Epoch 661/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.8924 - val_loss: 24.4997\n",
      "Epoch 662/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.0826 - val_loss: 24.9088\n",
      "Epoch 663/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.6064 - val_loss: 25.2273\n",
      "Epoch 664/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.1661 - val_loss: 25.3844\n",
      "Epoch 665/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.1166 - val_loss: 25.7927\n",
      "Epoch 666/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.4686 - val_loss: 24.6189\n",
      "Epoch 667/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.3658 - val_loss: 28.1085\n",
      "Epoch 668/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.8112 - val_loss: 25.6583\n",
      "Epoch 669/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.6649 - val_loss: 24.4073\n",
      "Epoch 670/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.4278 - val_loss: 25.6912\n",
      "Epoch 671/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.9319 - val_loss: 24.9358\n",
      "Epoch 672/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.9962 - val_loss: 24.7656\n",
      "Epoch 673/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.6005 - val_loss: 26.1943\n",
      "Epoch 674/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.7978 - val_loss: 24.7615\n",
      "Epoch 675/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 31.7603 - val_loss: 24.3795\n",
      "Epoch 676/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.8332 - val_loss: 25.8973\n",
      "Epoch 677/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.8601 - val_loss: 24.6555\n",
      "Epoch 678/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.2204 - val_loss: 24.7251\n",
      "Epoch 679/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.1283 - val_loss: 25.1091\n",
      "Epoch 680/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.6536 - val_loss: 24.6639\n",
      "Epoch 681/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 31.7249 - val_loss: 24.5622\n",
      "Epoch 682/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.2938 - val_loss: 24.5421\n",
      "Epoch 683/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.0422 - val_loss: 28.2860\n",
      "Epoch 684/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.2838 - val_loss: 27.4425\n",
      "Epoch 685/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.1320 - val_loss: 26.3090\n",
      "Epoch 686/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.8815 - val_loss: 25.0707\n",
      "Epoch 687/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.7191 - val_loss: 28.0227\n",
      "Epoch 688/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.5505 - val_loss: 25.4796\n",
      "Epoch 689/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.3847 - val_loss: 27.1713\n",
      "Epoch 690/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.4357 - val_loss: 26.2591\n",
      "Epoch 691/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.2257 - val_loss: 24.5435\n",
      "Epoch 692/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 31.9891 - val_loss: 31.4727\n",
      "Epoch 693/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.3065 - val_loss: 25.0066\n",
      "Epoch 694/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.1340 - val_loss: 24.8905\n",
      "Epoch 695/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.3538 - val_loss: 30.5520\n",
      "Epoch 696/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.4095 - val_loss: 26.9722\n",
      "Epoch 697/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 31.7332 - val_loss: 24.4447\n",
      "Epoch 698/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 31.0266 - val_loss: 28.4055\n",
      "Epoch 699/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.1586 - val_loss: 25.9096\n",
      "Epoch 700/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.5328 - val_loss: 24.8445\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss = 'mean_squared_error', optimizer= 'adam')\n",
    "hist1 = model1.fit(x = x_train, y = y_train, epochs= 700, validation_split=0.2, batch_size = 32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 20)                200       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential(layers = [\n",
    "    tf.keras.layers.Dense(units = 20, activation= 'relu', use_bias= True, input_shape= (9,) ),\n",
    "    tf.keras.layers.Dense(units = 10, activation= 'relu', use_bias= True),\n",
    "    tf.keras.layers.Dense(units = 1, activation= 'relu', use_bias= True)\n",
    "])\n",
    "\n",
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 426.2219 - val_loss: 204.1241\n",
      "Epoch 2/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 190.6796 - val_loss: 166.1564\n",
      "Epoch 3/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 167.7055 - val_loss: 138.0776\n",
      "Epoch 4/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 144.1203 - val_loss: 113.9408\n",
      "Epoch 5/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 130.6572 - val_loss: 101.4362\n",
      "Epoch 6/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 118.5766 - val_loss: 95.9930\n",
      "Epoch 7/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 113.4717 - val_loss: 92.8106\n",
      "Epoch 8/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 109.0272 - val_loss: 90.9887\n",
      "Epoch 9/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 106.4835 - val_loss: 86.3675\n",
      "Epoch 10/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 101.3725 - val_loss: 82.9693\n",
      "Epoch 11/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 97.7320 - val_loss: 93.1407\n",
      "Epoch 12/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 96.3777 - val_loss: 80.9923\n",
      "Epoch 13/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 89.9473 - val_loss: 85.4743\n",
      "Epoch 14/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 93.3995 - val_loss: 84.5677\n",
      "Epoch 15/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 91.0530 - val_loss: 77.6761\n",
      "Epoch 16/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 88.1373 - val_loss: 78.9352\n",
      "Epoch 17/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 89.2829 - val_loss: 82.4524\n",
      "Epoch 18/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 99.3272 - val_loss: 107.4364\n",
      "Epoch 19/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 103.8703 - val_loss: 78.4937\n",
      "Epoch 20/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 90.1267 - val_loss: 80.2438\n",
      "Epoch 21/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 90.8577 - val_loss: 74.6586\n",
      "Epoch 22/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 89.3858 - val_loss: 74.6977\n",
      "Epoch 23/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 88.3461 - val_loss: 79.7225\n",
      "Epoch 24/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 85.2801 - val_loss: 73.8684\n",
      "Epoch 25/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 85.2249 - val_loss: 73.5466\n",
      "Epoch 26/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 84.4134 - val_loss: 73.2985\n",
      "Epoch 27/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 87.7579 - val_loss: 79.2372\n",
      "Epoch 28/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 82.5041 - val_loss: 74.8763\n",
      "Epoch 29/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 83.9957 - val_loss: 72.8232\n",
      "Epoch 30/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 83.3832 - val_loss: 75.1090\n",
      "Epoch 31/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 84.7164 - val_loss: 72.2407\n",
      "Epoch 32/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 82.7046 - val_loss: 78.0526\n",
      "Epoch 33/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 81.9784 - val_loss: 72.3959\n",
      "Epoch 34/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 82.2812 - val_loss: 71.0216\n",
      "Epoch 35/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 80.7624 - val_loss: 70.7452\n",
      "Epoch 36/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 79.7855 - val_loss: 73.0615\n",
      "Epoch 37/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 79.6745 - val_loss: 71.2155\n",
      "Epoch 38/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 83.5381 - val_loss: 70.5061\n",
      "Epoch 39/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 79.4511 - val_loss: 69.3579\n",
      "Epoch 40/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 78.1025 - val_loss: 70.3278\n",
      "Epoch 41/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 80.2294 - val_loss: 71.4804\n",
      "Epoch 42/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 82.6275 - val_loss: 68.9249\n",
      "Epoch 43/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 79.8143 - val_loss: 69.5487\n",
      "Epoch 44/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 79.0438 - val_loss: 69.1855\n",
      "Epoch 45/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.5473 - val_loss: 67.8018\n",
      "Epoch 46/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 78.9715 - val_loss: 69.2004\n",
      "Epoch 47/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 76.7633 - val_loss: 67.3662\n",
      "Epoch 48/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 77.8228 - val_loss: 73.4262\n",
      "Epoch 49/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 75.0455 - val_loss: 68.5580\n",
      "Epoch 50/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 76.4024 - val_loss: 67.1746\n",
      "Epoch 51/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 75.3990 - val_loss: 68.1121\n",
      "Epoch 52/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 75.8826 - val_loss: 65.7729\n",
      "Epoch 53/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 75.3853 - val_loss: 65.7552\n",
      "Epoch 54/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.6918 - val_loss: 71.8745\n",
      "Epoch 55/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.5524 - val_loss: 72.3804\n",
      "Epoch 56/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.2534 - val_loss: 67.9124\n",
      "Epoch 57/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.6895 - val_loss: 70.3916\n",
      "Epoch 58/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 74.0409 - val_loss: 66.2222\n",
      "Epoch 59/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.7460 - val_loss: 64.4064\n",
      "Epoch 60/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 74.0514 - val_loss: 65.6049\n",
      "Epoch 61/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 77.9272 - val_loss: 66.8821\n",
      "Epoch 62/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.2394 - val_loss: 69.5137\n",
      "Epoch 63/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 79.3267 - val_loss: 71.5032\n",
      "Epoch 64/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.9021 - val_loss: 63.2411\n",
      "Epoch 65/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.8831 - val_loss: 64.7465\n",
      "Epoch 66/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.4636 - val_loss: 63.2350\n",
      "Epoch 67/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 74.2309 - val_loss: 66.4459\n",
      "Epoch 68/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 76.2702 - val_loss: 69.2150\n",
      "Epoch 69/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 80.4062 - val_loss: 67.9846\n",
      "Epoch 70/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.0498 - val_loss: 69.3103\n",
      "Epoch 71/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 79.2761 - val_loss: 62.4938\n",
      "Epoch 72/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 77.0457 - val_loss: 69.7315\n",
      "Epoch 73/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 75.8626 - val_loss: 77.4246\n",
      "Epoch 74/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 79.4324 - val_loss: 72.8180\n",
      "Epoch 75/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 85.4971 - val_loss: 68.5745\n",
      "Epoch 76/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.1533 - val_loss: 62.8433\n",
      "Epoch 77/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.2675 - val_loss: 62.6583\n",
      "Epoch 78/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.0917 - val_loss: 61.4631\n",
      "Epoch 79/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.8519 - val_loss: 60.2723\n",
      "Epoch 80/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.5884 - val_loss: 60.6294\n",
      "Epoch 81/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.2489 - val_loss: 64.5584\n",
      "Epoch 82/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 70.7519 - val_loss: 62.8126\n",
      "Epoch 83/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.1876 - val_loss: 59.6145\n",
      "Epoch 84/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 71.7494 - val_loss: 58.4447\n",
      "Epoch 85/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 71.2067 - val_loss: 62.6522\n",
      "Epoch 86/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.1077 - val_loss: 58.3805\n",
      "Epoch 87/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.2584 - val_loss: 59.3339\n",
      "Epoch 88/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.8243 - val_loss: 58.7590\n",
      "Epoch 89/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.2171 - val_loss: 57.8605\n",
      "Epoch 90/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 73.5359 - val_loss: 60.1796\n",
      "Epoch 91/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.6097 - val_loss: 60.3582\n",
      "Epoch 92/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.3670 - val_loss: 59.8162\n",
      "Epoch 93/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 68.2612 - val_loss: 58.7674\n",
      "Epoch 94/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.5899 - val_loss: 56.8211\n",
      "Epoch 95/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.2681 - val_loss: 73.2588\n",
      "Epoch 96/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 71.0097 - val_loss: 56.5761\n",
      "Epoch 97/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.8862 - val_loss: 57.8460\n",
      "Epoch 98/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.7208 - val_loss: 57.1792\n",
      "Epoch 99/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.2547 - val_loss: 62.1013\n",
      "Epoch 100/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 69.1752 - val_loss: 60.7938\n",
      "Epoch 101/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 73.7354 - val_loss: 55.2598\n",
      "Epoch 102/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 68.4892 - val_loss: 55.1279\n",
      "Epoch 103/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.9838 - val_loss: 55.3674\n",
      "Epoch 104/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 67.1037 - val_loss: 58.8753\n",
      "Epoch 105/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.4406 - val_loss: 54.1631\n",
      "Epoch 106/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.3168 - val_loss: 58.5437\n",
      "Epoch 107/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 66.7353 - val_loss: 54.8469\n",
      "Epoch 108/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 65.1779 - val_loss: 65.1484\n",
      "Epoch 109/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 75.1832 - val_loss: 55.1606\n",
      "Epoch 110/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.9470 - val_loss: 53.1261\n",
      "Epoch 111/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 66.8934 - val_loss: 55.1034\n",
      "Epoch 112/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.8377 - val_loss: 58.7281\n",
      "Epoch 113/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.9367 - val_loss: 55.0627\n",
      "Epoch 114/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 62.7798 - val_loss: 55.9278\n",
      "Epoch 115/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 62.8864 - val_loss: 56.4701\n",
      "Epoch 116/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.2316 - val_loss: 52.3363\n",
      "Epoch 117/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.6093 - val_loss: 76.7253\n",
      "Epoch 118/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 72.9796 - val_loss: 59.5181\n",
      "Epoch 119/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 71.2804 - val_loss: 52.1887\n",
      "Epoch 120/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 67.4098 - val_loss: 54.0487\n",
      "Epoch 121/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.4572 - val_loss: 51.4940\n",
      "Epoch 122/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.5702 - val_loss: 57.1763\n",
      "Epoch 123/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.9829 - val_loss: 51.9571\n",
      "Epoch 124/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.5248 - val_loss: 57.9518\n",
      "Epoch 125/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.2745 - val_loss: 51.7899\n",
      "Epoch 126/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.1521 - val_loss: 50.3088\n",
      "Epoch 127/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.8517 - val_loss: 57.4885\n",
      "Epoch 128/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 65.2566 - val_loss: 54.5739\n",
      "Epoch 129/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.9177 - val_loss: 56.1772\n",
      "Epoch 130/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.8759 - val_loss: 56.6253\n",
      "Epoch 131/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 70.5614 - val_loss: 58.8560\n",
      "Epoch 132/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.7166 - val_loss: 52.3716\n",
      "Epoch 133/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 63.0722 - val_loss: 48.5574\n",
      "Epoch 134/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.8577 - val_loss: 55.6290\n",
      "Epoch 135/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.3392 - val_loss: 59.1962\n",
      "Epoch 136/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.8807 - val_loss: 48.2023\n",
      "Epoch 137/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.5994 - val_loss: 50.5150\n",
      "Epoch 138/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.0725 - val_loss: 47.8959\n",
      "Epoch 139/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.1196 - val_loss: 51.3906\n",
      "Epoch 140/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 64.2914 - val_loss: 47.3986\n",
      "Epoch 141/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 69.5424 - val_loss: 51.4222\n",
      "Epoch 142/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 61.5014 - val_loss: 48.7966\n",
      "Epoch 143/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 58.4544 - val_loss: 48.3726\n",
      "Epoch 144/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.9444 - val_loss: 47.2919\n",
      "Epoch 145/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.5660 - val_loss: 54.2962\n",
      "Epoch 146/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 61.1686 - val_loss: 46.5899\n",
      "Epoch 147/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 62.5950 - val_loss: 61.2515\n",
      "Epoch 148/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.3385 - val_loss: 50.6642\n",
      "Epoch 149/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 57.7606 - val_loss: 49.9186\n",
      "Epoch 150/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.6508 - val_loss: 68.1123\n",
      "Epoch 151/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 64.4052 - val_loss: 57.2189\n",
      "Epoch 152/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.5852 - val_loss: 49.5752\n",
      "Epoch 153/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 58.0956 - val_loss: 55.5827\n",
      "Epoch 154/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.5603 - val_loss: 51.3851\n",
      "Epoch 155/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 60.8223 - val_loss: 59.4175\n",
      "Epoch 156/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 62.0984 - val_loss: 45.9626\n",
      "Epoch 157/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.1083 - val_loss: 46.4334\n",
      "Epoch 158/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.1729 - val_loss: 46.6320\n",
      "Epoch 159/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.7987 - val_loss: 44.6949\n",
      "Epoch 160/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.6601 - val_loss: 45.5242\n",
      "Epoch 161/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.9947 - val_loss: 45.1199\n",
      "Epoch 162/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.6065 - val_loss: 44.1638\n",
      "Epoch 163/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.1738 - val_loss: 44.2449\n",
      "Epoch 164/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.6529 - val_loss: 44.9465\n",
      "Epoch 165/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.4165 - val_loss: 45.3904\n",
      "Epoch 166/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.2630 - val_loss: 45.0609\n",
      "Epoch 167/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.7363 - val_loss: 43.6985\n",
      "Epoch 168/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 53.8484 - val_loss: 43.9721\n",
      "Epoch 169/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.7365 - val_loss: 44.1293\n",
      "Epoch 170/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.6495 - val_loss: 46.4418\n",
      "Epoch 171/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.6015 - val_loss: 52.3192\n",
      "Epoch 172/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.4655 - val_loss: 43.1157\n",
      "Epoch 173/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 51.8595 - val_loss: 43.1738\n",
      "Epoch 174/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.3338 - val_loss: 43.6327\n",
      "Epoch 175/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.8918 - val_loss: 44.3788\n",
      "Epoch 176/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.7159 - val_loss: 47.9801\n",
      "Epoch 177/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.5562 - val_loss: 42.8507\n",
      "Epoch 178/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 53.2620 - val_loss: 45.0550\n",
      "Epoch 179/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.7117 - val_loss: 45.2952\n",
      "Epoch 180/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.9417 - val_loss: 42.8452\n",
      "Epoch 181/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.2290 - val_loss: 44.8809\n",
      "Epoch 182/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.4813 - val_loss: 42.1727\n",
      "Epoch 183/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.7980 - val_loss: 47.6197\n",
      "Epoch 184/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 52.1860 - val_loss: 47.7854\n",
      "Epoch 185/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 51.0902 - val_loss: 42.9957\n",
      "Epoch 186/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.9714 - val_loss: 43.8606\n",
      "Epoch 187/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.2450 - val_loss: 41.2696\n",
      "Epoch 188/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.8543 - val_loss: 42.4476\n",
      "Epoch 189/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.8210 - val_loss: 41.2298\n",
      "Epoch 190/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 54.0345 - val_loss: 41.3962\n",
      "Epoch 191/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 56.5783 - val_loss: 47.6176\n",
      "Epoch 192/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 52.6427 - val_loss: 41.1330\n",
      "Epoch 193/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.1783 - val_loss: 40.9248\n",
      "Epoch 194/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.2753 - val_loss: 44.7769\n",
      "Epoch 195/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.3393 - val_loss: 42.7058\n",
      "Epoch 196/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.0617 - val_loss: 46.1327\n",
      "Epoch 197/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.4007 - val_loss: 43.3879\n",
      "Epoch 198/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.2186 - val_loss: 40.0774\n",
      "Epoch 199/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 56.3726 - val_loss: 42.6929\n",
      "Epoch 200/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.6628 - val_loss: 39.8858\n",
      "Epoch 201/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.9794 - val_loss: 41.0552\n",
      "Epoch 202/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 51.2493 - val_loss: 41.7682\n",
      "Epoch 203/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.2720 - val_loss: 40.3994\n",
      "Epoch 204/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.9790 - val_loss: 43.7918\n",
      "Epoch 205/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.3358 - val_loss: 40.7888\n",
      "Epoch 206/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.3451 - val_loss: 40.9927\n",
      "Epoch 207/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.9229 - val_loss: 44.2668\n",
      "Epoch 208/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.3612 - val_loss: 41.7725\n",
      "Epoch 209/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.3502 - val_loss: 40.9466\n",
      "Epoch 210/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.1428 - val_loss: 46.4797\n",
      "Epoch 211/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.4297 - val_loss: 39.3556\n",
      "Epoch 212/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.0795 - val_loss: 40.8276\n",
      "Epoch 213/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.4977 - val_loss: 43.2421\n",
      "Epoch 214/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 48.8911 - val_loss: 39.0975\n",
      "Epoch 215/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.5311 - val_loss: 39.1418\n",
      "Epoch 216/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.9318 - val_loss: 40.3343\n",
      "Epoch 217/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.5157 - val_loss: 38.6512\n",
      "Epoch 218/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.2511 - val_loss: 40.2665\n",
      "Epoch 219/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.4252 - val_loss: 38.3233\n",
      "Epoch 220/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.0321 - val_loss: 39.7992\n",
      "Epoch 221/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.9240 - val_loss: 45.7929\n",
      "Epoch 222/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.6091 - val_loss: 40.1590\n",
      "Epoch 223/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.8382 - val_loss: 44.4678\n",
      "Epoch 224/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.8907 - val_loss: 46.5751\n",
      "Epoch 225/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 53.8516 - val_loss: 49.7867\n",
      "Epoch 226/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 59.8587 - val_loss: 53.9856\n",
      "Epoch 227/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 52.5210 - val_loss: 42.3751\n",
      "Epoch 228/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.6389 - val_loss: 38.3662\n",
      "Epoch 229/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.8545 - val_loss: 39.2316\n",
      "Epoch 230/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.3636 - val_loss: 38.0426\n",
      "Epoch 231/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.4574 - val_loss: 45.4122\n",
      "Epoch 232/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.8317 - val_loss: 40.7687\n",
      "Epoch 233/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 46.5744 - val_loss: 40.8850\n",
      "Epoch 234/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.1996 - val_loss: 40.5354\n",
      "Epoch 235/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.4732 - val_loss: 43.1487\n",
      "Epoch 236/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.1034 - val_loss: 57.7231\n",
      "Epoch 237/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 52.6005 - val_loss: 45.3997\n",
      "Epoch 238/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.2082 - val_loss: 40.6277\n",
      "Epoch 239/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.7125 - val_loss: 50.0348\n",
      "Epoch 240/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.3084 - val_loss: 53.0985\n",
      "Epoch 241/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.3521 - val_loss: 45.2979\n",
      "Epoch 242/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 50.8914 - val_loss: 43.2172\n",
      "Epoch 243/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.3213 - val_loss: 40.7994\n",
      "Epoch 244/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 47.0650 - val_loss: 36.9817\n",
      "Epoch 245/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.5525 - val_loss: 36.7983\n",
      "Epoch 246/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.4110 - val_loss: 37.5094\n",
      "Epoch 247/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.6285 - val_loss: 38.8480\n",
      "Epoch 248/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 47.5396 - val_loss: 52.3216\n",
      "Epoch 249/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.2358 - val_loss: 43.5559\n",
      "Epoch 250/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2418 - val_loss: 36.5771\n",
      "Epoch 251/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.1424 - val_loss: 39.2747\n",
      "Epoch 252/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.9193 - val_loss: 37.0072\n",
      "Epoch 253/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.7107 - val_loss: 40.6246\n",
      "Epoch 254/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.0507 - val_loss: 41.4375\n",
      "Epoch 255/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 49.0769 - val_loss: 45.1348\n",
      "Epoch 256/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.9800 - val_loss: 38.6736\n",
      "Epoch 257/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.1012 - val_loss: 36.6311\n",
      "Epoch 258/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 43.1959 - val_loss: 36.4798\n",
      "Epoch 259/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.5330 - val_loss: 41.0365\n",
      "Epoch 260/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.6661 - val_loss: 36.2864\n",
      "Epoch 261/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.5583 - val_loss: 41.6539\n",
      "Epoch 262/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.2523 - val_loss: 42.0855\n",
      "Epoch 263/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.8565 - val_loss: 36.8543\n",
      "Epoch 264/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.0454 - val_loss: 49.7340\n",
      "Epoch 265/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.9529 - val_loss: 36.7044\n",
      "Epoch 266/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.0333 - val_loss: 36.0018\n",
      "Epoch 267/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.4753 - val_loss: 39.1936\n",
      "Epoch 268/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.7829 - val_loss: 35.9029\n",
      "Epoch 269/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.1240 - val_loss: 38.2906\n",
      "Epoch 270/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.8095 - val_loss: 36.9478\n",
      "Epoch 271/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.8672 - val_loss: 38.7660\n",
      "Epoch 272/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.5099 - val_loss: 35.8929\n",
      "Epoch 273/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.2825 - val_loss: 35.7165\n",
      "Epoch 274/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.3382 - val_loss: 35.5846\n",
      "Epoch 275/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2176 - val_loss: 40.0934\n",
      "Epoch 276/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.9436 - val_loss: 37.3302\n",
      "Epoch 277/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.0269 - val_loss: 36.4284\n",
      "Epoch 278/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.3788 - val_loss: 35.4198\n",
      "Epoch 279/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.3838 - val_loss: 45.8085\n",
      "Epoch 280/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.5874 - val_loss: 35.5390\n",
      "Epoch 281/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.1729 - val_loss: 38.4698\n",
      "Epoch 282/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.6545 - val_loss: 35.2530\n",
      "Epoch 283/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.7577 - val_loss: 35.8332\n",
      "Epoch 284/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.9414 - val_loss: 35.2986\n",
      "Epoch 285/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.2534 - val_loss: 49.6764\n",
      "Epoch 286/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.0800 - val_loss: 43.1276\n",
      "Epoch 287/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.3762 - val_loss: 39.3028\n",
      "Epoch 288/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.7823 - val_loss: 35.7783\n",
      "Epoch 289/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.8705 - val_loss: 45.3571\n",
      "Epoch 290/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.3188 - val_loss: 36.6198\n",
      "Epoch 291/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.7713 - val_loss: 35.6251\n",
      "Epoch 292/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.2651 - val_loss: 35.4835\n",
      "Epoch 293/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.7282 - val_loss: 37.5480\n",
      "Epoch 294/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.5294 - val_loss: 35.5905\n",
      "Epoch 295/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2154 - val_loss: 52.2690\n",
      "Epoch 296/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.9035 - val_loss: 42.7681\n",
      "Epoch 297/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3688 - val_loss: 35.4225\n",
      "Epoch 298/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.4818 - val_loss: 34.9001\n",
      "Epoch 299/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3311 - val_loss: 35.2682\n",
      "Epoch 300/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3107 - val_loss: 36.5466\n",
      "Epoch 301/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.1421 - val_loss: 34.7217\n",
      "Epoch 302/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0323 - val_loss: 36.5090\n",
      "Epoch 303/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.7390 - val_loss: 38.6857\n",
      "Epoch 304/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 44.8160 - val_loss: 38.1312\n",
      "Epoch 305/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.8960 - val_loss: 35.8437\n",
      "Epoch 306/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.7426 - val_loss: 34.7434\n",
      "Epoch 307/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.4372 - val_loss: 36.4913\n",
      "Epoch 308/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.7942 - val_loss: 34.4773\n",
      "Epoch 309/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.6392 - val_loss: 34.5954\n",
      "Epoch 310/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.2497 - val_loss: 36.1014\n",
      "Epoch 311/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.6078 - val_loss: 34.9289\n",
      "Epoch 312/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3855 - val_loss: 38.6598\n",
      "Epoch 313/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0665 - val_loss: 34.8054\n",
      "Epoch 314/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.9542 - val_loss: 37.5805\n",
      "Epoch 315/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 50.2243 - val_loss: 34.8103\n",
      "Epoch 316/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.2407 - val_loss: 35.4426\n",
      "Epoch 317/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 46.7475 - val_loss: 35.8044\n",
      "Epoch 318/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.9816 - val_loss: 44.5105\n",
      "Epoch 319/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.2261 - val_loss: 39.0029\n",
      "Epoch 320/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.6965 - val_loss: 39.7975\n",
      "Epoch 321/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.1392 - val_loss: 36.6790\n",
      "Epoch 322/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7372 - val_loss: 34.2673\n",
      "Epoch 323/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.4689 - val_loss: 45.4269\n",
      "Epoch 324/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2816 - val_loss: 42.5785\n",
      "Epoch 325/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.5055 - val_loss: 53.5733\n",
      "Epoch 326/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.0035 - val_loss: 38.4056\n",
      "Epoch 327/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.2601 - val_loss: 56.7615\n",
      "Epoch 328/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.8981 - val_loss: 46.2081\n",
      "Epoch 329/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.8574 - val_loss: 43.5440\n",
      "Epoch 330/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.1325 - val_loss: 33.6897\n",
      "Epoch 331/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.2284 - val_loss: 34.8023\n",
      "Epoch 332/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.1169 - val_loss: 42.7189\n",
      "Epoch 333/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.8002 - val_loss: 52.7394\n",
      "Epoch 334/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.2515 - val_loss: 39.2399\n",
      "Epoch 335/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.8066 - val_loss: 33.7186\n",
      "Epoch 336/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.7825 - val_loss: 38.8152\n",
      "Epoch 337/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2966 - val_loss: 41.1766\n",
      "Epoch 338/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.9825 - val_loss: 33.6764\n",
      "Epoch 339/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0668 - val_loss: 35.8489\n",
      "Epoch 340/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.8383 - val_loss: 39.6863\n",
      "Epoch 341/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.5690 - val_loss: 35.6940\n",
      "Epoch 342/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.6958 - val_loss: 33.7066\n",
      "Epoch 343/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7689 - val_loss: 44.0789\n",
      "Epoch 344/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.4242 - val_loss: 36.8421\n",
      "Epoch 345/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.3861 - val_loss: 34.1822\n",
      "Epoch 346/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.9760 - val_loss: 38.8615\n",
      "Epoch 347/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.4581 - val_loss: 33.5753\n",
      "Epoch 348/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.1431 - val_loss: 35.2855\n",
      "Epoch 349/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 45.3774 - val_loss: 33.5778\n",
      "Epoch 350/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.8977 - val_loss: 44.9587\n",
      "Epoch 351/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.8247 - val_loss: 44.7194\n",
      "Epoch 352/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.2232 - val_loss: 35.1121\n",
      "Epoch 353/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.0550 - val_loss: 35.7150\n",
      "Epoch 354/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.5917 - val_loss: 43.6671\n",
      "Epoch 355/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3495 - val_loss: 32.9279\n",
      "Epoch 356/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7913 - val_loss: 33.0672\n",
      "Epoch 357/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.0601 - val_loss: 46.2888\n",
      "Epoch 358/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.5560 - val_loss: 35.4447\n",
      "Epoch 359/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 47.5654 - val_loss: 32.6430\n",
      "Epoch 360/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.4463 - val_loss: 33.2410\n",
      "Epoch 361/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0144 - val_loss: 33.6185\n",
      "Epoch 362/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.0535 - val_loss: 36.4268\n",
      "Epoch 363/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.1716 - val_loss: 33.2223\n",
      "Epoch 364/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5670 - val_loss: 33.6446\n",
      "Epoch 365/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5003 - val_loss: 35.7685\n",
      "Epoch 366/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3064 - val_loss: 32.5290\n",
      "Epoch 367/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.1364 - val_loss: 46.7439\n",
      "Epoch 368/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.9015 - val_loss: 38.5480\n",
      "Epoch 369/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.3147 - val_loss: 32.3949\n",
      "Epoch 370/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2359 - val_loss: 32.6567\n",
      "Epoch 371/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.9080 - val_loss: 33.3366\n",
      "Epoch 372/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.3227 - val_loss: 34.1988\n",
      "Epoch 373/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.1667 - val_loss: 32.0710\n",
      "Epoch 374/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.2529 - val_loss: 35.7879\n",
      "Epoch 375/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.4382 - val_loss: 39.2085\n",
      "Epoch 376/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.0237 - val_loss: 31.8367\n",
      "Epoch 377/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.8527 - val_loss: 40.8999\n",
      "Epoch 378/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.8236 - val_loss: 34.4677\n",
      "Epoch 379/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.9375 - val_loss: 31.6055\n",
      "Epoch 380/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.8001 - val_loss: 32.5987\n",
      "Epoch 381/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3263 - val_loss: 33.9330\n",
      "Epoch 382/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.1708 - val_loss: 32.5033\n",
      "Epoch 383/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.2441 - val_loss: 31.5634\n",
      "Epoch 384/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5820 - val_loss: 31.8615\n",
      "Epoch 385/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.8322 - val_loss: 35.7178\n",
      "Epoch 386/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.0313 - val_loss: 31.8648\n",
      "Epoch 387/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.0191 - val_loss: 38.2295\n",
      "Epoch 388/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2176 - val_loss: 36.6158\n",
      "Epoch 389/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.9615 - val_loss: 32.0902\n",
      "Epoch 390/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.8665 - val_loss: 30.9661\n",
      "Epoch 391/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.4731 - val_loss: 41.7270\n",
      "Epoch 392/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.6835 - val_loss: 32.0021\n",
      "Epoch 393/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.8857 - val_loss: 35.2197\n",
      "Epoch 394/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 48.4130 - val_loss: 45.1686\n",
      "Epoch 395/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.8866 - val_loss: 32.1523\n",
      "Epoch 396/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5895 - val_loss: 32.4793\n",
      "Epoch 397/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.2517 - val_loss: 34.3687\n",
      "Epoch 398/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.5403 - val_loss: 33.8304\n",
      "Epoch 399/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.4998 - val_loss: 36.5383\n",
      "Epoch 400/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.6628 - val_loss: 32.4471\n",
      "Epoch 401/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.0864 - val_loss: 30.7851\n",
      "Epoch 402/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8639 - val_loss: 30.9683\n",
      "Epoch 403/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.2607 - val_loss: 38.4765\n",
      "Epoch 404/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.6798 - val_loss: 37.6295\n",
      "Epoch 405/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5333 - val_loss: 36.1743\n",
      "Epoch 406/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.4952 - val_loss: 34.0814\n",
      "Epoch 407/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.2493 - val_loss: 31.2585\n",
      "Epoch 408/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.2603 - val_loss: 30.9561\n",
      "Epoch 409/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.0786 - val_loss: 37.0958\n",
      "Epoch 410/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.9179 - val_loss: 33.1506\n",
      "Epoch 411/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.0418 - val_loss: 32.1415\n",
      "Epoch 412/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.6513 - val_loss: 38.3211\n",
      "Epoch 413/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5884 - val_loss: 30.3815\n",
      "Epoch 414/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.4293 - val_loss: 32.0452\n",
      "Epoch 415/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7478 - val_loss: 39.6513\n",
      "Epoch 416/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7013 - val_loss: 33.2158\n",
      "Epoch 417/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.7833 - val_loss: 31.1771\n",
      "Epoch 418/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.1712 - val_loss: 35.5962\n",
      "Epoch 419/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5429 - val_loss: 35.7588\n",
      "Epoch 420/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.0041 - val_loss: 43.6022\n",
      "Epoch 421/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 48.3721 - val_loss: 34.7460\n",
      "Epoch 422/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.1689 - val_loss: 32.0681\n",
      "Epoch 423/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.1841 - val_loss: 35.1951\n",
      "Epoch 424/700\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 36.4539 - val_loss: 33.9233\n",
      "Epoch 425/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.0707 - val_loss: 31.9975\n",
      "Epoch 426/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.1871 - val_loss: 49.0852\n",
      "Epoch 427/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.2745 - val_loss: 31.0988\n",
      "Epoch 428/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.2376 - val_loss: 31.8178\n",
      "Epoch 429/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3272 - val_loss: 31.1999\n",
      "Epoch 430/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0214 - val_loss: 31.0638\n",
      "Epoch 431/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7131 - val_loss: 30.4853\n",
      "Epoch 432/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 37.8207 - val_loss: 31.3286\n",
      "Epoch 433/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.7205 - val_loss: 40.0502\n",
      "Epoch 434/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.3251 - val_loss: 37.6583\n",
      "Epoch 435/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.1520 - val_loss: 32.7907\n",
      "Epoch 436/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2926 - val_loss: 30.2166\n",
      "Epoch 437/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8250 - val_loss: 30.0903\n",
      "Epoch 438/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8720 - val_loss: 30.3927\n",
      "Epoch 439/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8737 - val_loss: 32.5661\n",
      "Epoch 440/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7823 - val_loss: 30.5111\n",
      "Epoch 441/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3477 - val_loss: 30.6625\n",
      "Epoch 442/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.2896 - val_loss: 32.2563\n",
      "Epoch 443/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.5157 - val_loss: 35.5633\n",
      "Epoch 444/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.2246 - val_loss: 54.3077\n",
      "Epoch 445/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.8993 - val_loss: 29.8461\n",
      "Epoch 446/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8264 - val_loss: 31.5455\n",
      "Epoch 447/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6060 - val_loss: 31.8111\n",
      "Epoch 448/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.3779 - val_loss: 33.4954\n",
      "Epoch 449/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.5872 - val_loss: 42.1196\n",
      "Epoch 450/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8932 - val_loss: 31.3391\n",
      "Epoch 451/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.3405 - val_loss: 29.9279\n",
      "Epoch 452/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7280 - val_loss: 32.0967\n",
      "Epoch 453/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.5842 - val_loss: 32.4051\n",
      "Epoch 454/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.3287 - val_loss: 35.8193\n",
      "Epoch 455/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.8603 - val_loss: 31.4783\n",
      "Epoch 456/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 41.5452 - val_loss: 34.7167\n",
      "Epoch 457/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.3050 - val_loss: 38.3937\n",
      "Epoch 458/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.9140 - val_loss: 37.9981\n",
      "Epoch 459/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3621 - val_loss: 31.5757\n",
      "Epoch 460/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.2600 - val_loss: 32.0186\n",
      "Epoch 461/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.4549 - val_loss: 46.6187\n",
      "Epoch 462/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.2993 - val_loss: 47.6343\n",
      "Epoch 463/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.6988 - val_loss: 39.2220\n",
      "Epoch 464/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.4645 - val_loss: 54.3947\n",
      "Epoch 465/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.2529 - val_loss: 32.5736\n",
      "Epoch 466/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.6181 - val_loss: 30.2658\n",
      "Epoch 467/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3700 - val_loss: 31.3706\n",
      "Epoch 468/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.8470 - val_loss: 32.1717\n",
      "Epoch 469/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.9044 - val_loss: 29.6315\n",
      "Epoch 470/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.8147 - val_loss: 30.7863\n",
      "Epoch 471/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0168 - val_loss: 29.4409\n",
      "Epoch 472/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.4474 - val_loss: 30.9843\n",
      "Epoch 473/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5006 - val_loss: 29.4848\n",
      "Epoch 474/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.2306 - val_loss: 29.6040\n",
      "Epoch 475/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7994 - val_loss: 29.7100\n",
      "Epoch 476/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2153 - val_loss: 31.2493\n",
      "Epoch 477/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.6948 - val_loss: 33.4729\n",
      "Epoch 478/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.4271 - val_loss: 39.5307\n",
      "Epoch 479/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.1149 - val_loss: 33.9133\n",
      "Epoch 480/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.7477 - val_loss: 30.6826\n",
      "Epoch 481/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.1838 - val_loss: 29.8088\n",
      "Epoch 482/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4762 - val_loss: 29.6541\n",
      "Epoch 483/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5705 - val_loss: 29.5378\n",
      "Epoch 484/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.8846 - val_loss: 29.5646\n",
      "Epoch 485/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2888 - val_loss: 29.6744\n",
      "Epoch 486/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6265 - val_loss: 30.0309\n",
      "Epoch 487/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0510 - val_loss: 31.1048\n",
      "Epoch 488/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6556 - val_loss: 29.2427\n",
      "Epoch 489/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.3968 - val_loss: 29.5270\n",
      "Epoch 490/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.0601 - val_loss: 30.2862\n",
      "Epoch 491/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.0982 - val_loss: 29.9424\n",
      "Epoch 492/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.1575 - val_loss: 31.7165\n",
      "Epoch 493/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.2148 - val_loss: 31.8241\n",
      "Epoch 494/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.9913 - val_loss: 33.3826\n",
      "Epoch 495/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8507 - val_loss: 29.6032\n",
      "Epoch 496/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7134 - val_loss: 30.9022\n",
      "Epoch 497/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.4545 - val_loss: 29.6688\n",
      "Epoch 498/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 39.6622 - val_loss: 31.1442\n",
      "Epoch 499/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6482 - val_loss: 30.5475\n",
      "Epoch 500/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.2194 - val_loss: 30.0867\n",
      "Epoch 501/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.9583 - val_loss: 29.7619\n",
      "Epoch 502/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.5543 - val_loss: 30.2402\n",
      "Epoch 503/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.6324 - val_loss: 30.2905\n",
      "Epoch 504/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.7106 - val_loss: 30.5972\n",
      "Epoch 505/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8251 - val_loss: 29.3203\n",
      "Epoch 506/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.2122 - val_loss: 32.5668\n",
      "Epoch 507/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0927 - val_loss: 29.5549\n",
      "Epoch 508/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5187 - val_loss: 32.5290\n",
      "Epoch 509/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0724 - val_loss: 32.2316\n",
      "Epoch 510/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.5696 - val_loss: 30.1409\n",
      "Epoch 511/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.5319 - val_loss: 29.2181\n",
      "Epoch 512/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.2642 - val_loss: 33.9605\n",
      "Epoch 513/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 42.9551 - val_loss: 30.1517\n",
      "Epoch 514/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2898 - val_loss: 30.6132\n",
      "Epoch 515/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3153 - val_loss: 30.1926\n",
      "Epoch 516/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6420 - val_loss: 30.5018\n",
      "Epoch 517/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1695 - val_loss: 31.8319\n",
      "Epoch 518/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1367 - val_loss: 29.6565\n",
      "Epoch 519/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0662 - val_loss: 29.5044\n",
      "Epoch 520/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.9424 - val_loss: 29.9608\n",
      "Epoch 521/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.4716 - val_loss: 36.9067\n",
      "Epoch 522/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8636 - val_loss: 29.8512\n",
      "Epoch 523/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.7194 - val_loss: 29.2492\n",
      "Epoch 524/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.6853 - val_loss: 30.1125\n",
      "Epoch 525/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.7648 - val_loss: 30.5380\n",
      "Epoch 526/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 41.8843 - val_loss: 40.8615\n",
      "Epoch 527/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 42.8713 - val_loss: 30.0866\n",
      "Epoch 528/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.1345 - val_loss: 29.8367\n",
      "Epoch 529/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.2676 - val_loss: 29.5466\n",
      "Epoch 530/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.5109 - val_loss: 40.9210\n",
      "Epoch 531/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8295 - val_loss: 30.6697\n",
      "Epoch 532/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.7013 - val_loss: 30.6246\n",
      "Epoch 533/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5172 - val_loss: 32.8622\n",
      "Epoch 534/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7073 - val_loss: 29.6323\n",
      "Epoch 535/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5013 - val_loss: 31.3561\n",
      "Epoch 536/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7972 - val_loss: 39.7200\n",
      "Epoch 537/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.6834 - val_loss: 30.0088\n",
      "Epoch 538/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6792 - val_loss: 47.3678\n",
      "Epoch 539/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5411 - val_loss: 34.2445\n",
      "Epoch 540/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0409 - val_loss: 30.0509\n",
      "Epoch 541/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7712 - val_loss: 32.5735\n",
      "Epoch 542/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.3801 - val_loss: 31.4851\n",
      "Epoch 543/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.7111 - val_loss: 30.5384\n",
      "Epoch 544/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.4481 - val_loss: 30.3971\n",
      "Epoch 545/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.0471 - val_loss: 29.4726\n",
      "Epoch 546/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 55.3369 - val_loss: 34.1142\n",
      "Epoch 547/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.5919 - val_loss: 35.9516\n",
      "Epoch 548/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.3132 - val_loss: 33.1610\n",
      "Epoch 549/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.9764 - val_loss: 39.9347\n",
      "Epoch 550/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.2568 - val_loss: 35.8898\n",
      "Epoch 551/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.7027 - val_loss: 35.1371\n",
      "Epoch 552/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.9970 - val_loss: 37.1205\n",
      "Epoch 553/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.9808 - val_loss: 38.0765\n",
      "Epoch 554/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.7254 - val_loss: 35.5446\n",
      "Epoch 555/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5912 - val_loss: 29.8120\n",
      "Epoch 556/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6098 - val_loss: 29.5626\n",
      "Epoch 557/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.2442 - val_loss: 35.4501\n",
      "Epoch 558/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.2703 - val_loss: 34.2785\n",
      "Epoch 559/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.6113 - val_loss: 29.7322\n",
      "Epoch 560/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.9732 - val_loss: 32.9129\n",
      "Epoch 561/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2752 - val_loss: 33.3576\n",
      "Epoch 562/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6165 - val_loss: 37.5639\n",
      "Epoch 563/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3910 - val_loss: 42.7338\n",
      "Epoch 564/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.7849 - val_loss: 29.9195\n",
      "Epoch 565/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.7688 - val_loss: 29.0963\n",
      "Epoch 566/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0994 - val_loss: 34.9000\n",
      "Epoch 567/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3507 - val_loss: 29.7551\n",
      "Epoch 568/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8760 - val_loss: 30.4170\n",
      "Epoch 569/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8971 - val_loss: 35.8552\n",
      "Epoch 570/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3057 - val_loss: 40.5504\n",
      "Epoch 571/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.8000 - val_loss: 29.4734\n",
      "Epoch 572/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.0736 - val_loss: 32.4954\n",
      "Epoch 573/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.2818 - val_loss: 30.8301\n",
      "Epoch 574/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1711 - val_loss: 32.7854\n",
      "Epoch 575/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.3917 - val_loss: 31.9107\n",
      "Epoch 576/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8641 - val_loss: 29.6427\n",
      "Epoch 577/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.4051 - val_loss: 29.4736\n",
      "Epoch 578/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.4322 - val_loss: 30.7585\n",
      "Epoch 579/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 37.6927 - val_loss: 38.2455\n",
      "Epoch 580/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.1677 - val_loss: 32.5485\n",
      "Epoch 581/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.7743 - val_loss: 30.0201\n",
      "Epoch 582/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.5104 - val_loss: 30.5003\n",
      "Epoch 583/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3924 - val_loss: 29.6772\n",
      "Epoch 584/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0543 - val_loss: 30.2869\n",
      "Epoch 585/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.6557 - val_loss: 29.8980\n",
      "Epoch 586/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.9498 - val_loss: 36.2996\n",
      "Epoch 587/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.9363 - val_loss: 30.4780\n",
      "Epoch 588/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.1194 - val_loss: 32.1913\n",
      "Epoch 589/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.0737 - val_loss: 38.3226\n",
      "Epoch 590/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.6431 - val_loss: 29.4451\n",
      "Epoch 591/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.5275 - val_loss: 32.0265\n",
      "Epoch 592/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.3159 - val_loss: 34.4838\n",
      "Epoch 593/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0324 - val_loss: 35.7605\n",
      "Epoch 594/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.4103 - val_loss: 34.0248\n",
      "Epoch 595/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.9907 - val_loss: 31.9575\n",
      "Epoch 596/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.8168 - val_loss: 30.0853\n",
      "Epoch 597/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.5549 - val_loss: 30.6057\n",
      "Epoch 598/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.1953 - val_loss: 31.0763\n",
      "Epoch 599/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.8791 - val_loss: 38.6203\n",
      "Epoch 600/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.4830 - val_loss: 32.4817\n",
      "Epoch 601/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8656 - val_loss: 29.4601\n",
      "Epoch 602/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.9401 - val_loss: 40.3262\n",
      "Epoch 603/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.1388 - val_loss: 29.6627\n",
      "Epoch 604/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2800 - val_loss: 31.6579\n",
      "Epoch 605/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.6059 - val_loss: 29.0491\n",
      "Epoch 606/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.7009 - val_loss: 45.7843\n",
      "Epoch 607/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.4440 - val_loss: 38.8837\n",
      "Epoch 608/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.8178 - val_loss: 41.4834\n",
      "Epoch 609/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.9365 - val_loss: 44.6978\n",
      "Epoch 610/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.7948 - val_loss: 51.5732\n",
      "Epoch 611/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 46.7699 - val_loss: 29.7213\n",
      "Epoch 612/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.5123 - val_loss: 32.0938\n",
      "Epoch 613/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.3577 - val_loss: 31.1009\n",
      "Epoch 614/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 41.6681 - val_loss: 33.0224\n",
      "Epoch 615/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8013 - val_loss: 29.3085\n",
      "Epoch 616/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1985 - val_loss: 29.5154\n",
      "Epoch 617/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.3747 - val_loss: 34.7280\n",
      "Epoch 618/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.6369 - val_loss: 34.9591\n",
      "Epoch 619/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6673 - val_loss: 41.8888\n",
      "Epoch 620/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.5804 - val_loss: 32.8693\n",
      "Epoch 621/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.1669 - val_loss: 30.1756\n",
      "Epoch 622/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.2440 - val_loss: 30.3826\n",
      "Epoch 623/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.7265 - val_loss: 31.1651\n",
      "Epoch 624/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.5880 - val_loss: 31.8560\n",
      "Epoch 625/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6763 - val_loss: 29.9221\n",
      "Epoch 626/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.8753 - val_loss: 29.5958\n",
      "Epoch 627/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0943 - val_loss: 29.9832\n",
      "Epoch 628/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.6957 - val_loss: 29.3917\n",
      "Epoch 629/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3558 - val_loss: 32.4960\n",
      "Epoch 630/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.9658 - val_loss: 31.4480\n",
      "Epoch 631/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.8842 - val_loss: 30.9645\n",
      "Epoch 632/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.8208 - val_loss: 31.3779\n",
      "Epoch 633/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.2601 - val_loss: 29.7021\n",
      "Epoch 634/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.5724 - val_loss: 34.6287\n",
      "Epoch 635/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.1432 - val_loss: 30.0573\n",
      "Epoch 636/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6026 - val_loss: 35.2059\n",
      "Epoch 637/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.6530 - val_loss: 38.5622\n",
      "Epoch 638/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.0839 - val_loss: 39.8107\n",
      "Epoch 639/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.8371 - val_loss: 32.3212\n",
      "Epoch 640/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.8797 - val_loss: 29.4597\n",
      "Epoch 641/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.4877 - val_loss: 29.2184\n",
      "Epoch 642/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2083 - val_loss: 36.9718\n",
      "Epoch 643/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0943 - val_loss: 50.6797\n",
      "Epoch 644/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.7957 - val_loss: 47.2523\n",
      "Epoch 645/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.3621 - val_loss: 52.9999\n",
      "Epoch 646/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.9857 - val_loss: 30.7813\n",
      "Epoch 647/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.7652 - val_loss: 36.6560\n",
      "Epoch 648/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.7242 - val_loss: 33.0086\n",
      "Epoch 649/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 32.9334 - val_loss: 32.4689\n",
      "Epoch 650/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.0281 - val_loss: 43.2857\n",
      "Epoch 651/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.4183 - val_loss: 33.4838\n",
      "Epoch 652/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.1095 - val_loss: 32.3053\n",
      "Epoch 653/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.1710 - val_loss: 29.4551\n",
      "Epoch 654/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.6316 - val_loss: 32.5363\n",
      "Epoch 655/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.1098 - val_loss: 30.3962\n",
      "Epoch 656/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.1464 - val_loss: 30.2902\n",
      "Epoch 657/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.0843 - val_loss: 29.6716\n",
      "Epoch 658/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.1387 - val_loss: 43.7121\n",
      "Epoch 659/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.1044 - val_loss: 36.8816\n",
      "Epoch 660/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 43.6731 - val_loss: 30.1300\n",
      "Epoch 661/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 49.2330 - val_loss: 36.3694\n",
      "Epoch 662/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.1450 - val_loss: 46.0284\n",
      "Epoch 663/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5212 - val_loss: 41.3410\n",
      "Epoch 664/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.5482 - val_loss: 32.5970\n",
      "Epoch 665/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3117 - val_loss: 34.8622\n",
      "Epoch 666/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.8379 - val_loss: 29.4645\n",
      "Epoch 667/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.2255 - val_loss: 31.2156\n",
      "Epoch 668/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.2316 - val_loss: 34.6084\n",
      "Epoch 669/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 40.6746 - val_loss: 50.0141\n",
      "Epoch 670/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.3468 - val_loss: 31.5609\n",
      "Epoch 671/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 33.7158 - val_loss: 29.2709\n",
      "Epoch 672/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.2844 - val_loss: 37.4535\n",
      "Epoch 673/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.0075 - val_loss: 29.3798\n",
      "Epoch 674/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.2362 - val_loss: 29.6023\n",
      "Epoch 675/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6754 - val_loss: 29.9867\n",
      "Epoch 676/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.1290 - val_loss: 33.0047\n",
      "Epoch 677/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0050 - val_loss: 30.9831\n",
      "Epoch 678/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5996 - val_loss: 30.9912\n",
      "Epoch 679/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.5715 - val_loss: 29.4660\n",
      "Epoch 680/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 40.8642 - val_loss: 29.5741\n",
      "Epoch 681/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.8029 - val_loss: 29.1803\n",
      "Epoch 682/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.7215 - val_loss: 39.6409\n",
      "Epoch 683/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 41.4396 - val_loss: 43.2092\n",
      "Epoch 684/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 44.3537 - val_loss: 30.8519\n",
      "Epoch 685/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 38.2315 - val_loss: 29.3894\n",
      "Epoch 686/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 32.6309 - val_loss: 40.0831\n",
      "Epoch 687/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.5237 - val_loss: 60.1130\n",
      "Epoch 688/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 36.3804 - val_loss: 35.1427\n",
      "Epoch 689/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 38.5191 - val_loss: 37.7963\n",
      "Epoch 690/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.4249 - val_loss: 29.2432\n",
      "Epoch 691/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.3378 - val_loss: 29.3341\n",
      "Epoch 692/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 37.5255 - val_loss: 31.2669\n",
      "Epoch 693/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 33.9838 - val_loss: 29.4225\n",
      "Epoch 694/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.0592 - val_loss: 29.8834\n",
      "Epoch 695/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 34.6813 - val_loss: 29.7486\n",
      "Epoch 696/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.1932 - val_loss: 33.8465\n",
      "Epoch 697/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.6015 - val_loss: 31.4641\n",
      "Epoch 698/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 34.6397 - val_loss: 35.9681\n",
      "Epoch 699/700\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0128 - val_loss: 39.5683\n",
      "Epoch 700/700\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 35.6569 - val_loss: 59.2946\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "hist2 = model2.fit(x=x_train, y=y_train, epochs=700, validation_split=0.2, batch_size = 32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x = range(0, 700), y = hist1.history['loss'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x = range(0, 700), y = hist2.history['loss'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[2] Caesarian(제왕절개) Logistic Regression 모델을  Kears로  2층 신경망모델을 구현하여\n",
    "   Accuracy를 구하고 3층신경망 모델과 비교하여 보세요. 2층보다 3층이 Accuracy가 높아지도록\n",
    "   구현한다 하나의 소스에 2층과 3층 두개 모델을 구현하여 Accuracy를비교하여 보세요.학습 결과 시각화도 구현\n",
    "* 파라메터 설정 예시\n",
    "  [2층 신경망]\n",
    "  첫번째 층 출력 : [None,20],   활성화 함수 : 'relu', metrics:['accuracy']\n",
    "  optimizer='adam', loss: 'binary_crossentropy'\n",
    "   학습 epoch : 700\n",
    "\n",
    "  [3층 신경망]\n",
    "  첫번째 층 출력 : [Non,20],   활성화 함수 : 'relu',\n",
    "  두번째 층 출력 : [Non,2],   활성화 함수 : 'relu',\n",
    "  optimizer='adam', loss: 'binary_crossentropy', metrics:['accuracy']\n",
    "  학습 epoch : 700\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    22  1  0  2  0.1  0.2\n",
      "0   26  2  0  1    0    1\n",
      "1   26  2  1  1    0    0\n",
      "2   28  1  0  2    0    0\n",
      "3   22  2  0  1    0    1\n",
      "4   26  1  1  0    0    0\n",
      "..  .. .. .. ..  ...  ...\n",
      "74  27  2  1  1    0    0\n",
      "75  33  4  0  1    0    1\n",
      "76  29  2  1  2    0    1\n",
      "77  25  1  2  0    0    1\n",
      "78  24  2  2  1    0    0\n",
      "\n",
      "[79 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\n",
    "    'C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\ai\\\\.ipynb_checkpoints\\\\01_tensorflow_basic\\\\data_set\\\\caesarian.csv')\n",
    "print(train_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "        CRIM    ZN  INDUS    NOX     RM   AGE     DIS  TAX  PTRATIO  MEDV\n0    0.13587   0.0  10.59  0.489  6.064  59.1  4.2392  277     18.6  24.4\n1    0.08664  45.0   3.44  0.437  7.178  26.3  6.4798  398     15.2  36.4\n2    0.26938   0.0   9.90  0.544  6.266  82.8  3.2628  304     18.4  21.6\n3    0.05302   0.0   3.41  0.489  7.079  63.1  3.4145  270     17.8  28.7\n4    0.06860   0.0   2.89  0.445  7.416  62.5  3.4952  276     18.0  33.2\n..       ...   ...    ...    ...    ...   ...     ...  ...      ...   ...\n95   0.13262   0.0   8.56  0.520  5.851  96.7  2.1069  384     20.9  19.5\n96   6.80117   0.0  18.10  0.713  6.081  84.4  2.7175  666     20.2  20.0\n97  12.80230   0.0  18.10  0.740  5.854  96.6  1.8956  666     20.2  10.8\n98  10.23300   0.0  18.10  0.614  6.185  96.7  2.1705  666     20.2  14.6\n99   0.35809   0.0   6.20  0.507  6.951  88.5  2.8617  307     17.4  26.7\n\n[100 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.13587</td>\n      <td>0.0</td>\n      <td>10.59</td>\n      <td>0.489</td>\n      <td>6.064</td>\n      <td>59.1</td>\n      <td>4.2392</td>\n      <td>277</td>\n      <td>18.6</td>\n      <td>24.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.08664</td>\n      <td>45.0</td>\n      <td>3.44</td>\n      <td>0.437</td>\n      <td>7.178</td>\n      <td>26.3</td>\n      <td>6.4798</td>\n      <td>398</td>\n      <td>15.2</td>\n      <td>36.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.26938</td>\n      <td>0.0</td>\n      <td>9.90</td>\n      <td>0.544</td>\n      <td>6.266</td>\n      <td>82.8</td>\n      <td>3.2628</td>\n      <td>304</td>\n      <td>18.4</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05302</td>\n      <td>0.0</td>\n      <td>3.41</td>\n      <td>0.489</td>\n      <td>7.079</td>\n      <td>63.1</td>\n      <td>3.4145</td>\n      <td>270</td>\n      <td>17.8</td>\n      <td>28.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06860</td>\n      <td>0.0</td>\n      <td>2.89</td>\n      <td>0.445</td>\n      <td>7.416</td>\n      <td>62.5</td>\n      <td>3.4952</td>\n      <td>276</td>\n      <td>18.0</td>\n      <td>33.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.13262</td>\n      <td>0.0</td>\n      <td>8.56</td>\n      <td>0.520</td>\n      <td>5.851</td>\n      <td>96.7</td>\n      <td>2.1069</td>\n      <td>384</td>\n      <td>20.9</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>6.80117</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.713</td>\n      <td>6.081</td>\n      <td>84.4</td>\n      <td>2.7175</td>\n      <td>666</td>\n      <td>20.2</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>12.80230</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.740</td>\n      <td>5.854</td>\n      <td>96.6</td>\n      <td>1.8956</td>\n      <td>666</td>\n      <td>20.2</td>\n      <td>10.8</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>10.23300</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.614</td>\n      <td>6.185</td>\n      <td>96.7</td>\n      <td>2.1705</td>\n      <td>666</td>\n      <td>20.2</td>\n      <td>14.6</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.35809</td>\n      <td>0.0</td>\n      <td>6.20</td>\n      <td>0.507</td>\n      <td>6.951</td>\n      <td>88.5</td>\n      <td>2.8617</td>\n      <td>307</td>\n      <td>17.4</td>\n      <td>26.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\n",
    "    'C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\ai\\\\.ipynb_checkpoints\\\\01_tensorflow_basic\\\\data_set\\\\boston_test.csv')\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "((79, 5), (79,))"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_df.iloc[ :, :-1 ].to_numpy()\n",
    "y_train = train_df.iloc[ :, -1 ].to_numpy()\n",
    "x_train.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 20)                120       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Dense(units=20, activation='relu', use_bias=True, input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 1.8764 - accuracy: 0.5873 - val_loss: 1.9812 - val_accuracy: 0.5625\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8144 - accuracy: 0.5873 - val_loss: 1.9105 - val_accuracy: 0.5625\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7526 - accuracy: 0.5873 - val_loss: 1.8401 - val_accuracy: 0.5625\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6912 - accuracy: 0.5873 - val_loss: 1.7702 - val_accuracy: 0.5625\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6305 - accuracy: 0.5873 - val_loss: 1.7008 - val_accuracy: 0.5625\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5704 - accuracy: 0.5873 - val_loss: 1.6322 - val_accuracy: 0.5625\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5110 - accuracy: 0.5873 - val_loss: 1.5643 - val_accuracy: 0.5625\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4524 - accuracy: 0.5873 - val_loss: 1.4973 - val_accuracy: 0.5625\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3948 - accuracy: 0.5873 - val_loss: 1.4306 - val_accuracy: 0.5625\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3384 - accuracy: 0.5873 - val_loss: 1.3651 - val_accuracy: 0.5625\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2829 - accuracy: 0.5873 - val_loss: 1.3010 - val_accuracy: 0.5625\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2283 - accuracy: 0.5873 - val_loss: 1.2387 - val_accuracy: 0.5625\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1754 - accuracy: 0.5873 - val_loss: 1.1785 - val_accuracy: 0.5625\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1244 - accuracy: 0.5873 - val_loss: 1.1205 - val_accuracy: 0.5625\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0755 - accuracy: 0.5873 - val_loss: 1.0647 - val_accuracy: 0.5625\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0291 - accuracy: 0.5873 - val_loss: 1.0110 - val_accuracy: 0.5625\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9856 - accuracy: 0.5873 - val_loss: 0.9608 - val_accuracy: 0.5625\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9455 - accuracy: 0.5873 - val_loss: 0.9144 - val_accuracy: 0.5625\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9090 - accuracy: 0.5873 - val_loss: 0.8715 - val_accuracy: 0.5625\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8765 - accuracy: 0.5873 - val_loss: 0.8332 - val_accuracy: 0.5625\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8481 - accuracy: 0.5873 - val_loss: 0.7997 - val_accuracy: 0.5625\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8236 - accuracy: 0.5873 - val_loss: 0.7711 - val_accuracy: 0.5625\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8033 - accuracy: 0.5714 - val_loss: 0.7475 - val_accuracy: 0.5625\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7871 - accuracy: 0.5714 - val_loss: 0.7290 - val_accuracy: 0.5625\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7748 - accuracy: 0.5238 - val_loss: 0.7150 - val_accuracy: 0.5625\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7665 - accuracy: 0.5079 - val_loss: 0.7053 - val_accuracy: 0.5625\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7615 - accuracy: 0.4444 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7594 - accuracy: 0.4603 - val_loss: 0.6974 - val_accuracy: 0.5625\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7598 - accuracy: 0.3651 - val_loss: 0.6976 - val_accuracy: 0.5625\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7621 - accuracy: 0.3651 - val_loss: 0.6993 - val_accuracy: 0.5625\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7655 - accuracy: 0.3810 - val_loss: 0.7014 - val_accuracy: 0.5625\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7695 - accuracy: 0.4127 - val_loss: 0.7038 - val_accuracy: 0.5625\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7732 - accuracy: 0.3968 - val_loss: 0.7059 - val_accuracy: 0.5000\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7763 - accuracy: 0.4286 - val_loss: 0.7076 - val_accuracy: 0.5000\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7784 - accuracy: 0.4286 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7793 - accuracy: 0.4286 - val_loss: 0.7090 - val_accuracy: 0.5000\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7790 - accuracy: 0.4444 - val_loss: 0.7084 - val_accuracy: 0.5000\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7776 - accuracy: 0.4444 - val_loss: 0.7072 - val_accuracy: 0.5000\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7752 - accuracy: 0.4444 - val_loss: 0.7053 - val_accuracy: 0.5000\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7719 - accuracy: 0.4286 - val_loss: 0.7031 - val_accuracy: 0.5000\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7679 - accuracy: 0.3968 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7634 - accuracy: 0.3968 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7587 - accuracy: 0.3968 - val_loss: 0.6954 - val_accuracy: 0.6250\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7537 - accuracy: 0.3968 - val_loss: 0.6930 - val_accuracy: 0.6250\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7487 - accuracy: 0.3651 - val_loss: 0.6909 - val_accuracy: 0.5625\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7438 - accuracy: 0.3968 - val_loss: 0.6891 - val_accuracy: 0.5625\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7392 - accuracy: 0.4127 - val_loss: 0.6877 - val_accuracy: 0.4375\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7351 - accuracy: 0.3968 - val_loss: 0.6866 - val_accuracy: 0.4375\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7313 - accuracy: 0.4603 - val_loss: 0.6859 - val_accuracy: 0.3750\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7279 - accuracy: 0.4286 - val_loss: 0.6855 - val_accuracy: 0.3750\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7249 - accuracy: 0.4127 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7222 - accuracy: 0.4127 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7195 - accuracy: 0.4603 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7168 - accuracy: 0.4762 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7143 - accuracy: 0.5079 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7117 - accuracy: 0.5079 - val_loss: 0.6851 - val_accuracy: 0.5000\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7094 - accuracy: 0.5397 - val_loss: 0.6843 - val_accuracy: 0.5000\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7073 - accuracy: 0.5556 - val_loss: 0.6839 - val_accuracy: 0.5000\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7055 - accuracy: 0.5556 - val_loss: 0.6839 - val_accuracy: 0.5000\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7041 - accuracy: 0.5556 - val_loss: 0.6838 - val_accuracy: 0.5000\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7028 - accuracy: 0.5556 - val_loss: 0.6831 - val_accuracy: 0.5000\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7015 - accuracy: 0.5556 - val_loss: 0.6823 - val_accuracy: 0.5000\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7003 - accuracy: 0.5556 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6992 - accuracy: 0.5556 - val_loss: 0.6815 - val_accuracy: 0.5000\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6981 - accuracy: 0.5556 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6971 - accuracy: 0.5238 - val_loss: 0.6808 - val_accuracy: 0.5000\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6961 - accuracy: 0.5238 - val_loss: 0.6805 - val_accuracy: 0.5000\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6952 - accuracy: 0.5397 - val_loss: 0.6803 - val_accuracy: 0.5000\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6942 - accuracy: 0.5397 - val_loss: 0.6801 - val_accuracy: 0.5000\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.5397 - val_loss: 0.6799 - val_accuracy: 0.5000\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6923 - accuracy: 0.5397 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6913 - accuracy: 0.5397 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6903 - accuracy: 0.5397 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6894 - accuracy: 0.5397 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6884 - accuracy: 0.5397 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6874 - accuracy: 0.5397 - val_loss: 0.6799 - val_accuracy: 0.5000\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6865 - accuracy: 0.5397 - val_loss: 0.6800 - val_accuracy: 0.5000\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6855 - accuracy: 0.5397 - val_loss: 0.6801 - val_accuracy: 0.5000\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6845 - accuracy: 0.5397 - val_loss: 0.6802 - val_accuracy: 0.5000\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6836 - accuracy: 0.5397 - val_loss: 0.6804 - val_accuracy: 0.5000\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6826 - accuracy: 0.5397 - val_loss: 0.6805 - val_accuracy: 0.5000\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6816 - accuracy: 0.5714 - val_loss: 0.6806 - val_accuracy: 0.5000\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6807 - accuracy: 0.5714 - val_loss: 0.6808 - val_accuracy: 0.5000\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6798 - accuracy: 0.5714 - val_loss: 0.6809 - val_accuracy: 0.5000\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6788 - accuracy: 0.5714 - val_loss: 0.6810 - val_accuracy: 0.5000\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6779 - accuracy: 0.5714 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6770 - accuracy: 0.5714 - val_loss: 0.6812 - val_accuracy: 0.5000\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6760 - accuracy: 0.5873 - val_loss: 0.6812 - val_accuracy: 0.5000\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6751 - accuracy: 0.5873 - val_loss: 0.6813 - val_accuracy: 0.5000\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6742 - accuracy: 0.5873 - val_loss: 0.6813 - val_accuracy: 0.5000\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6733 - accuracy: 0.5873 - val_loss: 0.6813 - val_accuracy: 0.5000\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6724 - accuracy: 0.5873 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6715 - accuracy: 0.5873 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6706 - accuracy: 0.5873 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6697 - accuracy: 0.5873 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6688 - accuracy: 0.5873 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6679 - accuracy: 0.5873 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6670 - accuracy: 0.5873 - val_loss: 0.6815 - val_accuracy: 0.5000\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6661 - accuracy: 0.5873 - val_loss: 0.6815 - val_accuracy: 0.5000\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6652 - accuracy: 0.5873 - val_loss: 0.6815 - val_accuracy: 0.5000\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6644 - accuracy: 0.5873 - val_loss: 0.6816 - val_accuracy: 0.5000\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6635 - accuracy: 0.5873 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6626 - accuracy: 0.5873 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6618 - accuracy: 0.5873 - val_loss: 0.6818 - val_accuracy: 0.5000\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6609 - accuracy: 0.5873 - val_loss: 0.6818 - val_accuracy: 0.5000\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6601 - accuracy: 0.5873 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6592 - accuracy: 0.5873 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6584 - accuracy: 0.5873 - val_loss: 0.6820 - val_accuracy: 0.5000\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6575 - accuracy: 0.5873 - val_loss: 0.6821 - val_accuracy: 0.5000\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6567 - accuracy: 0.5873 - val_loss: 0.6822 - val_accuracy: 0.5000\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6559 - accuracy: 0.5873 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6551 - accuracy: 0.5873 - val_loss: 0.6825 - val_accuracy: 0.5000\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6543 - accuracy: 0.5873 - val_loss: 0.6827 - val_accuracy: 0.5000\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6535 - accuracy: 0.5873 - val_loss: 0.6828 - val_accuracy: 0.5000\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6527 - accuracy: 0.5873 - val_loss: 0.6830 - val_accuracy: 0.5000\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6519 - accuracy: 0.5873 - val_loss: 0.6832 - val_accuracy: 0.5000\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6511 - accuracy: 0.5873 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6503 - accuracy: 0.5873 - val_loss: 0.6835 - val_accuracy: 0.5000\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6495 - accuracy: 0.5873 - val_loss: 0.6836 - val_accuracy: 0.5000\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6488 - accuracy: 0.5873 - val_loss: 0.6838 - val_accuracy: 0.5000\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6480 - accuracy: 0.5873 - val_loss: 0.6839 - val_accuracy: 0.5000\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6472 - accuracy: 0.5873 - val_loss: 0.6841 - val_accuracy: 0.5000\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6465 - accuracy: 0.5714 - val_loss: 0.6842 - val_accuracy: 0.5000\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6457 - accuracy: 0.5714 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6450 - accuracy: 0.5714 - val_loss: 0.6845 - val_accuracy: 0.5000\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6442 - accuracy: 0.5714 - val_loss: 0.6847 - val_accuracy: 0.5000\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6435 - accuracy: 0.5714 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6427 - accuracy: 0.5714 - val_loss: 0.6850 - val_accuracy: 0.5000\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6420 - accuracy: 0.5873 - val_loss: 0.6852 - val_accuracy: 0.5000\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6413 - accuracy: 0.5873 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6406 - accuracy: 0.5873 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6398 - accuracy: 0.5873 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6391 - accuracy: 0.5873 - val_loss: 0.6858 - val_accuracy: 0.5000\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6384 - accuracy: 0.5873 - val_loss: 0.6860 - val_accuracy: 0.5625\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6378 - accuracy: 0.5873 - val_loss: 0.6861 - val_accuracy: 0.5625\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6371 - accuracy: 0.5873 - val_loss: 0.6863 - val_accuracy: 0.5625\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6364 - accuracy: 0.5873 - val_loss: 0.6865 - val_accuracy: 0.5625\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6357 - accuracy: 0.6032 - val_loss: 0.6867 - val_accuracy: 0.5625\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6350 - accuracy: 0.6190 - val_loss: 0.6868 - val_accuracy: 0.5625\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6343 - accuracy: 0.6190 - val_loss: 0.6871 - val_accuracy: 0.5625\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6337 - accuracy: 0.6190 - val_loss: 0.6873 - val_accuracy: 0.5625\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6330 - accuracy: 0.6190 - val_loss: 0.6875 - val_accuracy: 0.5625\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6323 - accuracy: 0.6190 - val_loss: 0.6877 - val_accuracy: 0.5625\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6317 - accuracy: 0.6190 - val_loss: 0.6880 - val_accuracy: 0.5625\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6310 - accuracy: 0.6190 - val_loss: 0.6883 - val_accuracy: 0.5625\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6304 - accuracy: 0.6190 - val_loss: 0.6885 - val_accuracy: 0.5625\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6297 - accuracy: 0.6190 - val_loss: 0.6888 - val_accuracy: 0.5625\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6291 - accuracy: 0.6190 - val_loss: 0.6891 - val_accuracy: 0.5625\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6284 - accuracy: 0.6190 - val_loss: 0.6893 - val_accuracy: 0.5625\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6278 - accuracy: 0.6190 - val_loss: 0.6896 - val_accuracy: 0.5625\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6271 - accuracy: 0.6190 - val_loss: 0.6899 - val_accuracy: 0.5625\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6265 - accuracy: 0.6032 - val_loss: 0.6902 - val_accuracy: 0.5625\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6259 - accuracy: 0.6032 - val_loss: 0.6905 - val_accuracy: 0.5625\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6253 - accuracy: 0.6032 - val_loss: 0.6908 - val_accuracy: 0.5625\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6246 - accuracy: 0.6032 - val_loss: 0.6910 - val_accuracy: 0.5625\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6240 - accuracy: 0.6032 - val_loss: 0.6913 - val_accuracy: 0.5625\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6234 - accuracy: 0.6032 - val_loss: 0.6916 - val_accuracy: 0.5625\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6228 - accuracy: 0.6032 - val_loss: 0.6919 - val_accuracy: 0.5625\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6222 - accuracy: 0.6032 - val_loss: 0.6922 - val_accuracy: 0.5625\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6216 - accuracy: 0.6190 - val_loss: 0.6924 - val_accuracy: 0.5625\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6210 - accuracy: 0.6190 - val_loss: 0.6927 - val_accuracy: 0.5625\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6204 - accuracy: 0.6190 - val_loss: 0.6930 - val_accuracy: 0.5625\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6198 - accuracy: 0.6190 - val_loss: 0.6933 - val_accuracy: 0.5625\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6192 - accuracy: 0.6190 - val_loss: 0.6936 - val_accuracy: 0.5625\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6186 - accuracy: 0.6190 - val_loss: 0.6939 - val_accuracy: 0.5625\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6180 - accuracy: 0.6032 - val_loss: 0.6942 - val_accuracy: 0.5625\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6174 - accuracy: 0.6032 - val_loss: 0.6945 - val_accuracy: 0.5625\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6169 - accuracy: 0.6190 - val_loss: 0.6948 - val_accuracy: 0.5625\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6163 - accuracy: 0.6190 - val_loss: 0.6951 - val_accuracy: 0.5625\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6157 - accuracy: 0.6190 - val_loss: 0.6955 - val_accuracy: 0.5625\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6152 - accuracy: 0.6190 - val_loss: 0.6958 - val_accuracy: 0.5625\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6146 - accuracy: 0.6349 - val_loss: 0.6962 - val_accuracy: 0.5625\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6140 - accuracy: 0.6349 - val_loss: 0.6965 - val_accuracy: 0.5625\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6135 - accuracy: 0.6349 - val_loss: 0.6969 - val_accuracy: 0.5625\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6129 - accuracy: 0.6349 - val_loss: 0.6973 - val_accuracy: 0.5625\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6124 - accuracy: 0.6349 - val_loss: 0.6976 - val_accuracy: 0.5625\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6118 - accuracy: 0.6349 - val_loss: 0.6980 - val_accuracy: 0.5625\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6113 - accuracy: 0.6349 - val_loss: 0.6983 - val_accuracy: 0.5625\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6108 - accuracy: 0.6349 - val_loss: 0.6987 - val_accuracy: 0.5625\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6102 - accuracy: 0.6349 - val_loss: 0.6990 - val_accuracy: 0.5625\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6097 - accuracy: 0.6349 - val_loss: 0.6993 - val_accuracy: 0.5625\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6092 - accuracy: 0.6349 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6087 - accuracy: 0.6508 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6081 - accuracy: 0.6508 - val_loss: 0.7004 - val_accuracy: 0.5000\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6076 - accuracy: 0.6508 - val_loss: 0.7008 - val_accuracy: 0.5000\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6071 - accuracy: 0.6508 - val_loss: 0.7011 - val_accuracy: 0.5000\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6066 - accuracy: 0.6508 - val_loss: 0.7015 - val_accuracy: 0.5000\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6061 - accuracy: 0.6508 - val_loss: 0.7019 - val_accuracy: 0.5000\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6056 - accuracy: 0.6508 - val_loss: 0.7022 - val_accuracy: 0.5000\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6051 - accuracy: 0.6508 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6046 - accuracy: 0.6508 - val_loss: 0.7029 - val_accuracy: 0.5000\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6041 - accuracy: 0.6508 - val_loss: 0.7033 - val_accuracy: 0.5000\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6036 - accuracy: 0.6508 - val_loss: 0.7036 - val_accuracy: 0.5000\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6032 - accuracy: 0.6508 - val_loss: 0.7039 - val_accuracy: 0.5000\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6027 - accuracy: 0.6508 - val_loss: 0.7043 - val_accuracy: 0.5000\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6022 - accuracy: 0.6667 - val_loss: 0.7047 - val_accuracy: 0.5000\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6017 - accuracy: 0.6667 - val_loss: 0.7051 - val_accuracy: 0.5000\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6012 - accuracy: 0.6667 - val_loss: 0.7055 - val_accuracy: 0.5000\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6008 - accuracy: 0.6667 - val_loss: 0.7059 - val_accuracy: 0.5000\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6003 - accuracy: 0.6667 - val_loss: 0.7063 - val_accuracy: 0.5000\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5999 - accuracy: 0.6667 - val_loss: 0.7067 - val_accuracy: 0.5000\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5994 - accuracy: 0.6667 - val_loss: 0.7071 - val_accuracy: 0.5000\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5989 - accuracy: 0.6667 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5985 - accuracy: 0.6667 - val_loss: 0.7078 - val_accuracy: 0.5000\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5980 - accuracy: 0.6667 - val_loss: 0.7082 - val_accuracy: 0.5000\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5976 - accuracy: 0.6667 - val_loss: 0.7086 - val_accuracy: 0.5000\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5971 - accuracy: 0.6667 - val_loss: 0.7090 - val_accuracy: 0.5000\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5967 - accuracy: 0.6667 - val_loss: 0.7094 - val_accuracy: 0.5000\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5962 - accuracy: 0.6667 - val_loss: 0.7098 - val_accuracy: 0.5000\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5958 - accuracy: 0.6667 - val_loss: 0.7102 - val_accuracy: 0.5000\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5954 - accuracy: 0.6667 - val_loss: 0.7107 - val_accuracy: 0.5000\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5949 - accuracy: 0.6667 - val_loss: 0.7111 - val_accuracy: 0.5000\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5945 - accuracy: 0.6667 - val_loss: 0.7115 - val_accuracy: 0.5000\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5941 - accuracy: 0.6667 - val_loss: 0.7119 - val_accuracy: 0.5000\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5937 - accuracy: 0.6667 - val_loss: 0.7123 - val_accuracy: 0.5000\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5932 - accuracy: 0.6667 - val_loss: 0.7128 - val_accuracy: 0.5625\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5928 - accuracy: 0.6667 - val_loss: 0.7132 - val_accuracy: 0.5625\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5924 - accuracy: 0.6667 - val_loss: 0.7136 - val_accuracy: 0.5625\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5920 - accuracy: 0.6667 - val_loss: 0.7140 - val_accuracy: 0.5625\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5916 - accuracy: 0.6667 - val_loss: 0.7144 - val_accuracy: 0.5625\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5912 - accuracy: 0.6667 - val_loss: 0.7148 - val_accuracy: 0.5625\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5908 - accuracy: 0.6667 - val_loss: 0.7152 - val_accuracy: 0.5625\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5904 - accuracy: 0.6667 - val_loss: 0.7157 - val_accuracy: 0.5625\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5900 - accuracy: 0.6667 - val_loss: 0.7161 - val_accuracy: 0.5625\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5896 - accuracy: 0.6667 - val_loss: 0.7165 - val_accuracy: 0.5625\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5892 - accuracy: 0.6667 - val_loss: 0.7169 - val_accuracy: 0.5625\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5888 - accuracy: 0.6667 - val_loss: 0.7174 - val_accuracy: 0.5625\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5884 - accuracy: 0.6667 - val_loss: 0.7178 - val_accuracy: 0.5625\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5880 - accuracy: 0.6667 - val_loss: 0.7182 - val_accuracy: 0.5625\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5876 - accuracy: 0.6667 - val_loss: 0.7186 - val_accuracy: 0.5625\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5872 - accuracy: 0.6667 - val_loss: 0.7191 - val_accuracy: 0.5625\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5869 - accuracy: 0.6667 - val_loss: 0.7195 - val_accuracy: 0.5625\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5865 - accuracy: 0.6667 - val_loss: 0.7200 - val_accuracy: 0.5625\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5861 - accuracy: 0.6667 - val_loss: 0.7204 - val_accuracy: 0.5625\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5857 - accuracy: 0.6825 - val_loss: 0.7208 - val_accuracy: 0.5625\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5854 - accuracy: 0.6825 - val_loss: 0.7213 - val_accuracy: 0.5625\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5850 - accuracy: 0.6825 - val_loss: 0.7217 - val_accuracy: 0.5625\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5846 - accuracy: 0.6825 - val_loss: 0.7221 - val_accuracy: 0.5625\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5843 - accuracy: 0.6825 - val_loss: 0.7225 - val_accuracy: 0.5625\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5839 - accuracy: 0.6984 - val_loss: 0.7230 - val_accuracy: 0.6250\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5835 - accuracy: 0.6984 - val_loss: 0.7234 - val_accuracy: 0.6250\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5832 - accuracy: 0.6984 - val_loss: 0.7239 - val_accuracy: 0.6250\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5828 - accuracy: 0.6984 - val_loss: 0.7243 - val_accuracy: 0.6250\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5825 - accuracy: 0.6984 - val_loss: 0.7248 - val_accuracy: 0.6250\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5821 - accuracy: 0.6984 - val_loss: 0.7252 - val_accuracy: 0.6250\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5818 - accuracy: 0.6984 - val_loss: 0.7257 - val_accuracy: 0.6250\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5814 - accuracy: 0.6984 - val_loss: 0.7261 - val_accuracy: 0.6250\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5811 - accuracy: 0.6984 - val_loss: 0.7266 - val_accuracy: 0.6250\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5808 - accuracy: 0.6984 - val_loss: 0.7270 - val_accuracy: 0.6250\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5804 - accuracy: 0.6984 - val_loss: 0.7274 - val_accuracy: 0.6250\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5801 - accuracy: 0.6984 - val_loss: 0.7279 - val_accuracy: 0.6250\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5798 - accuracy: 0.6984 - val_loss: 0.7283 - val_accuracy: 0.6250\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5794 - accuracy: 0.6984 - val_loss: 0.7288 - val_accuracy: 0.6250\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5791 - accuracy: 0.6984 - val_loss: 0.7293 - val_accuracy: 0.6250\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5788 - accuracy: 0.6825 - val_loss: 0.7297 - val_accuracy: 0.6250\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5784 - accuracy: 0.6825 - val_loss: 0.7302 - val_accuracy: 0.6250\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5781 - accuracy: 0.6825 - val_loss: 0.7306 - val_accuracy: 0.6250\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5778 - accuracy: 0.6984 - val_loss: 0.7311 - val_accuracy: 0.6250\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5775 - accuracy: 0.6984 - val_loss: 0.7315 - val_accuracy: 0.6250\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5772 - accuracy: 0.6984 - val_loss: 0.7319 - val_accuracy: 0.6250\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5768 - accuracy: 0.6984 - val_loss: 0.7324 - val_accuracy: 0.6250\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5765 - accuracy: 0.6984 - val_loss: 0.7328 - val_accuracy: 0.6250\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5762 - accuracy: 0.6984 - val_loss: 0.7333 - val_accuracy: 0.6250\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5759 - accuracy: 0.6984 - val_loss: 0.7338 - val_accuracy: 0.6250\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5756 - accuracy: 0.6984 - val_loss: 0.7342 - val_accuracy: 0.6250\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5753 - accuracy: 0.6984 - val_loss: 0.7347 - val_accuracy: 0.6250\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5750 - accuracy: 0.6984 - val_loss: 0.7352 - val_accuracy: 0.6250\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5747 - accuracy: 0.6984 - val_loss: 0.7356 - val_accuracy: 0.6250\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5744 - accuracy: 0.6984 - val_loss: 0.7361 - val_accuracy: 0.6250\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5741 - accuracy: 0.6984 - val_loss: 0.7365 - val_accuracy: 0.6250\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5738 - accuracy: 0.6984 - val_loss: 0.7369 - val_accuracy: 0.6250\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5735 - accuracy: 0.6984 - val_loss: 0.7374 - val_accuracy: 0.6250\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5732 - accuracy: 0.6984 - val_loss: 0.7379 - val_accuracy: 0.6250\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5729 - accuracy: 0.6984 - val_loss: 0.7383 - val_accuracy: 0.6250\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5726 - accuracy: 0.6984 - val_loss: 0.7388 - val_accuracy: 0.6250\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5724 - accuracy: 0.6984 - val_loss: 0.7393 - val_accuracy: 0.6250\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5721 - accuracy: 0.6984 - val_loss: 0.7397 - val_accuracy: 0.6250\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5718 - accuracy: 0.6984 - val_loss: 0.7402 - val_accuracy: 0.6250\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5715 - accuracy: 0.6984 - val_loss: 0.7406 - val_accuracy: 0.6250\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5712 - accuracy: 0.6984 - val_loss: 0.7411 - val_accuracy: 0.6250\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5710 - accuracy: 0.6984 - val_loss: 0.7415 - val_accuracy: 0.6250\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5707 - accuracy: 0.6984 - val_loss: 0.7420 - val_accuracy: 0.6250\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5704 - accuracy: 0.6984 - val_loss: 0.7424 - val_accuracy: 0.6250\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5701 - accuracy: 0.6984 - val_loss: 0.7429 - val_accuracy: 0.6250\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5699 - accuracy: 0.6984 - val_loss: 0.7434 - val_accuracy: 0.6250\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5696 - accuracy: 0.6984 - val_loss: 0.7438 - val_accuracy: 0.6250\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5693 - accuracy: 0.6984 - val_loss: 0.7443 - val_accuracy: 0.6250\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5691 - accuracy: 0.6984 - val_loss: 0.7447 - val_accuracy: 0.6250\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5688 - accuracy: 0.6984 - val_loss: 0.7452 - val_accuracy: 0.6250\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5686 - accuracy: 0.6984 - val_loss: 0.7456 - val_accuracy: 0.6250\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5683 - accuracy: 0.6984 - val_loss: 0.7461 - val_accuracy: 0.6250\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5680 - accuracy: 0.6984 - val_loss: 0.7465 - val_accuracy: 0.6250\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5678 - accuracy: 0.6984 - val_loss: 0.7470 - val_accuracy: 0.6250\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5675 - accuracy: 0.6984 - val_loss: 0.7475 - val_accuracy: 0.6250\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5673 - accuracy: 0.6984 - val_loss: 0.7479 - val_accuracy: 0.6250\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5670 - accuracy: 0.6984 - val_loss: 0.7484 - val_accuracy: 0.6250\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5668 - accuracy: 0.6984 - val_loss: 0.7488 - val_accuracy: 0.6250\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5665 - accuracy: 0.6984 - val_loss: 0.7493 - val_accuracy: 0.6250\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5663 - accuracy: 0.6984 - val_loss: 0.7497 - val_accuracy: 0.6250\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5660 - accuracy: 0.6984 - val_loss: 0.7502 - val_accuracy: 0.6250\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5658 - accuracy: 0.6984 - val_loss: 0.7507 - val_accuracy: 0.6250\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5655 - accuracy: 0.6984 - val_loss: 0.7511 - val_accuracy: 0.6250\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5653 - accuracy: 0.6984 - val_loss: 0.7516 - val_accuracy: 0.6250\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5651 - accuracy: 0.6984 - val_loss: 0.7520 - val_accuracy: 0.6250\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5648 - accuracy: 0.6984 - val_loss: 0.7525 - val_accuracy: 0.6250\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5646 - accuracy: 0.6984 - val_loss: 0.7529 - val_accuracy: 0.6250\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5644 - accuracy: 0.6984 - val_loss: 0.7534 - val_accuracy: 0.6250\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5641 - accuracy: 0.6984 - val_loss: 0.7538 - val_accuracy: 0.6250\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5639 - accuracy: 0.6984 - val_loss: 0.7543 - val_accuracy: 0.6250\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5637 - accuracy: 0.6984 - val_loss: 0.7547 - val_accuracy: 0.6250\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5634 - accuracy: 0.6984 - val_loss: 0.7552 - val_accuracy: 0.6250\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5632 - accuracy: 0.6984 - val_loss: 0.7556 - val_accuracy: 0.6250\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5630 - accuracy: 0.6984 - val_loss: 0.7561 - val_accuracy: 0.6250\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5628 - accuracy: 0.6984 - val_loss: 0.7565 - val_accuracy: 0.6250\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5625 - accuracy: 0.6984 - val_loss: 0.7570 - val_accuracy: 0.6250\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5623 - accuracy: 0.6984 - val_loss: 0.7574 - val_accuracy: 0.6250\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5621 - accuracy: 0.6984 - val_loss: 0.7579 - val_accuracy: 0.6250\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5619 - accuracy: 0.6984 - val_loss: 0.7583 - val_accuracy: 0.6250\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5617 - accuracy: 0.6984 - val_loss: 0.7588 - val_accuracy: 0.6250\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5615 - accuracy: 0.6984 - val_loss: 0.7592 - val_accuracy: 0.6250\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5612 - accuracy: 0.6984 - val_loss: 0.7597 - val_accuracy: 0.6250\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5610 - accuracy: 0.6984 - val_loss: 0.7601 - val_accuracy: 0.6250\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5608 - accuracy: 0.6984 - val_loss: 0.7606 - val_accuracy: 0.6250\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5606 - accuracy: 0.6984 - val_loss: 0.7610 - val_accuracy: 0.6250\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5604 - accuracy: 0.6984 - val_loss: 0.7615 - val_accuracy: 0.6250\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5602 - accuracy: 0.6984 - val_loss: 0.7619 - val_accuracy: 0.6250\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5600 - accuracy: 0.6984 - val_loss: 0.7624 - val_accuracy: 0.6250\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5598 - accuracy: 0.6984 - val_loss: 0.7628 - val_accuracy: 0.6250\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5596 - accuracy: 0.6984 - val_loss: 0.7632 - val_accuracy: 0.6250\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5594 - accuracy: 0.6984 - val_loss: 0.7637 - val_accuracy: 0.6250\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5592 - accuracy: 0.6984 - val_loss: 0.7641 - val_accuracy: 0.6250\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5590 - accuracy: 0.6984 - val_loss: 0.7646 - val_accuracy: 0.6250\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5588 - accuracy: 0.6984 - val_loss: 0.7650 - val_accuracy: 0.6250\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5586 - accuracy: 0.6984 - val_loss: 0.7655 - val_accuracy: 0.6250\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5584 - accuracy: 0.6984 - val_loss: 0.7659 - val_accuracy: 0.6250\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5582 - accuracy: 0.6984 - val_loss: 0.7663 - val_accuracy: 0.6250\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5580 - accuracy: 0.6984 - val_loss: 0.7668 - val_accuracy: 0.6250\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5578 - accuracy: 0.6984 - val_loss: 0.7672 - val_accuracy: 0.6250\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5576 - accuracy: 0.6984 - val_loss: 0.7676 - val_accuracy: 0.6250\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5574 - accuracy: 0.6984 - val_loss: 0.7681 - val_accuracy: 0.6250\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5572 - accuracy: 0.7143 - val_loss: 0.7685 - val_accuracy: 0.6250\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5571 - accuracy: 0.7143 - val_loss: 0.7690 - val_accuracy: 0.6250\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5569 - accuracy: 0.7143 - val_loss: 0.7694 - val_accuracy: 0.6250\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5567 - accuracy: 0.7143 - val_loss: 0.7699 - val_accuracy: 0.6250\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5565 - accuracy: 0.7143 - val_loss: 0.7703 - val_accuracy: 0.6250\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5563 - accuracy: 0.7143 - val_loss: 0.7707 - val_accuracy: 0.6250\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5561 - accuracy: 0.7143 - val_loss: 0.7712 - val_accuracy: 0.6250\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5560 - accuracy: 0.7143 - val_loss: 0.7716 - val_accuracy: 0.6250\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5558 - accuracy: 0.7143 - val_loss: 0.7720 - val_accuracy: 0.6250\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5556 - accuracy: 0.7143 - val_loss: 0.7725 - val_accuracy: 0.6250\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5554 - accuracy: 0.7302 - val_loss: 0.7729 - val_accuracy: 0.6250\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5552 - accuracy: 0.7302 - val_loss: 0.7734 - val_accuracy: 0.6250\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5551 - accuracy: 0.7302 - val_loss: 0.7738 - val_accuracy: 0.6250\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5549 - accuracy: 0.7460 - val_loss: 0.7742 - val_accuracy: 0.6250\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5547 - accuracy: 0.7460 - val_loss: 0.7746 - val_accuracy: 0.6250\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5546 - accuracy: 0.7460 - val_loss: 0.7750 - val_accuracy: 0.6250\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5544 - accuracy: 0.7460 - val_loss: 0.7755 - val_accuracy: 0.6250\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5542 - accuracy: 0.7460 - val_loss: 0.7759 - val_accuracy: 0.6250\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5540 - accuracy: 0.7460 - val_loss: 0.7763 - val_accuracy: 0.6250\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5539 - accuracy: 0.7460 - val_loss: 0.7768 - val_accuracy: 0.6250\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5537 - accuracy: 0.7460 - val_loss: 0.7772 - val_accuracy: 0.6250\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5536 - accuracy: 0.7460 - val_loss: 0.7776 - val_accuracy: 0.6250\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5534 - accuracy: 0.7460 - val_loss: 0.7780 - val_accuracy: 0.6250\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5532 - accuracy: 0.7460 - val_loss: 0.7785 - val_accuracy: 0.6250\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5531 - accuracy: 0.7460 - val_loss: 0.7789 - val_accuracy: 0.6250\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5529 - accuracy: 0.7460 - val_loss: 0.7793 - val_accuracy: 0.6250\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5527 - accuracy: 0.7460 - val_loss: 0.7797 - val_accuracy: 0.6250\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5526 - accuracy: 0.7460 - val_loss: 0.7802 - val_accuracy: 0.6250\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5524 - accuracy: 0.7619 - val_loss: 0.7806 - val_accuracy: 0.6250\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5523 - accuracy: 0.7619 - val_loss: 0.7810 - val_accuracy: 0.6250\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5521 - accuracy: 0.7619 - val_loss: 0.7814 - val_accuracy: 0.6250\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5520 - accuracy: 0.7619 - val_loss: 0.7818 - val_accuracy: 0.6250\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5518 - accuracy: 0.7619 - val_loss: 0.7823 - val_accuracy: 0.6250\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5517 - accuracy: 0.7619 - val_loss: 0.7827 - val_accuracy: 0.6250\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5515 - accuracy: 0.7619 - val_loss: 0.7831 - val_accuracy: 0.6250\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5513 - accuracy: 0.7778 - val_loss: 0.7835 - val_accuracy: 0.6250\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5512 - accuracy: 0.7778 - val_loss: 0.7839 - val_accuracy: 0.6250\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5510 - accuracy: 0.7778 - val_loss: 0.7843 - val_accuracy: 0.6250\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5509 - accuracy: 0.7778 - val_loss: 0.7847 - val_accuracy: 0.6250\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5508 - accuracy: 0.7778 - val_loss: 0.7851 - val_accuracy: 0.6250\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5506 - accuracy: 0.7778 - val_loss: 0.7856 - val_accuracy: 0.6250\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5505 - accuracy: 0.7778 - val_loss: 0.7860 - val_accuracy: 0.6250\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5503 - accuracy: 0.7778 - val_loss: 0.7864 - val_accuracy: 0.6250\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5502 - accuracy: 0.7778 - val_loss: 0.7868 - val_accuracy: 0.6250\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5500 - accuracy: 0.7778 - val_loss: 0.7872 - val_accuracy: 0.6250\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5499 - accuracy: 0.7778 - val_loss: 0.7876 - val_accuracy: 0.6250\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5497 - accuracy: 0.7778 - val_loss: 0.7880 - val_accuracy: 0.6250\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5496 - accuracy: 0.7778 - val_loss: 0.7884 - val_accuracy: 0.6250\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5495 - accuracy: 0.7778 - val_loss: 0.7888 - val_accuracy: 0.6250\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5493 - accuracy: 0.7778 - val_loss: 0.7892 - val_accuracy: 0.6250\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5492 - accuracy: 0.7778 - val_loss: 0.7896 - val_accuracy: 0.6250\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5491 - accuracy: 0.7778 - val_loss: 0.7900 - val_accuracy: 0.6250\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5489 - accuracy: 0.7778 - val_loss: 0.7904 - val_accuracy: 0.6250\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5488 - accuracy: 0.7778 - val_loss: 0.7908 - val_accuracy: 0.6250\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5486 - accuracy: 0.7778 - val_loss: 0.7912 - val_accuracy: 0.6250\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5485 - accuracy: 0.7778 - val_loss: 0.7917 - val_accuracy: 0.6250\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5484 - accuracy: 0.7778 - val_loss: 0.7921 - val_accuracy: 0.6250\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5482 - accuracy: 0.7778 - val_loss: 0.7925 - val_accuracy: 0.6250\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5481 - accuracy: 0.7778 - val_loss: 0.7929 - val_accuracy: 0.6250\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5480 - accuracy: 0.7778 - val_loss: 0.7932 - val_accuracy: 0.6250\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5479 - accuracy: 0.7778 - val_loss: 0.7936 - val_accuracy: 0.6250\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5477 - accuracy: 0.7778 - val_loss: 0.7940 - val_accuracy: 0.6250\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5476 - accuracy: 0.7778 - val_loss: 0.7944 - val_accuracy: 0.6250\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5475 - accuracy: 0.7778 - val_loss: 0.7948 - val_accuracy: 0.6250\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5473 - accuracy: 0.7778 - val_loss: 0.7952 - val_accuracy: 0.6250\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5472 - accuracy: 0.7778 - val_loss: 0.7956 - val_accuracy: 0.6250\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5471 - accuracy: 0.7619 - val_loss: 0.7960 - val_accuracy: 0.6250\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5470 - accuracy: 0.7619 - val_loss: 0.7964 - val_accuracy: 0.6250\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5468 - accuracy: 0.7619 - val_loss: 0.7968 - val_accuracy: 0.6250\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5467 - accuracy: 0.7619 - val_loss: 0.7972 - val_accuracy: 0.6250\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5466 - accuracy: 0.7619 - val_loss: 0.7976 - val_accuracy: 0.6250\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5465 - accuracy: 0.7619 - val_loss: 0.7979 - val_accuracy: 0.6250\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5464 - accuracy: 0.7619 - val_loss: 0.7983 - val_accuracy: 0.6250\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5462 - accuracy: 0.7619 - val_loss: 0.7987 - val_accuracy: 0.6250\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5461 - accuracy: 0.7619 - val_loss: 0.7991 - val_accuracy: 0.6250\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5460 - accuracy: 0.7619 - val_loss: 0.7995 - val_accuracy: 0.6250\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5459 - accuracy: 0.7619 - val_loss: 0.7999 - val_accuracy: 0.6250\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5458 - accuracy: 0.7619 - val_loss: 0.8003 - val_accuracy: 0.6250\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5457 - accuracy: 0.7619 - val_loss: 0.8006 - val_accuracy: 0.6250\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5455 - accuracy: 0.7619 - val_loss: 0.8010 - val_accuracy: 0.6250\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5454 - accuracy: 0.7619 - val_loss: 0.8014 - val_accuracy: 0.6250\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5453 - accuracy: 0.7619 - val_loss: 0.8018 - val_accuracy: 0.6250\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5452 - accuracy: 0.7619 - val_loss: 0.8022 - val_accuracy: 0.6250\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5451 - accuracy: 0.7619 - val_loss: 0.8026 - val_accuracy: 0.6250\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5450 - accuracy: 0.7619 - val_loss: 0.8029 - val_accuracy: 0.6250\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5449 - accuracy: 0.7619 - val_loss: 0.8033 - val_accuracy: 0.6250\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5448 - accuracy: 0.7619 - val_loss: 0.8037 - val_accuracy: 0.6250\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5446 - accuracy: 0.7619 - val_loss: 0.8040 - val_accuracy: 0.6250\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5445 - accuracy: 0.7619 - val_loss: 0.8044 - val_accuracy: 0.6250\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5444 - accuracy: 0.7619 - val_loss: 0.8048 - val_accuracy: 0.6250\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5443 - accuracy: 0.7619 - val_loss: 0.8052 - val_accuracy: 0.6250\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5442 - accuracy: 0.7619 - val_loss: 0.8056 - val_accuracy: 0.6250\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5441 - accuracy: 0.7619 - val_loss: 0.8059 - val_accuracy: 0.6250\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5440 - accuracy: 0.7619 - val_loss: 0.8063 - val_accuracy: 0.6250\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5439 - accuracy: 0.7619 - val_loss: 0.8066 - val_accuracy: 0.6250\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5438 - accuracy: 0.7619 - val_loss: 0.8070 - val_accuracy: 0.6250\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5437 - accuracy: 0.7619 - val_loss: 0.8074 - val_accuracy: 0.6250\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5436 - accuracy: 0.7619 - val_loss: 0.8078 - val_accuracy: 0.5625\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5435 - accuracy: 0.7778 - val_loss: 0.8081 - val_accuracy: 0.5625\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5434 - accuracy: 0.7778 - val_loss: 0.8085 - val_accuracy: 0.5625\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5433 - accuracy: 0.7778 - val_loss: 0.8089 - val_accuracy: 0.5625\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5432 - accuracy: 0.7778 - val_loss: 0.8092 - val_accuracy: 0.5625\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5431 - accuracy: 0.7778 - val_loss: 0.8096 - val_accuracy: 0.5625\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5430 - accuracy: 0.7778 - val_loss: 0.8099 - val_accuracy: 0.5625\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5429 - accuracy: 0.7778 - val_loss: 0.8103 - val_accuracy: 0.5625\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5428 - accuracy: 0.7778 - val_loss: 0.8107 - val_accuracy: 0.5625\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5427 - accuracy: 0.7778 - val_loss: 0.8110 - val_accuracy: 0.5625\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5426 - accuracy: 0.7778 - val_loss: 0.8114 - val_accuracy: 0.5625\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5425 - accuracy: 0.7778 - val_loss: 0.8118 - val_accuracy: 0.5625\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5424 - accuracy: 0.7778 - val_loss: 0.8121 - val_accuracy: 0.5625\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5423 - accuracy: 0.7778 - val_loss: 0.8125 - val_accuracy: 0.5625\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5422 - accuracy: 0.7778 - val_loss: 0.8128 - val_accuracy: 0.5625\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5421 - accuracy: 0.7778 - val_loss: 0.8132 - val_accuracy: 0.5625\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5420 - accuracy: 0.7778 - val_loss: 0.8135 - val_accuracy: 0.5625\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5419 - accuracy: 0.7778 - val_loss: 0.8139 - val_accuracy: 0.5625\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5418 - accuracy: 0.7778 - val_loss: 0.8142 - val_accuracy: 0.5625\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5417 - accuracy: 0.7778 - val_loss: 0.8146 - val_accuracy: 0.5625\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5416 - accuracy: 0.7778 - val_loss: 0.8149 - val_accuracy: 0.5625\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5416 - accuracy: 0.7778 - val_loss: 0.8153 - val_accuracy: 0.5625\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5415 - accuracy: 0.7778 - val_loss: 0.8156 - val_accuracy: 0.5625\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5414 - accuracy: 0.7778 - val_loss: 0.8160 - val_accuracy: 0.5625\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5413 - accuracy: 0.7778 - val_loss: 0.8163 - val_accuracy: 0.5625\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5412 - accuracy: 0.7778 - val_loss: 0.8167 - val_accuracy: 0.5625\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5411 - accuracy: 0.7778 - val_loss: 0.8170 - val_accuracy: 0.5625\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5410 - accuracy: 0.7778 - val_loss: 0.8174 - val_accuracy: 0.5625\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5409 - accuracy: 0.7778 - val_loss: 0.8177 - val_accuracy: 0.5625\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5409 - accuracy: 0.7778 - val_loss: 0.8181 - val_accuracy: 0.5625\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5408 - accuracy: 0.7778 - val_loss: 0.8184 - val_accuracy: 0.5625\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5407 - accuracy: 0.7778 - val_loss: 0.8188 - val_accuracy: 0.5625\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5406 - accuracy: 0.7778 - val_loss: 0.8191 - val_accuracy: 0.5625\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5405 - accuracy: 0.7778 - val_loss: 0.8195 - val_accuracy: 0.5625\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5404 - accuracy: 0.7778 - val_loss: 0.8198 - val_accuracy: 0.5625\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5403 - accuracy: 0.7778 - val_loss: 0.8201 - val_accuracy: 0.5625\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5403 - accuracy: 0.7778 - val_loss: 0.8205 - val_accuracy: 0.5625\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5402 - accuracy: 0.7778 - val_loss: 0.8208 - val_accuracy: 0.5625\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5401 - accuracy: 0.7778 - val_loss: 0.8211 - val_accuracy: 0.5625\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5400 - accuracy: 0.7778 - val_loss: 0.8215 - val_accuracy: 0.5625\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5399 - accuracy: 0.7778 - val_loss: 0.8218 - val_accuracy: 0.5625\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5399 - accuracy: 0.7778 - val_loss: 0.8222 - val_accuracy: 0.5625\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5398 - accuracy: 0.7778 - val_loss: 0.8225 - val_accuracy: 0.5625\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5397 - accuracy: 0.7778 - val_loss: 0.8228 - val_accuracy: 0.5625\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5396 - accuracy: 0.7778 - val_loss: 0.8231 - val_accuracy: 0.5625\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5396 - accuracy: 0.7778 - val_loss: 0.8235 - val_accuracy: 0.5625\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5395 - accuracy: 0.7778 - val_loss: 0.8238 - val_accuracy: 0.5625\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5394 - accuracy: 0.7778 - val_loss: 0.8242 - val_accuracy: 0.5625\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5393 - accuracy: 0.7778 - val_loss: 0.8245 - val_accuracy: 0.5625\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5392 - accuracy: 0.7778 - val_loss: 0.8248 - val_accuracy: 0.5625\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5392 - accuracy: 0.7619 - val_loss: 0.8251 - val_accuracy: 0.5625\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5391 - accuracy: 0.7619 - val_loss: 0.8255 - val_accuracy: 0.5625\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5390 - accuracy: 0.7619 - val_loss: 0.8258 - val_accuracy: 0.5625\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5389 - accuracy: 0.7619 - val_loss: 0.8261 - val_accuracy: 0.5625\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5389 - accuracy: 0.7619 - val_loss: 0.8265 - val_accuracy: 0.5625\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5388 - accuracy: 0.7619 - val_loss: 0.8268 - val_accuracy: 0.5625\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5387 - accuracy: 0.7302 - val_loss: 0.8271 - val_accuracy: 0.5625\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5387 - accuracy: 0.7302 - val_loss: 0.8274 - val_accuracy: 0.5625\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5386 - accuracy: 0.7302 - val_loss: 0.8278 - val_accuracy: 0.5625\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5385 - accuracy: 0.7302 - val_loss: 0.8281 - val_accuracy: 0.5625\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5384 - accuracy: 0.7302 - val_loss: 0.8284 - val_accuracy: 0.5625\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5384 - accuracy: 0.7302 - val_loss: 0.8287 - val_accuracy: 0.5625\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5383 - accuracy: 0.7302 - val_loss: 0.8290 - val_accuracy: 0.5625\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5382 - accuracy: 0.7302 - val_loss: 0.8294 - val_accuracy: 0.5625\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5382 - accuracy: 0.7302 - val_loss: 0.8297 - val_accuracy: 0.5625\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5381 - accuracy: 0.7302 - val_loss: 0.8300 - val_accuracy: 0.5625\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5380 - accuracy: 0.7302 - val_loss: 0.8303 - val_accuracy: 0.5625\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5380 - accuracy: 0.7302 - val_loss: 0.8306 - val_accuracy: 0.5625\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5379 - accuracy: 0.7302 - val_loss: 0.8309 - val_accuracy: 0.5625\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5378 - accuracy: 0.7302 - val_loss: 0.8313 - val_accuracy: 0.5625\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5378 - accuracy: 0.7302 - val_loss: 0.8316 - val_accuracy: 0.5625\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5377 - accuracy: 0.7302 - val_loss: 0.8319 - val_accuracy: 0.5625\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5376 - accuracy: 0.7302 - val_loss: 0.8322 - val_accuracy: 0.5625\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5376 - accuracy: 0.7302 - val_loss: 0.8325 - val_accuracy: 0.5625\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5375 - accuracy: 0.7302 - val_loss: 0.8328 - val_accuracy: 0.5625\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5374 - accuracy: 0.7302 - val_loss: 0.8331 - val_accuracy: 0.5625\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5374 - accuracy: 0.7302 - val_loss: 0.8334 - val_accuracy: 0.5625\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5373 - accuracy: 0.7302 - val_loss: 0.8338 - val_accuracy: 0.5625\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5372 - accuracy: 0.7302 - val_loss: 0.8341 - val_accuracy: 0.5625\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5372 - accuracy: 0.7302 - val_loss: 0.8344 - val_accuracy: 0.5625\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5371 - accuracy: 0.7302 - val_loss: 0.8347 - val_accuracy: 0.5625\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5371 - accuracy: 0.7302 - val_loss: 0.8350 - val_accuracy: 0.5625\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5370 - accuracy: 0.7302 - val_loss: 0.8353 - val_accuracy: 0.5625\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5369 - accuracy: 0.7302 - val_loss: 0.8356 - val_accuracy: 0.5625\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5369 - accuracy: 0.7302 - val_loss: 0.8359 - val_accuracy: 0.5625\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5368 - accuracy: 0.7302 - val_loss: 0.8362 - val_accuracy: 0.5625\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5368 - accuracy: 0.7302 - val_loss: 0.8365 - val_accuracy: 0.5625\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5367 - accuracy: 0.7302 - val_loss: 0.8368 - val_accuracy: 0.5625\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5366 - accuracy: 0.7302 - val_loss: 0.8371 - val_accuracy: 0.5625\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5366 - accuracy: 0.7302 - val_loss: 0.8374 - val_accuracy: 0.5625\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5365 - accuracy: 0.7302 - val_loss: 0.8377 - val_accuracy: 0.5625\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5365 - accuracy: 0.7302 - val_loss: 0.8380 - val_accuracy: 0.5625\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5364 - accuracy: 0.7302 - val_loss: 0.8383 - val_accuracy: 0.5625\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5364 - accuracy: 0.7302 - val_loss: 0.8386 - val_accuracy: 0.5625\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5363 - accuracy: 0.7302 - val_loss: 0.8389 - val_accuracy: 0.5625\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5362 - accuracy: 0.7302 - val_loss: 0.8392 - val_accuracy: 0.5625\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5362 - accuracy: 0.7302 - val_loss: 0.8395 - val_accuracy: 0.5625\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5361 - accuracy: 0.7302 - val_loss: 0.8398 - val_accuracy: 0.5625\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5361 - accuracy: 0.7302 - val_loss: 0.8401 - val_accuracy: 0.5625\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5360 - accuracy: 0.7302 - val_loss: 0.8404 - val_accuracy: 0.5625\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5360 - accuracy: 0.7302 - val_loss: 0.8407 - val_accuracy: 0.5625\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5359 - accuracy: 0.7302 - val_loss: 0.8410 - val_accuracy: 0.5625\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5359 - accuracy: 0.7302 - val_loss: 0.8413 - val_accuracy: 0.5625\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5358 - accuracy: 0.7302 - val_loss: 0.8416 - val_accuracy: 0.5625\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5357 - accuracy: 0.7302 - val_loss: 0.8419 - val_accuracy: 0.5625\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5357 - accuracy: 0.7302 - val_loss: 0.8421 - val_accuracy: 0.5625\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5356 - accuracy: 0.7302 - val_loss: 0.8424 - val_accuracy: 0.5625\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5356 - accuracy: 0.7302 - val_loss: 0.8427 - val_accuracy: 0.5625\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5355 - accuracy: 0.7302 - val_loss: 0.8430 - val_accuracy: 0.5625\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5355 - accuracy: 0.7302 - val_loss: 0.8433 - val_accuracy: 0.5625\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5354 - accuracy: 0.7302 - val_loss: 0.8436 - val_accuracy: 0.5625\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5354 - accuracy: 0.7302 - val_loss: 0.8439 - val_accuracy: 0.5625\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5353 - accuracy: 0.7302 - val_loss: 0.8442 - val_accuracy: 0.5625\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5353 - accuracy: 0.7302 - val_loss: 0.8444 - val_accuracy: 0.5625\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5352 - accuracy: 0.7302 - val_loss: 0.8447 - val_accuracy: 0.5625\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5352 - accuracy: 0.7302 - val_loss: 0.8450 - val_accuracy: 0.5625\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5351 - accuracy: 0.7302 - val_loss: 0.8453 - val_accuracy: 0.5625\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5351 - accuracy: 0.7302 - val_loss: 0.8456 - val_accuracy: 0.5625\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5350 - accuracy: 0.7302 - val_loss: 0.8458 - val_accuracy: 0.5625\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5350 - accuracy: 0.7302 - val_loss: 0.8461 - val_accuracy: 0.5625\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5350 - accuracy: 0.7302 - val_loss: 0.8464 - val_accuracy: 0.5625\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5349 - accuracy: 0.7302 - val_loss: 0.8467 - val_accuracy: 0.5625\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5349 - accuracy: 0.7460 - val_loss: 0.8470 - val_accuracy: 0.5625\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5348 - accuracy: 0.7460 - val_loss: 0.8472 - val_accuracy: 0.5625\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5348 - accuracy: 0.7460 - val_loss: 0.8475 - val_accuracy: 0.5625\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5347 - accuracy: 0.7460 - val_loss: 0.8478 - val_accuracy: 0.5625\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5347 - accuracy: 0.7460 - val_loss: 0.8481 - val_accuracy: 0.5625\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5346 - accuracy: 0.7460 - val_loss: 0.8483 - val_accuracy: 0.5625\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5346 - accuracy: 0.7460 - val_loss: 0.8486 - val_accuracy: 0.5625\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5345 - accuracy: 0.7460 - val_loss: 0.8489 - val_accuracy: 0.5625\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5345 - accuracy: 0.7460 - val_loss: 0.8492 - val_accuracy: 0.5625\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5345 - accuracy: 0.7460 - val_loss: 0.8494 - val_accuracy: 0.5625\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5344 - accuracy: 0.7460 - val_loss: 0.8497 - val_accuracy: 0.5625\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5344 - accuracy: 0.7460 - val_loss: 0.8500 - val_accuracy: 0.5625\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5343 - accuracy: 0.7460 - val_loss: 0.8503 - val_accuracy: 0.5625\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5343 - accuracy: 0.7460 - val_loss: 0.8505 - val_accuracy: 0.5625\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5342 - accuracy: 0.7460 - val_loss: 0.8508 - val_accuracy: 0.5625\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5342 - accuracy: 0.7460 - val_loss: 0.8511 - val_accuracy: 0.5625\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5342 - accuracy: 0.7460 - val_loss: 0.8513 - val_accuracy: 0.5625\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5341 - accuracy: 0.7460 - val_loss: 0.8516 - val_accuracy: 0.5625\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5341 - accuracy: 0.7460 - val_loss: 0.8519 - val_accuracy: 0.5625\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5340 - accuracy: 0.7460 - val_loss: 0.8521 - val_accuracy: 0.5625\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5340 - accuracy: 0.7460 - val_loss: 0.8524 - val_accuracy: 0.5625\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5339 - accuracy: 0.7460 - val_loss: 0.8527 - val_accuracy: 0.5625\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5339 - accuracy: 0.7460 - val_loss: 0.8529 - val_accuracy: 0.5625\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5339 - accuracy: 0.7460 - val_loss: 0.8532 - val_accuracy: 0.5625\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5338 - accuracy: 0.7460 - val_loss: 0.8535 - val_accuracy: 0.5625\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5338 - accuracy: 0.7460 - val_loss: 0.8537 - val_accuracy: 0.5625\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5337 - accuracy: 0.7460 - val_loss: 0.8540 - val_accuracy: 0.5625\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5337 - accuracy: 0.7460 - val_loss: 0.8542 - val_accuracy: 0.5625\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5337 - accuracy: 0.7460 - val_loss: 0.8545 - val_accuracy: 0.5625\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5336 - accuracy: 0.7460 - val_loss: 0.8548 - val_accuracy: 0.5625\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5336 - accuracy: 0.7460 - val_loss: 0.8550 - val_accuracy: 0.5625\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5336 - accuracy: 0.7460 - val_loss: 0.8553 - val_accuracy: 0.5625\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5335 - accuracy: 0.7460 - val_loss: 0.8555 - val_accuracy: 0.5625\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5335 - accuracy: 0.7460 - val_loss: 0.8558 - val_accuracy: 0.5625\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5334 - accuracy: 0.7460 - val_loss: 0.8560 - val_accuracy: 0.5625\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5334 - accuracy: 0.7460 - val_loss: 0.8563 - val_accuracy: 0.5625\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5334 - accuracy: 0.7460 - val_loss: 0.8566 - val_accuracy: 0.5625\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5333 - accuracy: 0.7460 - val_loss: 0.8568 - val_accuracy: 0.5625\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5333 - accuracy: 0.7460 - val_loss: 0.8571 - val_accuracy: 0.5625\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5333 - accuracy: 0.7460 - val_loss: 0.8573 - val_accuracy: 0.5625\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5332 - accuracy: 0.7460 - val_loss: 0.8576 - val_accuracy: 0.5625\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5332 - accuracy: 0.7460 - val_loss: 0.8578 - val_accuracy: 0.5625\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5332 - accuracy: 0.7460 - val_loss: 0.8581 - val_accuracy: 0.5625\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5331 - accuracy: 0.7460 - val_loss: 0.8583 - val_accuracy: 0.5625\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5331 - accuracy: 0.7460 - val_loss: 0.8586 - val_accuracy: 0.5625\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5331 - accuracy: 0.7460 - val_loss: 0.8588 - val_accuracy: 0.5625\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5330 - accuracy: 0.7460 - val_loss: 0.8591 - val_accuracy: 0.5625\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5330 - accuracy: 0.7460 - val_loss: 0.8593 - val_accuracy: 0.5625\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5330 - accuracy: 0.7460 - val_loss: 0.8596 - val_accuracy: 0.5000\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5329 - accuracy: 0.7460 - val_loss: 0.8598 - val_accuracy: 0.5000\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5329 - accuracy: 0.7460 - val_loss: 0.8600 - val_accuracy: 0.5000\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5329 - accuracy: 0.7460 - val_loss: 0.8603 - val_accuracy: 0.5000\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5328 - accuracy: 0.7460 - val_loss: 0.8605 - val_accuracy: 0.5000\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5328 - accuracy: 0.7460 - val_loss: 0.8608 - val_accuracy: 0.5000\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5328 - accuracy: 0.7460 - val_loss: 0.8610 - val_accuracy: 0.5000\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5327 - accuracy: 0.7460 - val_loss: 0.8613 - val_accuracy: 0.5000\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5327 - accuracy: 0.7460 - val_loss: 0.8615 - val_accuracy: 0.5000\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5327 - accuracy: 0.7460 - val_loss: 0.8617 - val_accuracy: 0.5000\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5326 - accuracy: 0.7460 - val_loss: 0.8620 - val_accuracy: 0.5000\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5326 - accuracy: 0.7460 - val_loss: 0.8622 - val_accuracy: 0.5000\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5326 - accuracy: 0.7460 - val_loss: 0.8625 - val_accuracy: 0.5000\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5325 - accuracy: 0.7460 - val_loss: 0.8627 - val_accuracy: 0.5000\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5325 - accuracy: 0.7460 - val_loss: 0.8629 - val_accuracy: 0.5000\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5325 - accuracy: 0.7460 - val_loss: 0.8632 - val_accuracy: 0.5000\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5325 - accuracy: 0.7460 - val_loss: 0.8634 - val_accuracy: 0.5000\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5324 - accuracy: 0.7460 - val_loss: 0.8637 - val_accuracy: 0.5000\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5324 - accuracy: 0.7460 - val_loss: 0.8639 - val_accuracy: 0.5000\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5324 - accuracy: 0.7460 - val_loss: 0.8641 - val_accuracy: 0.5000\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5323 - accuracy: 0.7460 - val_loss: 0.8643 - val_accuracy: 0.5000\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5323 - accuracy: 0.7460 - val_loss: 0.8646 - val_accuracy: 0.5000\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5323 - accuracy: 0.7460 - val_loss: 0.8648 - val_accuracy: 0.5000\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5323 - accuracy: 0.7460 - val_loss: 0.8650 - val_accuracy: 0.5000\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5322 - accuracy: 0.7460 - val_loss: 0.8653 - val_accuracy: 0.5000\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5322 - accuracy: 0.7460 - val_loss: 0.8655 - val_accuracy: 0.5000\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5322 - accuracy: 0.7460 - val_loss: 0.8657 - val_accuracy: 0.5000\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5321 - accuracy: 0.7460 - val_loss: 0.8660 - val_accuracy: 0.5000\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5321 - accuracy: 0.7460 - val_loss: 0.8662 - val_accuracy: 0.5000\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5321 - accuracy: 0.7460 - val_loss: 0.8664 - val_accuracy: 0.5000\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5321 - accuracy: 0.7460 - val_loss: 0.8667 - val_accuracy: 0.5000\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7460 - val_loss: 0.8669 - val_accuracy: 0.5000\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7460 - val_loss: 0.8671 - val_accuracy: 0.5000\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7460 - val_loss: 0.8673 - val_accuracy: 0.5000\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7460 - val_loss: 0.8676 - val_accuracy: 0.5000\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5319 - accuracy: 0.7460 - val_loss: 0.8678 - val_accuracy: 0.5000\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5319 - accuracy: 0.7460 - val_loss: 0.8680 - val_accuracy: 0.5000\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5319 - accuracy: 0.7460 - val_loss: 0.8682 - val_accuracy: 0.5000\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5319 - accuracy: 0.7460 - val_loss: 0.8685 - val_accuracy: 0.5000\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5318 - accuracy: 0.7460 - val_loss: 0.8687 - val_accuracy: 0.5000\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5318 - accuracy: 0.7460 - val_loss: 0.8689 - val_accuracy: 0.5000\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5318 - accuracy: 0.7460 - val_loss: 0.8691 - val_accuracy: 0.5000\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5318 - accuracy: 0.7460 - val_loss: 0.8693 - val_accuracy: 0.5000\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5317 - accuracy: 0.7460 - val_loss: 0.8696 - val_accuracy: 0.5000\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5317 - accuracy: 0.7460 - val_loss: 0.8698 - val_accuracy: 0.5000\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5317 - accuracy: 0.7460 - val_loss: 0.8700 - val_accuracy: 0.5000\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5317 - accuracy: 0.7460 - val_loss: 0.8702 - val_accuracy: 0.5000\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5316 - accuracy: 0.7460 - val_loss: 0.8704 - val_accuracy: 0.5000\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5316 - accuracy: 0.7460 - val_loss: 0.8706 - val_accuracy: 0.5000\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5316 - accuracy: 0.7460 - val_loss: 0.8709 - val_accuracy: 0.5000\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5316 - accuracy: 0.7460 - val_loss: 0.8711 - val_accuracy: 0.5000\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5316 - accuracy: 0.7460 - val_loss: 0.8713 - val_accuracy: 0.5000\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5315 - accuracy: 0.7460 - val_loss: 0.8715 - val_accuracy: 0.5000\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5315 - accuracy: 0.7460 - val_loss: 0.8717 - val_accuracy: 0.5000\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5315 - accuracy: 0.7460 - val_loss: 0.8719 - val_accuracy: 0.5000\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5315 - accuracy: 0.7460 - val_loss: 0.8721 - val_accuracy: 0.5000\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5314 - accuracy: 0.7460 - val_loss: 0.8723 - val_accuracy: 0.4375\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5314 - accuracy: 0.7460 - val_loss: 0.8726 - val_accuracy: 0.4375\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5314 - accuracy: 0.7460 - val_loss: 0.8728 - val_accuracy: 0.4375\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5314 - accuracy: 0.7460 - val_loss: 0.8730 - val_accuracy: 0.4375\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5314 - accuracy: 0.7460 - val_loss: 0.8732 - val_accuracy: 0.4375\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5313 - accuracy: 0.7460 - val_loss: 0.8734 - val_accuracy: 0.4375\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5313 - accuracy: 0.7460 - val_loss: 0.8736 - val_accuracy: 0.4375\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5313 - accuracy: 0.7460 - val_loss: 0.8738 - val_accuracy: 0.4375\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5313 - accuracy: 0.7460 - val_loss: 0.8740 - val_accuracy: 0.4375\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5313 - accuracy: 0.7460 - val_loss: 0.8742 - val_accuracy: 0.4375\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5312 - accuracy: 0.7460 - val_loss: 0.8744 - val_accuracy: 0.4375\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5312 - accuracy: 0.7460 - val_loss: 0.8746 - val_accuracy: 0.4375\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5312 - accuracy: 0.7460 - val_loss: 0.8748 - val_accuracy: 0.4375\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5312 - accuracy: 0.7460 - val_loss: 0.8750 - val_accuracy: 0.4375\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5312 - accuracy: 0.7460 - val_loss: 0.8752 - val_accuracy: 0.4375\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5311 - accuracy: 0.7460 - val_loss: 0.8754 - val_accuracy: 0.4375\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5311 - accuracy: 0.7460 - val_loss: 0.8756 - val_accuracy: 0.4375\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5311 - accuracy: 0.7460 - val_loss: 0.8758 - val_accuracy: 0.4375\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5311 - accuracy: 0.7460 - val_loss: 0.8760 - val_accuracy: 0.4375\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5311 - accuracy: 0.7460 - val_loss: 0.8762 - val_accuracy: 0.4375\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.8764 - val_accuracy: 0.4375\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.8766 - val_accuracy: 0.4375\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.8768 - val_accuracy: 0.4375\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.8770 - val_accuracy: 0.4375\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.8772 - val_accuracy: 0.4375\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5310 - accuracy: 0.7460 - val_loss: 0.8774 - val_accuracy: 0.4375\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5309 - accuracy: 0.7460 - val_loss: 0.8776 - val_accuracy: 0.4375\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5309 - accuracy: 0.7460 - val_loss: 0.8778 - val_accuracy: 0.4375\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5309 - accuracy: 0.7460 - val_loss: 0.8780 - val_accuracy: 0.4375\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5309 - accuracy: 0.7460 - val_loss: 0.8782 - val_accuracy: 0.4375\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5309 - accuracy: 0.7460 - val_loss: 0.8784 - val_accuracy: 0.4375\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5308 - accuracy: 0.7460 - val_loss: 0.8786 - val_accuracy: 0.4375\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5308 - accuracy: 0.7460 - val_loss: 0.8788 - val_accuracy: 0.4375\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5308 - accuracy: 0.7460 - val_loss: 0.8790 - val_accuracy: 0.4375\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5308 - accuracy: 0.7460 - val_loss: 0.8792 - val_accuracy: 0.4375\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5308 - accuracy: 0.7460 - val_loss: 0.8794 - val_accuracy: 0.4375\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5308 - accuracy: 0.7460 - val_loss: 0.8795 - val_accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics= ['accuracy'])\n",
    "hist1 = model1.fit(x=x_train, y=y_train, epochs=700, validation_split=0.2, batch_size = 64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_37 (Dense)            (None, 40)                240       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,081\n",
      "Trainable params: 1,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Dense(units=40, activation='relu', use_bias=True, input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(units=20, activation='relu', use_bias=True),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', use_bias=True)\n",
    "])\n",
    "\n",
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 3.9093 - accuracy: 0.4127 - val_loss: 3.6453 - val_accuracy: 0.4375\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7144 - accuracy: 0.4127 - val_loss: 3.4555 - val_accuracy: 0.4375\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5194 - accuracy: 0.4127 - val_loss: 3.2671 - val_accuracy: 0.4375\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.3233 - accuracy: 0.4127 - val_loss: 3.0792 - val_accuracy: 0.4375\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1284 - accuracy: 0.4127 - val_loss: 2.8906 - val_accuracy: 0.4375\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.9261 - accuracy: 0.4127 - val_loss: 2.7013 - val_accuracy: 0.4375\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7174 - accuracy: 0.4127 - val_loss: 2.4976 - val_accuracy: 0.4375\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5036 - accuracy: 0.4127 - val_loss: 2.2879 - val_accuracy: 0.4375\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2871 - accuracy: 0.4127 - val_loss: 2.0758 - val_accuracy: 0.4375\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0668 - accuracy: 0.4127 - val_loss: 1.8645 - val_accuracy: 0.4375\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8482 - accuracy: 0.4127 - val_loss: 1.6568 - val_accuracy: 0.4375\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6365 - accuracy: 0.4127 - val_loss: 1.4587 - val_accuracy: 0.4375\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4351 - accuracy: 0.4127 - val_loss: 1.2733 - val_accuracy: 0.4375\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2479 - accuracy: 0.4127 - val_loss: 1.1051 - val_accuracy: 0.4375\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0786 - accuracy: 0.4127 - val_loss: 0.9620 - val_accuracy: 0.4375\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9324 - accuracy: 0.4127 - val_loss: 0.8478 - val_accuracy: 0.4375\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8147 - accuracy: 0.4127 - val_loss: 0.7676 - val_accuracy: 0.4375\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7295 - accuracy: 0.4286 - val_loss: 0.7230 - val_accuracy: 0.4375\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6786 - accuracy: 0.6825 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6575 - accuracy: 0.5873 - val_loss: 0.7196 - val_accuracy: 0.5625\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6599 - accuracy: 0.5873 - val_loss: 0.7458 - val_accuracy: 0.5625\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6782 - accuracy: 0.5873 - val_loss: 0.7799 - val_accuracy: 0.5625\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7046 - accuracy: 0.5873 - val_loss: 0.8145 - val_accuracy: 0.5625\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7329 - accuracy: 0.5873 - val_loss: 0.8450 - val_accuracy: 0.5625\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7587 - accuracy: 0.5873 - val_loss: 0.8689 - val_accuracy: 0.5625\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7797 - accuracy: 0.5873 - val_loss: 0.8859 - val_accuracy: 0.5625\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7950 - accuracy: 0.5873 - val_loss: 0.8956 - val_accuracy: 0.5625\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8037 - accuracy: 0.5873 - val_loss: 0.8982 - val_accuracy: 0.5625\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8062 - accuracy: 0.5873 - val_loss: 0.8943 - val_accuracy: 0.5625\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8027 - accuracy: 0.5873 - val_loss: 0.8847 - val_accuracy: 0.5625\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7941 - accuracy: 0.5873 - val_loss: 0.8704 - val_accuracy: 0.5625\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7812 - accuracy: 0.5873 - val_loss: 0.8527 - val_accuracy: 0.5625\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7653 - accuracy: 0.5873 - val_loss: 0.8327 - val_accuracy: 0.5625\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7475 - accuracy: 0.5873 - val_loss: 0.8117 - val_accuracy: 0.5625\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7288 - accuracy: 0.5873 - val_loss: 0.7909 - val_accuracy: 0.5625\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7104 - accuracy: 0.5873 - val_loss: 0.7714 - val_accuracy: 0.5625\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.5873 - val_loss: 0.7540 - val_accuracy: 0.5625\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6781 - accuracy: 0.5873 - val_loss: 0.7395 - val_accuracy: 0.5625\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6656 - accuracy: 0.5873 - val_loss: 0.7282 - val_accuracy: 0.5625\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6561 - accuracy: 0.5873 - val_loss: 0.7203 - val_accuracy: 0.5625\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6498 - accuracy: 0.5873 - val_loss: 0.7157 - val_accuracy: 0.5625\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6465 - accuracy: 0.5873 - val_loss: 0.7140 - val_accuracy: 0.5625\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6458 - accuracy: 0.5873 - val_loss: 0.7146 - val_accuracy: 0.5625\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6471 - accuracy: 0.5714 - val_loss: 0.7168 - val_accuracy: 0.3750\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6497 - accuracy: 0.6032 - val_loss: 0.7199 - val_accuracy: 0.4375\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6531 - accuracy: 0.6508 - val_loss: 0.7231 - val_accuracy: 0.4375\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6564 - accuracy: 0.6825 - val_loss: 0.7260 - val_accuracy: 0.3750\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6593 - accuracy: 0.7143 - val_loss: 0.7282 - val_accuracy: 0.3750\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6612 - accuracy: 0.6984 - val_loss: 0.7293 - val_accuracy: 0.3750\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6622 - accuracy: 0.6667 - val_loss: 0.7295 - val_accuracy: 0.3750\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6619 - accuracy: 0.6667 - val_loss: 0.7286 - val_accuracy: 0.3750\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6607 - accuracy: 0.6667 - val_loss: 0.7270 - val_accuracy: 0.3750\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6586 - accuracy: 0.7143 - val_loss: 0.7248 - val_accuracy: 0.4375\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6559 - accuracy: 0.7302 - val_loss: 0.7224 - val_accuracy: 0.4375\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6529 - accuracy: 0.6825 - val_loss: 0.7200 - val_accuracy: 0.4375\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6498 - accuracy: 0.6508 - val_loss: 0.7178 - val_accuracy: 0.4375\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6470 - accuracy: 0.6349 - val_loss: 0.7161 - val_accuracy: 0.5000\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6446 - accuracy: 0.6190 - val_loss: 0.7150 - val_accuracy: 0.5000\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6427 - accuracy: 0.5873 - val_loss: 0.7144 - val_accuracy: 0.6250\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6414 - accuracy: 0.5873 - val_loss: 0.7143 - val_accuracy: 0.6250\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6405 - accuracy: 0.5873 - val_loss: 0.7147 - val_accuracy: 0.5625\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6402 - accuracy: 0.5873 - val_loss: 0.7154 - val_accuracy: 0.5625\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6401 - accuracy: 0.5873 - val_loss: 0.7162 - val_accuracy: 0.5625\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6403 - accuracy: 0.5873 - val_loss: 0.7171 - val_accuracy: 0.5625\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6406 - accuracy: 0.5873 - val_loss: 0.7180 - val_accuracy: 0.5625\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6409 - accuracy: 0.5873 - val_loss: 0.7186 - val_accuracy: 0.5625\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6411 - accuracy: 0.5873 - val_loss: 0.7191 - val_accuracy: 0.5625\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6411 - accuracy: 0.5873 - val_loss: 0.7193 - val_accuracy: 0.5625\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6409 - accuracy: 0.5873 - val_loss: 0.7192 - val_accuracy: 0.5625\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6405 - accuracy: 0.5873 - val_loss: 0.7189 - val_accuracy: 0.5625\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6399 - accuracy: 0.5873 - val_loss: 0.7185 - val_accuracy: 0.5625\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6393 - accuracy: 0.5873 - val_loss: 0.7179 - val_accuracy: 0.5625\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6385 - accuracy: 0.5873 - val_loss: 0.7173 - val_accuracy: 0.5625\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6378 - accuracy: 0.5873 - val_loss: 0.7167 - val_accuracy: 0.5625\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6370 - accuracy: 0.5873 - val_loss: 0.7162 - val_accuracy: 0.5625\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6364 - accuracy: 0.5873 - val_loss: 0.7158 - val_accuracy: 0.5625\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6358 - accuracy: 0.5873 - val_loss: 0.7154 - val_accuracy: 0.6250\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6353 - accuracy: 0.5873 - val_loss: 0.7152 - val_accuracy: 0.6250\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6349 - accuracy: 0.5873 - val_loss: 0.7151 - val_accuracy: 0.6250\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6346 - accuracy: 0.5873 - val_loss: 0.7151 - val_accuracy: 0.6250\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6343 - accuracy: 0.5873 - val_loss: 0.7152 - val_accuracy: 0.6250\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6341 - accuracy: 0.6032 - val_loss: 0.7153 - val_accuracy: 0.6250\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6339 - accuracy: 0.6032 - val_loss: 0.7154 - val_accuracy: 0.6250\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6337 - accuracy: 0.6032 - val_loss: 0.7155 - val_accuracy: 0.6250\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6334 - accuracy: 0.6032 - val_loss: 0.7155 - val_accuracy: 0.6250\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6331 - accuracy: 0.6032 - val_loss: 0.7156 - val_accuracy: 0.6250\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6328 - accuracy: 0.6032 - val_loss: 0.7157 - val_accuracy: 0.6250\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6324 - accuracy: 0.6032 - val_loss: 0.7157 - val_accuracy: 0.6250\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6321 - accuracy: 0.6032 - val_loss: 0.7157 - val_accuracy: 0.6250\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6317 - accuracy: 0.6032 - val_loss: 0.7157 - val_accuracy: 0.6250\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6312 - accuracy: 0.6032 - val_loss: 0.7158 - val_accuracy: 0.6250\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6308 - accuracy: 0.6032 - val_loss: 0.7159 - val_accuracy: 0.6250\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6304 - accuracy: 0.6032 - val_loss: 0.7159 - val_accuracy: 0.6250\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6301 - accuracy: 0.6032 - val_loss: 0.7160 - val_accuracy: 0.6250\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6297 - accuracy: 0.6032 - val_loss: 0.7161 - val_accuracy: 0.6250\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6294 - accuracy: 0.6032 - val_loss: 0.7163 - val_accuracy: 0.6250\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6291 - accuracy: 0.6032 - val_loss: 0.7164 - val_accuracy: 0.6250\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6288 - accuracy: 0.6032 - val_loss: 0.7165 - val_accuracy: 0.6250\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6284 - accuracy: 0.6032 - val_loss: 0.7166 - val_accuracy: 0.6250\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6281 - accuracy: 0.6032 - val_loss: 0.7167 - val_accuracy: 0.6250\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6278 - accuracy: 0.6032 - val_loss: 0.7168 - val_accuracy: 0.6250\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6275 - accuracy: 0.6032 - val_loss: 0.7169 - val_accuracy: 0.6250\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6272 - accuracy: 0.6032 - val_loss: 0.7170 - val_accuracy: 0.6250\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6268 - accuracy: 0.6032 - val_loss: 0.7170 - val_accuracy: 0.6250\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6265 - accuracy: 0.6032 - val_loss: 0.7171 - val_accuracy: 0.6250\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6262 - accuracy: 0.6032 - val_loss: 0.7171 - val_accuracy: 0.6250\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6258 - accuracy: 0.6032 - val_loss: 0.7171 - val_accuracy: 0.6250\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6255 - accuracy: 0.6032 - val_loss: 0.7172 - val_accuracy: 0.6250\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6251 - accuracy: 0.6032 - val_loss: 0.7172 - val_accuracy: 0.6250\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6248 - accuracy: 0.6032 - val_loss: 0.7173 - val_accuracy: 0.6250\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6244 - accuracy: 0.6190 - val_loss: 0.7174 - val_accuracy: 0.6250\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6241 - accuracy: 0.6190 - val_loss: 0.7174 - val_accuracy: 0.6250\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6238 - accuracy: 0.6190 - val_loss: 0.7175 - val_accuracy: 0.6250\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6234 - accuracy: 0.6190 - val_loss: 0.7176 - val_accuracy: 0.6250\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6231 - accuracy: 0.6349 - val_loss: 0.7177 - val_accuracy: 0.6250\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6228 - accuracy: 0.6349 - val_loss: 0.7178 - val_accuracy: 0.6250\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6224 - accuracy: 0.6349 - val_loss: 0.7179 - val_accuracy: 0.6250\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6221 - accuracy: 0.6349 - val_loss: 0.7180 - val_accuracy: 0.6250\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6218 - accuracy: 0.6349 - val_loss: 0.7181 - val_accuracy: 0.6250\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6214 - accuracy: 0.6349 - val_loss: 0.7182 - val_accuracy: 0.6250\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6211 - accuracy: 0.6349 - val_loss: 0.7183 - val_accuracy: 0.6250\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6208 - accuracy: 0.6349 - val_loss: 0.7184 - val_accuracy: 0.6250\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6204 - accuracy: 0.6349 - val_loss: 0.7185 - val_accuracy: 0.6250\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6201 - accuracy: 0.6349 - val_loss: 0.7186 - val_accuracy: 0.6250\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6197 - accuracy: 0.6349 - val_loss: 0.7187 - val_accuracy: 0.6250\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6194 - accuracy: 0.6349 - val_loss: 0.7188 - val_accuracy: 0.6250\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6191 - accuracy: 0.6349 - val_loss: 0.7189 - val_accuracy: 0.6250\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6187 - accuracy: 0.6349 - val_loss: 0.7190 - val_accuracy: 0.6250\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6184 - accuracy: 0.6349 - val_loss: 0.7191 - val_accuracy: 0.6250\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6180 - accuracy: 0.6349 - val_loss: 0.7192 - val_accuracy: 0.6250\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6177 - accuracy: 0.6349 - val_loss: 0.7193 - val_accuracy: 0.6250\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6174 - accuracy: 0.6349 - val_loss: 0.7194 - val_accuracy: 0.6250\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6170 - accuracy: 0.6349 - val_loss: 0.7196 - val_accuracy: 0.6250\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6167 - accuracy: 0.6349 - val_loss: 0.7197 - val_accuracy: 0.6250\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6164 - accuracy: 0.6349 - val_loss: 0.7198 - val_accuracy: 0.6250\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6160 - accuracy: 0.6349 - val_loss: 0.7199 - val_accuracy: 0.6250\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6157 - accuracy: 0.6349 - val_loss: 0.7200 - val_accuracy: 0.6250\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6153 - accuracy: 0.6349 - val_loss: 0.7201 - val_accuracy: 0.6250\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6150 - accuracy: 0.6349 - val_loss: 0.7203 - val_accuracy: 0.6250\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6146 - accuracy: 0.6349 - val_loss: 0.7204 - val_accuracy: 0.6250\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6143 - accuracy: 0.6349 - val_loss: 0.7205 - val_accuracy: 0.6250\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6140 - accuracy: 0.6349 - val_loss: 0.7206 - val_accuracy: 0.6250\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6136 - accuracy: 0.6349 - val_loss: 0.7208 - val_accuracy: 0.6250\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6133 - accuracy: 0.6349 - val_loss: 0.7209 - val_accuracy: 0.6250\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6129 - accuracy: 0.6190 - val_loss: 0.7210 - val_accuracy: 0.6250\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6126 - accuracy: 0.6190 - val_loss: 0.7211 - val_accuracy: 0.6250\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6123 - accuracy: 0.6190 - val_loss: 0.7213 - val_accuracy: 0.6250\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6119 - accuracy: 0.6508 - val_loss: 0.7214 - val_accuracy: 0.6250\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6116 - accuracy: 0.6508 - val_loss: 0.7216 - val_accuracy: 0.6250\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6112 - accuracy: 0.6508 - val_loss: 0.7217 - val_accuracy: 0.6250\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6109 - accuracy: 0.6508 - val_loss: 0.7218 - val_accuracy: 0.6250\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6105 - accuracy: 0.6508 - val_loss: 0.7220 - val_accuracy: 0.6250\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6102 - accuracy: 0.6508 - val_loss: 0.7221 - val_accuracy: 0.6250\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6099 - accuracy: 0.6508 - val_loss: 0.7223 - val_accuracy: 0.6250\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6095 - accuracy: 0.6508 - val_loss: 0.7224 - val_accuracy: 0.6250\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6092 - accuracy: 0.6508 - val_loss: 0.7226 - val_accuracy: 0.6250\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6088 - accuracy: 0.6508 - val_loss: 0.7227 - val_accuracy: 0.6250\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6085 - accuracy: 0.6508 - val_loss: 0.7229 - val_accuracy: 0.6250\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6082 - accuracy: 0.6508 - val_loss: 0.7230 - val_accuracy: 0.6250\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6078 - accuracy: 0.6508 - val_loss: 0.7232 - val_accuracy: 0.6250\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6075 - accuracy: 0.6508 - val_loss: 0.7233 - val_accuracy: 0.6250\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6071 - accuracy: 0.6508 - val_loss: 0.7235 - val_accuracy: 0.6250\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6068 - accuracy: 0.6508 - val_loss: 0.7237 - val_accuracy: 0.6250\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6064 - accuracy: 0.6508 - val_loss: 0.7238 - val_accuracy: 0.6250\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6061 - accuracy: 0.6508 - val_loss: 0.7240 - val_accuracy: 0.6250\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6058 - accuracy: 0.6508 - val_loss: 0.7241 - val_accuracy: 0.6250\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6054 - accuracy: 0.6508 - val_loss: 0.7243 - val_accuracy: 0.6250\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6051 - accuracy: 0.6508 - val_loss: 0.7245 - val_accuracy: 0.6250\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6047 - accuracy: 0.6508 - val_loss: 0.7247 - val_accuracy: 0.6250\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6044 - accuracy: 0.6508 - val_loss: 0.7248 - val_accuracy: 0.6250\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6040 - accuracy: 0.6508 - val_loss: 0.7250 - val_accuracy: 0.6250\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6037 - accuracy: 0.6667 - val_loss: 0.7252 - val_accuracy: 0.6250\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6033 - accuracy: 0.6667 - val_loss: 0.7254 - val_accuracy: 0.6250\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6030 - accuracy: 0.6667 - val_loss: 0.7255 - val_accuracy: 0.6875\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6027 - accuracy: 0.6667 - val_loss: 0.7257 - val_accuracy: 0.6875\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6023 - accuracy: 0.6508 - val_loss: 0.7259 - val_accuracy: 0.6875\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6020 - accuracy: 0.6508 - val_loss: 0.7261 - val_accuracy: 0.6875\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6016 - accuracy: 0.6508 - val_loss: 0.7263 - val_accuracy: 0.6875\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6013 - accuracy: 0.6508 - val_loss: 0.7265 - val_accuracy: 0.6875\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6009 - accuracy: 0.6508 - val_loss: 0.7267 - val_accuracy: 0.6875\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6006 - accuracy: 0.6508 - val_loss: 0.7269 - val_accuracy: 0.6875\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6003 - accuracy: 0.6508 - val_loss: 0.7271 - val_accuracy: 0.6875\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5999 - accuracy: 0.6508 - val_loss: 0.7272 - val_accuracy: 0.6875\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5996 - accuracy: 0.6667 - val_loss: 0.7274 - val_accuracy: 0.6875\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5992 - accuracy: 0.6667 - val_loss: 0.7276 - val_accuracy: 0.6875\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5989 - accuracy: 0.6825 - val_loss: 0.7279 - val_accuracy: 0.6875\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5986 - accuracy: 0.6825 - val_loss: 0.7281 - val_accuracy: 0.6875\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5982 - accuracy: 0.6825 - val_loss: 0.7283 - val_accuracy: 0.6875\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5979 - accuracy: 0.6825 - val_loss: 0.7285 - val_accuracy: 0.6875\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5975 - accuracy: 0.6825 - val_loss: 0.7287 - val_accuracy: 0.6875\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5972 - accuracy: 0.6825 - val_loss: 0.7289 - val_accuracy: 0.6875\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5968 - accuracy: 0.6825 - val_loss: 0.7291 - val_accuracy: 0.6875\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5965 - accuracy: 0.6825 - val_loss: 0.7293 - val_accuracy: 0.6875\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5962 - accuracy: 0.6984 - val_loss: 0.7295 - val_accuracy: 0.6875\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5958 - accuracy: 0.6984 - val_loss: 0.7298 - val_accuracy: 0.6875\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5955 - accuracy: 0.6984 - val_loss: 0.7300 - val_accuracy: 0.6875\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5951 - accuracy: 0.6825 - val_loss: 0.7302 - val_accuracy: 0.6875\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5948 - accuracy: 0.6825 - val_loss: 0.7304 - val_accuracy: 0.6875\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5945 - accuracy: 0.6825 - val_loss: 0.7307 - val_accuracy: 0.6875\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5941 - accuracy: 0.6825 - val_loss: 0.7309 - val_accuracy: 0.6875\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5938 - accuracy: 0.6825 - val_loss: 0.7311 - val_accuracy: 0.6875\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5934 - accuracy: 0.6825 - val_loss: 0.7314 - val_accuracy: 0.6875\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5931 - accuracy: 0.6825 - val_loss: 0.7316 - val_accuracy: 0.6875\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5928 - accuracy: 0.6825 - val_loss: 0.7318 - val_accuracy: 0.6875\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5924 - accuracy: 0.6825 - val_loss: 0.7321 - val_accuracy: 0.6875\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5921 - accuracy: 0.6825 - val_loss: 0.7323 - val_accuracy: 0.6875\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5917 - accuracy: 0.6825 - val_loss: 0.7326 - val_accuracy: 0.6875\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5914 - accuracy: 0.6825 - val_loss: 0.7328 - val_accuracy: 0.6875\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5911 - accuracy: 0.6825 - val_loss: 0.7331 - val_accuracy: 0.6875\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5907 - accuracy: 0.6825 - val_loss: 0.7333 - val_accuracy: 0.6875\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5904 - accuracy: 0.6825 - val_loss: 0.7336 - val_accuracy: 0.6875\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5900 - accuracy: 0.6984 - val_loss: 0.7338 - val_accuracy: 0.6875\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5897 - accuracy: 0.6984 - val_loss: 0.7341 - val_accuracy: 0.6875\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5894 - accuracy: 0.6984 - val_loss: 0.7343 - val_accuracy: 0.6250\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5890 - accuracy: 0.6984 - val_loss: 0.7346 - val_accuracy: 0.6250\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5887 - accuracy: 0.6984 - val_loss: 0.7349 - val_accuracy: 0.6250\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5883 - accuracy: 0.7143 - val_loss: 0.7351 - val_accuracy: 0.6250\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5880 - accuracy: 0.7143 - val_loss: 0.7354 - val_accuracy: 0.6250\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5877 - accuracy: 0.7143 - val_loss: 0.7357 - val_accuracy: 0.6250\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5873 - accuracy: 0.7143 - val_loss: 0.7359 - val_accuracy: 0.6250\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5870 - accuracy: 0.7143 - val_loss: 0.7362 - val_accuracy: 0.6250\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5866 - accuracy: 0.7143 - val_loss: 0.7365 - val_accuracy: 0.6250\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5863 - accuracy: 0.7143 - val_loss: 0.7368 - val_accuracy: 0.6250\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5860 - accuracy: 0.7143 - val_loss: 0.7370 - val_accuracy: 0.6250\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5856 - accuracy: 0.7143 - val_loss: 0.7373 - val_accuracy: 0.6250\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5853 - accuracy: 0.7143 - val_loss: 0.7376 - val_accuracy: 0.6250\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5850 - accuracy: 0.7143 - val_loss: 0.7379 - val_accuracy: 0.6250\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5846 - accuracy: 0.7143 - val_loss: 0.7382 - val_accuracy: 0.6250\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5843 - accuracy: 0.7143 - val_loss: 0.7385 - val_accuracy: 0.6250\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5840 - accuracy: 0.7143 - val_loss: 0.7387 - val_accuracy: 0.6250\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5836 - accuracy: 0.7143 - val_loss: 0.7390 - val_accuracy: 0.6250\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5833 - accuracy: 0.7143 - val_loss: 0.7393 - val_accuracy: 0.6250\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5830 - accuracy: 0.7143 - val_loss: 0.7396 - val_accuracy: 0.6250\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5826 - accuracy: 0.7143 - val_loss: 0.7399 - val_accuracy: 0.6250\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5823 - accuracy: 0.7143 - val_loss: 0.7402 - val_accuracy: 0.6250\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5820 - accuracy: 0.7143 - val_loss: 0.7405 - val_accuracy: 0.6250\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5817 - accuracy: 0.6984 - val_loss: 0.7408 - val_accuracy: 0.6250\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5813 - accuracy: 0.6984 - val_loss: 0.7411 - val_accuracy: 0.6250\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5810 - accuracy: 0.6984 - val_loss: 0.7415 - val_accuracy: 0.6250\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5807 - accuracy: 0.6984 - val_loss: 0.7418 - val_accuracy: 0.6250\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5804 - accuracy: 0.6984 - val_loss: 0.7421 - val_accuracy: 0.6250\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5800 - accuracy: 0.6984 - val_loss: 0.7424 - val_accuracy: 0.6250\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5797 - accuracy: 0.6984 - val_loss: 0.7427 - val_accuracy: 0.6250\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5794 - accuracy: 0.6984 - val_loss: 0.7430 - val_accuracy: 0.6250\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5791 - accuracy: 0.6984 - val_loss: 0.7434 - val_accuracy: 0.6250\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5788 - accuracy: 0.6984 - val_loss: 0.7437 - val_accuracy: 0.6250\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5785 - accuracy: 0.6984 - val_loss: 0.7440 - val_accuracy: 0.6250\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5781 - accuracy: 0.6984 - val_loss: 0.7444 - val_accuracy: 0.6250\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5778 - accuracy: 0.6984 - val_loss: 0.7447 - val_accuracy: 0.6250\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5775 - accuracy: 0.6984 - val_loss: 0.7450 - val_accuracy: 0.6250\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5772 - accuracy: 0.6984 - val_loss: 0.7454 - val_accuracy: 0.6250\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5769 - accuracy: 0.6984 - val_loss: 0.7457 - val_accuracy: 0.6250\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5766 - accuracy: 0.6984 - val_loss: 0.7460 - val_accuracy: 0.6250\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5762 - accuracy: 0.6984 - val_loss: 0.7464 - val_accuracy: 0.6250\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5759 - accuracy: 0.6984 - val_loss: 0.7467 - val_accuracy: 0.6250\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5756 - accuracy: 0.6984 - val_loss: 0.7471 - val_accuracy: 0.6250\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5753 - accuracy: 0.6984 - val_loss: 0.7474 - val_accuracy: 0.6250\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5750 - accuracy: 0.6984 - val_loss: 0.7478 - val_accuracy: 0.6250\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5747 - accuracy: 0.6984 - val_loss: 0.7481 - val_accuracy: 0.6250\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5744 - accuracy: 0.6984 - val_loss: 0.7485 - val_accuracy: 0.6250\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5741 - accuracy: 0.6984 - val_loss: 0.7488 - val_accuracy: 0.6250\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5738 - accuracy: 0.6984 - val_loss: 0.7492 - val_accuracy: 0.6250\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5735 - accuracy: 0.6984 - val_loss: 0.7496 - val_accuracy: 0.6250\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5732 - accuracy: 0.6984 - val_loss: 0.7499 - val_accuracy: 0.6250\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5729 - accuracy: 0.6984 - val_loss: 0.7503 - val_accuracy: 0.6250\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5725 - accuracy: 0.6984 - val_loss: 0.7506 - val_accuracy: 0.6250\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5722 - accuracy: 0.6984 - val_loss: 0.7510 - val_accuracy: 0.6250\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5719 - accuracy: 0.6984 - val_loss: 0.7514 - val_accuracy: 0.6250\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5716 - accuracy: 0.6984 - val_loss: 0.7518 - val_accuracy: 0.6250\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5713 - accuracy: 0.6984 - val_loss: 0.7521 - val_accuracy: 0.6250\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5710 - accuracy: 0.6984 - val_loss: 0.7525 - val_accuracy: 0.6250\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5707 - accuracy: 0.6984 - val_loss: 0.7529 - val_accuracy: 0.6250\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5704 - accuracy: 0.6984 - val_loss: 0.7533 - val_accuracy: 0.6250\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5701 - accuracy: 0.6984 - val_loss: 0.7536 - val_accuracy: 0.6250\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5698 - accuracy: 0.6984 - val_loss: 0.7540 - val_accuracy: 0.6250\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5695 - accuracy: 0.6984 - val_loss: 0.7544 - val_accuracy: 0.6250\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5692 - accuracy: 0.6984 - val_loss: 0.7548 - val_accuracy: 0.6250\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5689 - accuracy: 0.6984 - val_loss: 0.7552 - val_accuracy: 0.6250\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5686 - accuracy: 0.6984 - val_loss: 0.7556 - val_accuracy: 0.6250\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5683 - accuracy: 0.6984 - val_loss: 0.7560 - val_accuracy: 0.6250\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5680 - accuracy: 0.6984 - val_loss: 0.7563 - val_accuracy: 0.6250\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5677 - accuracy: 0.6984 - val_loss: 0.7567 - val_accuracy: 0.6250\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5674 - accuracy: 0.6984 - val_loss: 0.7571 - val_accuracy: 0.6250\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5671 - accuracy: 0.6984 - val_loss: 0.7575 - val_accuracy: 0.6250\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5668 - accuracy: 0.6984 - val_loss: 0.7579 - val_accuracy: 0.6250\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5665 - accuracy: 0.6984 - val_loss: 0.7583 - val_accuracy: 0.6250\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5662 - accuracy: 0.6984 - val_loss: 0.7587 - val_accuracy: 0.6250\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5659 - accuracy: 0.6984 - val_loss: 0.7591 - val_accuracy: 0.6250\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5656 - accuracy: 0.6984 - val_loss: 0.7595 - val_accuracy: 0.6250\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5653 - accuracy: 0.6984 - val_loss: 0.7599 - val_accuracy: 0.6250\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5651 - accuracy: 0.6984 - val_loss: 0.7604 - val_accuracy: 0.6250\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5648 - accuracy: 0.6984 - val_loss: 0.7608 - val_accuracy: 0.6250\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5645 - accuracy: 0.6984 - val_loss: 0.7612 - val_accuracy: 0.6250\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5642 - accuracy: 0.6984 - val_loss: 0.7616 - val_accuracy: 0.6250\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5639 - accuracy: 0.6984 - val_loss: 0.7620 - val_accuracy: 0.6250\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5636 - accuracy: 0.6984 - val_loss: 0.7624 - val_accuracy: 0.6250\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5633 - accuracy: 0.6984 - val_loss: 0.7628 - val_accuracy: 0.6250\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5631 - accuracy: 0.6984 - val_loss: 0.7633 - val_accuracy: 0.6250\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5628 - accuracy: 0.6984 - val_loss: 0.7637 - val_accuracy: 0.6250\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5625 - accuracy: 0.6984 - val_loss: 0.7641 - val_accuracy: 0.6250\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5622 - accuracy: 0.6984 - val_loss: 0.7645 - val_accuracy: 0.6250\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5620 - accuracy: 0.6984 - val_loss: 0.7649 - val_accuracy: 0.6250\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5617 - accuracy: 0.6984 - val_loss: 0.7654 - val_accuracy: 0.6250\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5614 - accuracy: 0.6984 - val_loss: 0.7658 - val_accuracy: 0.6250\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5611 - accuracy: 0.6984 - val_loss: 0.7662 - val_accuracy: 0.6250\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5609 - accuracy: 0.6984 - val_loss: 0.7667 - val_accuracy: 0.6250\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5606 - accuracy: 0.6984 - val_loss: 0.7671 - val_accuracy: 0.6250\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5603 - accuracy: 0.6984 - val_loss: 0.7675 - val_accuracy: 0.6250\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5600 - accuracy: 0.6984 - val_loss: 0.7680 - val_accuracy: 0.6250\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5598 - accuracy: 0.6984 - val_loss: 0.7684 - val_accuracy: 0.6250\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5595 - accuracy: 0.6984 - val_loss: 0.7688 - val_accuracy: 0.6250\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5592 - accuracy: 0.6984 - val_loss: 0.7693 - val_accuracy: 0.6250\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5590 - accuracy: 0.6984 - val_loss: 0.7697 - val_accuracy: 0.6250\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5587 - accuracy: 0.6984 - val_loss: 0.7702 - val_accuracy: 0.6250\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5584 - accuracy: 0.6984 - val_loss: 0.7706 - val_accuracy: 0.6250\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5582 - accuracy: 0.6984 - val_loss: 0.7711 - val_accuracy: 0.6250\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5579 - accuracy: 0.6984 - val_loss: 0.7715 - val_accuracy: 0.6250\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5577 - accuracy: 0.6984 - val_loss: 0.7720 - val_accuracy: 0.6250\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5574 - accuracy: 0.6984 - val_loss: 0.7724 - val_accuracy: 0.6250\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5571 - accuracy: 0.6984 - val_loss: 0.7729 - val_accuracy: 0.6250\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5569 - accuracy: 0.6984 - val_loss: 0.7733 - val_accuracy: 0.6250\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5566 - accuracy: 0.6984 - val_loss: 0.7738 - val_accuracy: 0.6250\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5564 - accuracy: 0.6984 - val_loss: 0.7742 - val_accuracy: 0.6250\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5561 - accuracy: 0.6984 - val_loss: 0.7747 - val_accuracy: 0.6250\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5559 - accuracy: 0.6984 - val_loss: 0.7751 - val_accuracy: 0.6250\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5556 - accuracy: 0.6984 - val_loss: 0.7756 - val_accuracy: 0.6250\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5554 - accuracy: 0.6984 - val_loss: 0.7760 - val_accuracy: 0.6250\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5551 - accuracy: 0.6984 - val_loss: 0.7765 - val_accuracy: 0.6250\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5549 - accuracy: 0.6984 - val_loss: 0.7769 - val_accuracy: 0.6250\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5546 - accuracy: 0.6984 - val_loss: 0.7774 - val_accuracy: 0.6250\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5544 - accuracy: 0.6984 - val_loss: 0.7779 - val_accuracy: 0.6250\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5542 - accuracy: 0.6984 - val_loss: 0.7783 - val_accuracy: 0.6250\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5539 - accuracy: 0.6984 - val_loss: 0.7788 - val_accuracy: 0.6250\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5537 - accuracy: 0.6984 - val_loss: 0.7793 - val_accuracy: 0.6250\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5534 - accuracy: 0.6984 - val_loss: 0.7797 - val_accuracy: 0.6250\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5532 - accuracy: 0.6984 - val_loss: 0.7802 - val_accuracy: 0.6250\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5529 - accuracy: 0.6984 - val_loss: 0.7807 - val_accuracy: 0.6250\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5527 - accuracy: 0.6984 - val_loss: 0.7811 - val_accuracy: 0.6250\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5525 - accuracy: 0.6984 - val_loss: 0.7816 - val_accuracy: 0.6250\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5522 - accuracy: 0.6984 - val_loss: 0.7821 - val_accuracy: 0.6250\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5520 - accuracy: 0.6984 - val_loss: 0.7826 - val_accuracy: 0.6250\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5518 - accuracy: 0.6984 - val_loss: 0.7830 - val_accuracy: 0.6250\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5515 - accuracy: 0.6984 - val_loss: 0.7835 - val_accuracy: 0.6250\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5513 - accuracy: 0.6984 - val_loss: 0.7840 - val_accuracy: 0.6250\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5511 - accuracy: 0.6984 - val_loss: 0.7845 - val_accuracy: 0.6250\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5509 - accuracy: 0.6984 - val_loss: 0.7849 - val_accuracy: 0.6250\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5506 - accuracy: 0.6984 - val_loss: 0.7854 - val_accuracy: 0.6250\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5504 - accuracy: 0.6984 - val_loss: 0.7859 - val_accuracy: 0.6250\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5502 - accuracy: 0.6984 - val_loss: 0.7864 - val_accuracy: 0.6250\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5500 - accuracy: 0.6984 - val_loss: 0.7869 - val_accuracy: 0.6250\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5497 - accuracy: 0.6984 - val_loss: 0.7873 - val_accuracy: 0.6250\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5495 - accuracy: 0.6984 - val_loss: 0.7878 - val_accuracy: 0.6250\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5493 - accuracy: 0.6984 - val_loss: 0.7883 - val_accuracy: 0.6250\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5491 - accuracy: 0.6984 - val_loss: 0.7888 - val_accuracy: 0.6250\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5489 - accuracy: 0.6984 - val_loss: 0.7893 - val_accuracy: 0.6250\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5486 - accuracy: 0.6984 - val_loss: 0.7897 - val_accuracy: 0.6250\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5484 - accuracy: 0.6984 - val_loss: 0.7902 - val_accuracy: 0.6250\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5482 - accuracy: 0.6984 - val_loss: 0.7907 - val_accuracy: 0.6250\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5480 - accuracy: 0.6984 - val_loss: 0.7912 - val_accuracy: 0.6250\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5478 - accuracy: 0.6984 - val_loss: 0.7917 - val_accuracy: 0.6250\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5476 - accuracy: 0.6984 - val_loss: 0.7922 - val_accuracy: 0.6250\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5474 - accuracy: 0.6984 - val_loss: 0.7927 - val_accuracy: 0.6250\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5471 - accuracy: 0.6984 - val_loss: 0.7932 - val_accuracy: 0.6250\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5469 - accuracy: 0.6984 - val_loss: 0.7936 - val_accuracy: 0.6250\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5467 - accuracy: 0.6984 - val_loss: 0.7941 - val_accuracy: 0.6250\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5465 - accuracy: 0.6984 - val_loss: 0.7946 - val_accuracy: 0.6250\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5463 - accuracy: 0.6984 - val_loss: 0.7951 - val_accuracy: 0.6250\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5461 - accuracy: 0.6984 - val_loss: 0.7956 - val_accuracy: 0.6250\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5459 - accuracy: 0.6984 - val_loss: 0.7961 - val_accuracy: 0.6250\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5457 - accuracy: 0.6984 - val_loss: 0.7966 - val_accuracy: 0.6250\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5455 - accuracy: 0.6984 - val_loss: 0.7971 - val_accuracy: 0.6250\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5453 - accuracy: 0.6984 - val_loss: 0.7976 - val_accuracy: 0.6250\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5451 - accuracy: 0.6984 - val_loss: 0.7981 - val_accuracy: 0.6250\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5449 - accuracy: 0.6984 - val_loss: 0.7986 - val_accuracy: 0.6250\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5447 - accuracy: 0.6984 - val_loss: 0.7990 - val_accuracy: 0.6250\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5445 - accuracy: 0.6984 - val_loss: 0.7995 - val_accuracy: 0.6250\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5444 - accuracy: 0.6984 - val_loss: 0.8000 - val_accuracy: 0.6250\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5442 - accuracy: 0.6984 - val_loss: 0.8005 - val_accuracy: 0.6250\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5440 - accuracy: 0.6984 - val_loss: 0.8010 - val_accuracy: 0.6250\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5438 - accuracy: 0.6984 - val_loss: 0.8015 - val_accuracy: 0.6250\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5436 - accuracy: 0.6984 - val_loss: 0.8020 - val_accuracy: 0.6250\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5434 - accuracy: 0.6984 - val_loss: 0.8025 - val_accuracy: 0.6250\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5432 - accuracy: 0.6984 - val_loss: 0.8030 - val_accuracy: 0.6250\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5430 - accuracy: 0.6984 - val_loss: 0.8035 - val_accuracy: 0.6250\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5429 - accuracy: 0.6984 - val_loss: 0.8040 - val_accuracy: 0.6250\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5427 - accuracy: 0.6984 - val_loss: 0.8045 - val_accuracy: 0.6250\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5425 - accuracy: 0.6984 - val_loss: 0.8050 - val_accuracy: 0.6250\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5423 - accuracy: 0.6984 - val_loss: 0.8055 - val_accuracy: 0.6250\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5421 - accuracy: 0.6984 - val_loss: 0.8060 - val_accuracy: 0.6250\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5420 - accuracy: 0.6984 - val_loss: 0.8065 - val_accuracy: 0.6250\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5418 - accuracy: 0.6984 - val_loss: 0.8070 - val_accuracy: 0.6250\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5416 - accuracy: 0.6984 - val_loss: 0.8075 - val_accuracy: 0.6250\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5414 - accuracy: 0.6984 - val_loss: 0.8080 - val_accuracy: 0.6250\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5413 - accuracy: 0.6984 - val_loss: 0.8085 - val_accuracy: 0.6250\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5411 - accuracy: 0.6984 - val_loss: 0.8090 - val_accuracy: 0.6250\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5409 - accuracy: 0.6984 - val_loss: 0.8095 - val_accuracy: 0.6250\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5408 - accuracy: 0.6984 - val_loss: 0.8100 - val_accuracy: 0.6250\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5406 - accuracy: 0.6984 - val_loss: 0.8104 - val_accuracy: 0.6250\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5404 - accuracy: 0.6984 - val_loss: 0.8109 - val_accuracy: 0.6250\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5403 - accuracy: 0.6984 - val_loss: 0.8114 - val_accuracy: 0.6250\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5401 - accuracy: 0.6984 - val_loss: 0.8119 - val_accuracy: 0.6250\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5399 - accuracy: 0.6984 - val_loss: 0.8124 - val_accuracy: 0.6250\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5398 - accuracy: 0.6984 - val_loss: 0.8129 - val_accuracy: 0.6250\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5396 - accuracy: 0.6984 - val_loss: 0.8134 - val_accuracy: 0.6250\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5395 - accuracy: 0.6984 - val_loss: 0.8139 - val_accuracy: 0.6250\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5393 - accuracy: 0.6984 - val_loss: 0.8144 - val_accuracy: 0.6250\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5391 - accuracy: 0.6984 - val_loss: 0.8149 - val_accuracy: 0.6250\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5390 - accuracy: 0.6984 - val_loss: 0.8154 - val_accuracy: 0.6250\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5388 - accuracy: 0.6984 - val_loss: 0.8159 - val_accuracy: 0.6250\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5387 - accuracy: 0.6984 - val_loss: 0.8164 - val_accuracy: 0.6250\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5385 - accuracy: 0.6984 - val_loss: 0.8169 - val_accuracy: 0.6250\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5384 - accuracy: 0.6984 - val_loss: 0.8174 - val_accuracy: 0.6250\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5382 - accuracy: 0.7143 - val_loss: 0.8179 - val_accuracy: 0.6250\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5381 - accuracy: 0.7143 - val_loss: 0.8184 - val_accuracy: 0.6250\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5379 - accuracy: 0.7302 - val_loss: 0.8188 - val_accuracy: 0.6250\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5378 - accuracy: 0.7302 - val_loss: 0.8193 - val_accuracy: 0.6250\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5376 - accuracy: 0.7302 - val_loss: 0.8198 - val_accuracy: 0.6250\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5375 - accuracy: 0.7302 - val_loss: 0.8203 - val_accuracy: 0.6250\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5373 - accuracy: 0.7302 - val_loss: 0.8208 - val_accuracy: 0.6250\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5372 - accuracy: 0.7143 - val_loss: 0.8213 - val_accuracy: 0.6250\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5371 - accuracy: 0.7143 - val_loss: 0.8218 - val_accuracy: 0.6250\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5369 - accuracy: 0.7143 - val_loss: 0.8223 - val_accuracy: 0.6250\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5368 - accuracy: 0.7143 - val_loss: 0.8228 - val_accuracy: 0.6250\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5366 - accuracy: 0.7143 - val_loss: 0.8233 - val_accuracy: 0.6250\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5365 - accuracy: 0.7302 - val_loss: 0.8238 - val_accuracy: 0.6250\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5364 - accuracy: 0.7302 - val_loss: 0.8243 - val_accuracy: 0.6250\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5362 - accuracy: 0.7302 - val_loss: 0.8248 - val_accuracy: 0.6250\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5361 - accuracy: 0.7460 - val_loss: 0.8252 - val_accuracy: 0.6250\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5360 - accuracy: 0.7460 - val_loss: 0.8257 - val_accuracy: 0.6250\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5358 - accuracy: 0.7460 - val_loss: 0.8262 - val_accuracy: 0.6250\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5357 - accuracy: 0.7460 - val_loss: 0.8267 - val_accuracy: 0.6250\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5356 - accuracy: 0.7460 - val_loss: 0.8272 - val_accuracy: 0.6250\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5354 - accuracy: 0.7460 - val_loss: 0.8277 - val_accuracy: 0.6250\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5353 - accuracy: 0.7460 - val_loss: 0.8282 - val_accuracy: 0.6250\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5352 - accuracy: 0.7460 - val_loss: 0.8286 - val_accuracy: 0.6250\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5350 - accuracy: 0.7460 - val_loss: 0.8291 - val_accuracy: 0.6250\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5349 - accuracy: 0.7460 - val_loss: 0.8296 - val_accuracy: 0.6250\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5348 - accuracy: 0.7460 - val_loss: 0.8301 - val_accuracy: 0.6250\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5346 - accuracy: 0.7460 - val_loss: 0.8306 - val_accuracy: 0.6250\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5345 - accuracy: 0.7460 - val_loss: 0.8311 - val_accuracy: 0.6250\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5344 - accuracy: 0.7460 - val_loss: 0.8316 - val_accuracy: 0.6250\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5343 - accuracy: 0.7460 - val_loss: 0.8321 - val_accuracy: 0.6250\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5342 - accuracy: 0.7460 - val_loss: 0.8326 - val_accuracy: 0.6250\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5341 - accuracy: 0.7619 - val_loss: 0.8330 - val_accuracy: 0.6250\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5339 - accuracy: 0.7619 - val_loss: 0.8335 - val_accuracy: 0.6250\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5338 - accuracy: 0.7619 - val_loss: 0.8340 - val_accuracy: 0.6250\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5337 - accuracy: 0.7619 - val_loss: 0.8345 - val_accuracy: 0.6250\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5336 - accuracy: 0.7619 - val_loss: 0.8349 - val_accuracy: 0.6250\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5335 - accuracy: 0.7778 - val_loss: 0.8354 - val_accuracy: 0.6250\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5334 - accuracy: 0.7778 - val_loss: 0.8359 - val_accuracy: 0.6250\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5333 - accuracy: 0.7778 - val_loss: 0.8364 - val_accuracy: 0.6250\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5331 - accuracy: 0.7778 - val_loss: 0.8368 - val_accuracy: 0.6250\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5330 - accuracy: 0.7778 - val_loss: 0.8373 - val_accuracy: 0.6250\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5329 - accuracy: 0.7778 - val_loss: 0.8378 - val_accuracy: 0.6250\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5328 - accuracy: 0.7778 - val_loss: 0.8383 - val_accuracy: 0.6250\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5327 - accuracy: 0.7778 - val_loss: 0.8387 - val_accuracy: 0.6250\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5326 - accuracy: 0.7778 - val_loss: 0.8392 - val_accuracy: 0.6250\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5325 - accuracy: 0.7778 - val_loss: 0.8397 - val_accuracy: 0.6250\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5324 - accuracy: 0.7778 - val_loss: 0.8401 - val_accuracy: 0.6250\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5323 - accuracy: 0.7778 - val_loss: 0.8406 - val_accuracy: 0.6250\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5322 - accuracy: 0.7778 - val_loss: 0.8411 - val_accuracy: 0.6250\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5321 - accuracy: 0.7778 - val_loss: 0.8415 - val_accuracy: 0.6250\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7778 - val_loss: 0.8420 - val_accuracy: 0.6250\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5319 - accuracy: 0.7778 - val_loss: 0.8425 - val_accuracy: 0.6250\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5318 - accuracy: 0.7778 - val_loss: 0.8429 - val_accuracy: 0.6250\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5317 - accuracy: 0.7778 - val_loss: 0.8434 - val_accuracy: 0.6250\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5316 - accuracy: 0.7778 - val_loss: 0.8439 - val_accuracy: 0.6250\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5315 - accuracy: 0.7778 - val_loss: 0.8443 - val_accuracy: 0.6250\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5314 - accuracy: 0.7778 - val_loss: 0.8448 - val_accuracy: 0.6250\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5313 - accuracy: 0.7778 - val_loss: 0.8453 - val_accuracy: 0.6250\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5312 - accuracy: 0.7619 - val_loss: 0.8457 - val_accuracy: 0.6250\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5311 - accuracy: 0.7619 - val_loss: 0.8462 - val_accuracy: 0.6250\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5310 - accuracy: 0.7619 - val_loss: 0.8466 - val_accuracy: 0.6250\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5310 - accuracy: 0.7619 - val_loss: 0.8471 - val_accuracy: 0.6250\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5309 - accuracy: 0.7619 - val_loss: 0.8475 - val_accuracy: 0.6250\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5308 - accuracy: 0.7619 - val_loss: 0.8480 - val_accuracy: 0.6250\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5307 - accuracy: 0.7619 - val_loss: 0.8484 - val_accuracy: 0.6250\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5306 - accuracy: 0.7619 - val_loss: 0.8489 - val_accuracy: 0.6250\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5305 - accuracy: 0.7619 - val_loss: 0.8494 - val_accuracy: 0.6250\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5304 - accuracy: 0.7619 - val_loss: 0.8498 - val_accuracy: 0.6250\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5304 - accuracy: 0.7619 - val_loss: 0.8502 - val_accuracy: 0.6250\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5303 - accuracy: 0.7619 - val_loss: 0.8507 - val_accuracy: 0.6250\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5302 - accuracy: 0.7619 - val_loss: 0.8511 - val_accuracy: 0.6250\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5301 - accuracy: 0.7619 - val_loss: 0.8516 - val_accuracy: 0.6250\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5300 - accuracy: 0.7619 - val_loss: 0.8521 - val_accuracy: 0.5625\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5300 - accuracy: 0.7778 - val_loss: 0.8525 - val_accuracy: 0.5625\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5299 - accuracy: 0.7778 - val_loss: 0.8530 - val_accuracy: 0.5625\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5298 - accuracy: 0.7778 - val_loss: 0.8534 - val_accuracy: 0.5625\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5298 - accuracy: 0.7778 - val_loss: 0.8539 - val_accuracy: 0.5625\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5297 - accuracy: 0.7778 - val_loss: 0.8543 - val_accuracy: 0.5625\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5296 - accuracy: 0.7778 - val_loss: 0.8547 - val_accuracy: 0.5625\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5295 - accuracy: 0.7778 - val_loss: 0.8552 - val_accuracy: 0.5625\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5295 - accuracy: 0.7778 - val_loss: 0.8556 - val_accuracy: 0.5625\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5294 - accuracy: 0.7778 - val_loss: 0.8560 - val_accuracy: 0.5625\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5293 - accuracy: 0.7778 - val_loss: 0.8565 - val_accuracy: 0.5625\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5293 - accuracy: 0.7778 - val_loss: 0.8569 - val_accuracy: 0.5625\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5292 - accuracy: 0.7778 - val_loss: 0.8574 - val_accuracy: 0.5625\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5291 - accuracy: 0.7778 - val_loss: 0.8578 - val_accuracy: 0.5625\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5291 - accuracy: 0.7778 - val_loss: 0.8582 - val_accuracy: 0.5625\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5290 - accuracy: 0.7778 - val_loss: 0.8587 - val_accuracy: 0.5625\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5289 - accuracy: 0.7778 - val_loss: 0.8591 - val_accuracy: 0.5625\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5289 - accuracy: 0.7778 - val_loss: 0.8595 - val_accuracy: 0.5625\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5288 - accuracy: 0.7778 - val_loss: 0.8600 - val_accuracy: 0.5625\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5287 - accuracy: 0.7778 - val_loss: 0.8604 - val_accuracy: 0.5625\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5287 - accuracy: 0.7778 - val_loss: 0.8608 - val_accuracy: 0.5625\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5286 - accuracy: 0.7778 - val_loss: 0.8613 - val_accuracy: 0.5625\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5286 - accuracy: 0.7778 - val_loss: 0.8617 - val_accuracy: 0.5625\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5285 - accuracy: 0.7778 - val_loss: 0.8621 - val_accuracy: 0.5625\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5284 - accuracy: 0.7778 - val_loss: 0.8625 - val_accuracy: 0.5625\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5284 - accuracy: 0.7778 - val_loss: 0.8629 - val_accuracy: 0.5625\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5283 - accuracy: 0.7778 - val_loss: 0.8634 - val_accuracy: 0.5625\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5283 - accuracy: 0.7778 - val_loss: 0.8638 - val_accuracy: 0.5625\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5282 - accuracy: 0.7778 - val_loss: 0.8642 - val_accuracy: 0.5625\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5282 - accuracy: 0.7778 - val_loss: 0.8646 - val_accuracy: 0.5625\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5281 - accuracy: 0.7778 - val_loss: 0.8650 - val_accuracy: 0.5625\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5281 - accuracy: 0.7778 - val_loss: 0.8654 - val_accuracy: 0.5625\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5280 - accuracy: 0.7778 - val_loss: 0.8658 - val_accuracy: 0.5625\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5279 - accuracy: 0.7778 - val_loss: 0.8662 - val_accuracy: 0.5625\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5279 - accuracy: 0.7778 - val_loss: 0.8666 - val_accuracy: 0.5625\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5278 - accuracy: 0.7778 - val_loss: 0.8670 - val_accuracy: 0.5625\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5278 - accuracy: 0.7460 - val_loss: 0.8674 - val_accuracy: 0.5625\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5277 - accuracy: 0.7460 - val_loss: 0.8678 - val_accuracy: 0.5625\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5277 - accuracy: 0.7460 - val_loss: 0.8682 - val_accuracy: 0.5625\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5276 - accuracy: 0.7460 - val_loss: 0.8686 - val_accuracy: 0.5625\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5276 - accuracy: 0.7460 - val_loss: 0.8690 - val_accuracy: 0.5625\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5275 - accuracy: 0.7460 - val_loss: 0.8694 - val_accuracy: 0.5625\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5275 - accuracy: 0.7460 - val_loss: 0.8698 - val_accuracy: 0.5625\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5274 - accuracy: 0.7460 - val_loss: 0.8702 - val_accuracy: 0.5625\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5274 - accuracy: 0.7460 - val_loss: 0.8706 - val_accuracy: 0.5625\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5274 - accuracy: 0.7460 - val_loss: 0.8710 - val_accuracy: 0.5625\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5273 - accuracy: 0.7460 - val_loss: 0.8714 - val_accuracy: 0.5625\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5273 - accuracy: 0.7460 - val_loss: 0.8717 - val_accuracy: 0.5625\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5272 - accuracy: 0.7460 - val_loss: 0.8721 - val_accuracy: 0.5625\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5272 - accuracy: 0.7460 - val_loss: 0.8725 - val_accuracy: 0.5625\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5271 - accuracy: 0.7460 - val_loss: 0.8728 - val_accuracy: 0.5625\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5271 - accuracy: 0.7460 - val_loss: 0.8732 - val_accuracy: 0.5625\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5270 - accuracy: 0.7460 - val_loss: 0.8736 - val_accuracy: 0.5625\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5270 - accuracy: 0.7460 - val_loss: 0.8740 - val_accuracy: 0.5625\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5269 - accuracy: 0.7460 - val_loss: 0.8743 - val_accuracy: 0.5625\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5269 - accuracy: 0.7460 - val_loss: 0.8747 - val_accuracy: 0.5625\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5269 - accuracy: 0.7460 - val_loss: 0.8751 - val_accuracy: 0.5625\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5268 - accuracy: 0.7460 - val_loss: 0.8754 - val_accuracy: 0.5625\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5268 - accuracy: 0.7302 - val_loss: 0.8758 - val_accuracy: 0.5625\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5267 - accuracy: 0.7302 - val_loss: 0.8761 - val_accuracy: 0.5625\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5267 - accuracy: 0.7302 - val_loss: 0.8765 - val_accuracy: 0.5625\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5267 - accuracy: 0.7302 - val_loss: 0.8768 - val_accuracy: 0.5625\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5266 - accuracy: 0.7302 - val_loss: 0.8772 - val_accuracy: 0.5625\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5266 - accuracy: 0.7302 - val_loss: 0.8775 - val_accuracy: 0.5625\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5265 - accuracy: 0.7302 - val_loss: 0.8779 - val_accuracy: 0.5625\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5265 - accuracy: 0.7302 - val_loss: 0.8782 - val_accuracy: 0.5625\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5265 - accuracy: 0.7302 - val_loss: 0.8786 - val_accuracy: 0.5625\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5264 - accuracy: 0.7302 - val_loss: 0.8789 - val_accuracy: 0.5625\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5264 - accuracy: 0.7302 - val_loss: 0.8793 - val_accuracy: 0.5625\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5264 - accuracy: 0.7460 - val_loss: 0.8796 - val_accuracy: 0.5625\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5263 - accuracy: 0.7460 - val_loss: 0.8799 - val_accuracy: 0.5625\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5263 - accuracy: 0.7460 - val_loss: 0.8803 - val_accuracy: 0.5625\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5262 - accuracy: 0.7460 - val_loss: 0.8806 - val_accuracy: 0.5625\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5262 - accuracy: 0.7460 - val_loss: 0.8810 - val_accuracy: 0.5625\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5262 - accuracy: 0.7460 - val_loss: 0.8813 - val_accuracy: 0.5625\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5261 - accuracy: 0.7460 - val_loss: 0.8816 - val_accuracy: 0.5625\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5261 - accuracy: 0.7460 - val_loss: 0.8819 - val_accuracy: 0.5625\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5261 - accuracy: 0.7460 - val_loss: 0.8822 - val_accuracy: 0.5625\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5260 - accuracy: 0.7460 - val_loss: 0.8826 - val_accuracy: 0.5625\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5260 - accuracy: 0.7460 - val_loss: 0.8829 - val_accuracy: 0.5625\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5260 - accuracy: 0.7460 - val_loss: 0.8832 - val_accuracy: 0.5625\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5259 - accuracy: 0.7460 - val_loss: 0.8835 - val_accuracy: 0.5625\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5259 - accuracy: 0.7460 - val_loss: 0.8838 - val_accuracy: 0.5000\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5259 - accuracy: 0.7460 - val_loss: 0.8842 - val_accuracy: 0.5000\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5259 - accuracy: 0.7460 - val_loss: 0.8845 - val_accuracy: 0.5000\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5258 - accuracy: 0.7460 - val_loss: 0.8848 - val_accuracy: 0.5000\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5258 - accuracy: 0.7460 - val_loss: 0.8851 - val_accuracy: 0.5000\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5258 - accuracy: 0.7460 - val_loss: 0.8854 - val_accuracy: 0.5000\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5257 - accuracy: 0.7460 - val_loss: 0.8857 - val_accuracy: 0.5000\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5257 - accuracy: 0.7460 - val_loss: 0.8860 - val_accuracy: 0.5000\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5257 - accuracy: 0.7460 - val_loss: 0.8863 - val_accuracy: 0.5000\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5256 - accuracy: 0.7460 - val_loss: 0.8866 - val_accuracy: 0.5000\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5256 - accuracy: 0.7460 - val_loss: 0.8869 - val_accuracy: 0.5000\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5256 - accuracy: 0.7460 - val_loss: 0.8872 - val_accuracy: 0.5000\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5255 - accuracy: 0.7460 - val_loss: 0.8876 - val_accuracy: 0.5000\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5255 - accuracy: 0.7460 - val_loss: 0.8879 - val_accuracy: 0.5000\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5255 - accuracy: 0.7460 - val_loss: 0.8883 - val_accuracy: 0.5000\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5254 - accuracy: 0.7460 - val_loss: 0.8886 - val_accuracy: 0.5000\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5254 - accuracy: 0.7460 - val_loss: 0.8890 - val_accuracy: 0.5000\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5253 - accuracy: 0.7460 - val_loss: 0.8894 - val_accuracy: 0.5000\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5253 - accuracy: 0.7460 - val_loss: 0.8897 - val_accuracy: 0.5000\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5253 - accuracy: 0.7460 - val_loss: 0.8901 - val_accuracy: 0.5000\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5252 - accuracy: 0.7460 - val_loss: 0.8904 - val_accuracy: 0.5000\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5252 - accuracy: 0.7460 - val_loss: 0.8908 - val_accuracy: 0.5000\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5251 - accuracy: 0.7460 - val_loss: 0.8912 - val_accuracy: 0.5000\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5251 - accuracy: 0.7460 - val_loss: 0.8915 - val_accuracy: 0.5000\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5250 - accuracy: 0.7460 - val_loss: 0.8919 - val_accuracy: 0.5000\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5250 - accuracy: 0.7460 - val_loss: 0.8923 - val_accuracy: 0.5000\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5250 - accuracy: 0.7460 - val_loss: 0.8927 - val_accuracy: 0.5000\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5249 - accuracy: 0.7460 - val_loss: 0.8930 - val_accuracy: 0.5000\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5249 - accuracy: 0.7460 - val_loss: 0.8931 - val_accuracy: 0.5000\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5249 - accuracy: 0.7460 - val_loss: 0.8933 - val_accuracy: 0.5000\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5248 - accuracy: 0.7460 - val_loss: 0.8935 - val_accuracy: 0.5000\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5248 - accuracy: 0.7460 - val_loss: 0.8937 - val_accuracy: 0.5000\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5248 - accuracy: 0.7460 - val_loss: 0.8939 - val_accuracy: 0.5000\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5247 - accuracy: 0.7460 - val_loss: 0.8941 - val_accuracy: 0.5000\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5247 - accuracy: 0.7460 - val_loss: 0.8943 - val_accuracy: 0.5000\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5247 - accuracy: 0.7460 - val_loss: 0.8945 - val_accuracy: 0.5000\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5246 - accuracy: 0.7460 - val_loss: 0.8947 - val_accuracy: 0.5000\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5246 - accuracy: 0.7460 - val_loss: 0.8949 - val_accuracy: 0.5000\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5246 - accuracy: 0.7460 - val_loss: 0.8951 - val_accuracy: 0.5000\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5246 - accuracy: 0.7460 - val_loss: 0.8954 - val_accuracy: 0.5000\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5245 - accuracy: 0.7460 - val_loss: 0.8956 - val_accuracy: 0.5000\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5245 - accuracy: 0.7460 - val_loss: 0.8958 - val_accuracy: 0.5000\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5245 - accuracy: 0.7460 - val_loss: 0.8961 - val_accuracy: 0.5000\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5245 - accuracy: 0.7460 - val_loss: 0.8964 - val_accuracy: 0.5000\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5244 - accuracy: 0.7460 - val_loss: 0.8967 - val_accuracy: 0.5000\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5244 - accuracy: 0.7460 - val_loss: 0.8969 - val_accuracy: 0.5000\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5244 - accuracy: 0.7460 - val_loss: 0.8972 - val_accuracy: 0.5000\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5244 - accuracy: 0.7460 - val_loss: 0.8975 - val_accuracy: 0.5000\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5244 - accuracy: 0.7460 - val_loss: 0.8977 - val_accuracy: 0.5000\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5243 - accuracy: 0.7460 - val_loss: 0.8980 - val_accuracy: 0.5000\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5243 - accuracy: 0.7460 - val_loss: 0.8982 - val_accuracy: 0.5000\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5243 - accuracy: 0.7460 - val_loss: 0.8985 - val_accuracy: 0.5000\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5243 - accuracy: 0.7460 - val_loss: 0.8987 - val_accuracy: 0.5000\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5242 - accuracy: 0.7460 - val_loss: 0.8990 - val_accuracy: 0.5000\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5242 - accuracy: 0.7460 - val_loss: 0.8992 - val_accuracy: 0.5000\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5242 - accuracy: 0.7460 - val_loss: 0.8995 - val_accuracy: 0.5000\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5242 - accuracy: 0.7460 - val_loss: 0.8997 - val_accuracy: 0.5000\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5242 - accuracy: 0.7460 - val_loss: 0.9000 - val_accuracy: 0.5000\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5241 - accuracy: 0.7460 - val_loss: 0.9002 - val_accuracy: 0.5000\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5241 - accuracy: 0.7460 - val_loss: 0.9004 - val_accuracy: 0.5000\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5241 - accuracy: 0.7460 - val_loss: 0.9007 - val_accuracy: 0.5000\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5241 - accuracy: 0.7460 - val_loss: 0.9009 - val_accuracy: 0.5000\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5240 - accuracy: 0.7460 - val_loss: 0.9011 - val_accuracy: 0.5000\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5240 - accuracy: 0.7460 - val_loss: 0.9013 - val_accuracy: 0.5000\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5240 - accuracy: 0.7460 - val_loss: 0.9015 - val_accuracy: 0.5000\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5240 - accuracy: 0.7460 - val_loss: 0.9018 - val_accuracy: 0.5000\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5240 - accuracy: 0.7460 - val_loss: 0.9020 - val_accuracy: 0.5000\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5239 - accuracy: 0.7460 - val_loss: 0.9022 - val_accuracy: 0.5000\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5239 - accuracy: 0.7460 - val_loss: 0.9024 - val_accuracy: 0.5000\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5239 - accuracy: 0.7460 - val_loss: 0.9026 - val_accuracy: 0.5000\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5239 - accuracy: 0.7460 - val_loss: 0.9028 - val_accuracy: 0.5000\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5239 - accuracy: 0.7460 - val_loss: 0.9030 - val_accuracy: 0.5000\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5238 - accuracy: 0.7460 - val_loss: 0.9032 - val_accuracy: 0.5000\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5238 - accuracy: 0.7460 - val_loss: 0.9034 - val_accuracy: 0.5000\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5238 - accuracy: 0.7460 - val_loss: 0.9036 - val_accuracy: 0.5000\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5238 - accuracy: 0.7460 - val_loss: 0.9038 - val_accuracy: 0.5000\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5237 - accuracy: 0.7460 - val_loss: 0.9040 - val_accuracy: 0.5000\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5237 - accuracy: 0.7460 - val_loss: 0.9042 - val_accuracy: 0.5000\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5237 - accuracy: 0.7460 - val_loss: 0.9044 - val_accuracy: 0.5000\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5237 - accuracy: 0.7460 - val_loss: 0.9046 - val_accuracy: 0.5000\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5237 - accuracy: 0.7460 - val_loss: 0.9048 - val_accuracy: 0.5000\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5236 - accuracy: 0.7460 - val_loss: 0.9050 - val_accuracy: 0.5000\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5236 - accuracy: 0.7460 - val_loss: 0.9052 - val_accuracy: 0.5000\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5236 - accuracy: 0.7460 - val_loss: 0.9054 - val_accuracy: 0.5000\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5236 - accuracy: 0.7460 - val_loss: 0.9056 - val_accuracy: 0.5000\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5236 - accuracy: 0.7460 - val_loss: 0.9057 - val_accuracy: 0.5000\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5236 - accuracy: 0.7460 - val_loss: 0.9059 - val_accuracy: 0.5000\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5235 - accuracy: 0.7460 - val_loss: 0.9061 - val_accuracy: 0.5000\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5235 - accuracy: 0.7460 - val_loss: 0.9063 - val_accuracy: 0.5000\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5235 - accuracy: 0.7460 - val_loss: 0.9065 - val_accuracy: 0.5000\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5235 - accuracy: 0.7460 - val_loss: 0.9066 - val_accuracy: 0.5000\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5234 - accuracy: 0.7460 - val_loss: 0.9068 - val_accuracy: 0.5000\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5234 - accuracy: 0.7460 - val_loss: 0.9070 - val_accuracy: 0.5000\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5234 - accuracy: 0.7460 - val_loss: 0.9071 - val_accuracy: 0.5000\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5234 - accuracy: 0.7460 - val_loss: 0.9073 - val_accuracy: 0.5000\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5234 - accuracy: 0.7460 - val_loss: 0.9075 - val_accuracy: 0.5000\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5233 - accuracy: 0.7460 - val_loss: 0.9076 - val_accuracy: 0.5000\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5233 - accuracy: 0.7460 - val_loss: 0.9078 - val_accuracy: 0.5000\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5233 - accuracy: 0.7460 - val_loss: 0.9080 - val_accuracy: 0.5000\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5233 - accuracy: 0.7460 - val_loss: 0.9081 - val_accuracy: 0.5000\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5233 - accuracy: 0.7460 - val_loss: 0.9083 - val_accuracy: 0.5000\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5233 - accuracy: 0.7460 - val_loss: 0.9084 - val_accuracy: 0.5000\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.9086 - val_accuracy: 0.5000\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.9087 - val_accuracy: 0.5000\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.9089 - val_accuracy: 0.5000\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.9090 - val_accuracy: 0.5000\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5232 - accuracy: 0.7460 - val_loss: 0.9092 - val_accuracy: 0.5000\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5231 - accuracy: 0.7460 - val_loss: 0.9093 - val_accuracy: 0.5000\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5231 - accuracy: 0.7460 - val_loss: 0.9095 - val_accuracy: 0.5000\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5231 - accuracy: 0.7460 - val_loss: 0.9096 - val_accuracy: 0.5000\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5231 - accuracy: 0.7460 - val_loss: 0.9098 - val_accuracy: 0.5000\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5231 - accuracy: 0.7460 - val_loss: 0.9099 - val_accuracy: 0.5000\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.9101 - val_accuracy: 0.5000\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.9102 - val_accuracy: 0.5000\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.9103 - val_accuracy: 0.5000\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.9105 - val_accuracy: 0.5000\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.9106 - val_accuracy: 0.5000\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5230 - accuracy: 0.7460 - val_loss: 0.9108 - val_accuracy: 0.5000\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.9110 - val_accuracy: 0.5000\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.9111 - val_accuracy: 0.5000\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.9112 - val_accuracy: 0.5000\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.9114 - val_accuracy: 0.5000\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5229 - accuracy: 0.7460 - val_loss: 0.9115 - val_accuracy: 0.5000\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5228 - accuracy: 0.7460 - val_loss: 0.9117 - val_accuracy: 0.5000\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5228 - accuracy: 0.7460 - val_loss: 0.9118 - val_accuracy: 0.5000\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5228 - accuracy: 0.7460 - val_loss: 0.9120 - val_accuracy: 0.5000\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5228 - accuracy: 0.7460 - val_loss: 0.9121 - val_accuracy: 0.5000\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5228 - accuracy: 0.7460 - val_loss: 0.9123 - val_accuracy: 0.5000\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5227 - accuracy: 0.7460 - val_loss: 0.9124 - val_accuracy: 0.5000\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5227 - accuracy: 0.7460 - val_loss: 0.9125 - val_accuracy: 0.5000\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5227 - accuracy: 0.7460 - val_loss: 0.9126 - val_accuracy: 0.5000\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5227 - accuracy: 0.7460 - val_loss: 0.9128 - val_accuracy: 0.5000\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5227 - accuracy: 0.7460 - val_loss: 0.9129 - val_accuracy: 0.5000\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5226 - accuracy: 0.7460 - val_loss: 0.9130 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics= ['accuracy'])\n",
    "hist2 = model2.fit(x=x_train, y=y_train, epochs=700, validation_split=0.2, batch_size = 64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAGbCAYAAAASrkAJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA00klEQVR4nO3dfXhU9Z3//9fckpkkEGAgSEVRCFJviUTRoqsWaW21iha1u2u79frRG6P2h9uitlz97apf/dmtW7dcXXbt9sZvL9m2ltab+rWt3f7qyq4IRSlot9qIcqNUJYEAyUwyM5nP74+ZM5nJDcmZnMmZyXk+rstLcjJz5nwOk8yL9+fOZ4wxAgAAGGd+ty8AAAB4EyEEAAC4ghACAABcQQgBAACuIIQAAABXEEIAAIArCCEAAMAVhBAAAOAKQggAAHAFIQQAALgi6PYFjKSj46icXlje55OmT68vy7mrgdfbL3EPvN5+iXvg9fZL3INytd8672hUfAgxRmV7c5Tz3NXA6+2XuAdeb7/EPfB6+yXugZvtpzsGAAC4ghACAABcQQgBAACuIIQAAABXEEIAAIArCCEAAMAVhBAAAOAKQggAAHAFIQQAALiCEAIAAFxBCAEAAK4ghAAAAFdU/AZ2ADBQZyKlH7/0trqSfSWfwyepJhJSTyIlI+mCk6dpyYlTHbvGnfuP6D9eOyC39kWbOy2ij58126VXB0aHEAKg6jz58jv6zgt7HT3nM6++p1/ddL5j57vv13/Srva4Y+crxdnHN+ik6VFXrwE4FkIIgKrTEU9Kks44brJaTphS8nmi0bAOHu7RD196W52JlIwx8vl8jlzjwe6UJOnqM2epIRJy5Jyj9djOd9SZSOlgPEkIQUUjhACoOvFcN8wHTpqqVeefWNI5fD4pFqvX3v2d+uFLbytjpJ50RpFQwJlrTGWv8dPnnqDZU2ocOedovbD7kDoTKSVSpXdXAeOBgakAqo714RoNjz0w1IT6fw3GxzDGpFA6Y9SbzkiSog6FGjus++JUe4ByIYQAqDrduQ9XJz7g/T5f/jxOfWgnCs7jRFCyy2pPNyEEFY4QAqDqWGHBqQ94pysHVldM0O9TODj+v2at9tAdg0pHCAFQdaywUBt2Zlib9aHdnUo7cr7+6xv/Kkj2dbP3hUoIKh0hBEDViTs4JkTqDwuOVUKS2TDj1CBXuyIOdy8B5UIIAVB1Kr07ptvh67PL6VAFlAshBEDViTs4MFVyvnJgjcVwqzsmH6oYE4IKRwgBUFUyxpSvO8ahD223KyFM0UW1IIQAqCqFMz6cqjTkB6Y6NiYkex63xoT0Tzl2ZqAtUC6smAqg4j31h3e0ZU+nJCmZWwTM75MmOTT9NRrK/ir89WsHtPdQYszn292R3TPG7e6YtgPd+urTr0qSmo+fomvOPM6V6wGGQwgBUNHSfRnd+0yb0pni/Whn1k1ybJ+XmfVhSdKbHXG92eHcpnMz6yc5di47GnOve7gnrV/+8T1J0q/++J4+vHCGY9OaASfwbgRQ0bqTffkA8n9fdLL8udxxzgkNjr3G1Wcep7pwUF0Odl/UBP1afspMx85nx4KZdfr6ladq/5EeSdKDz74hI6knlVFt2JVLAoZECAFQ0azBouGATze0HF+W14iEArryjFllObdbLm6K5f/8rU1vKtVnlOrLuHhFwGAMTAVQ0dwe5DkRhPzZX/WpPjPCI4HxRQgBUNHcXgJ9IggFsn1YqQyVEFQWQgiAita/Oiq9x6UKBXKVkDSVEFQWQgiAitbt8MJkXhSmEoIKRQgBUNGsBbcIIaULBhgTgspECAFQ0eLJ7L/eGRNSOmtMSJLZMagwhBAAFc2qhDA7pnThXCUkTSUEFYYQAqCixV3ekXYiCOam6FIJQaUhhACoaHGXd6SdCMLB3MBUQggqDHPeALhmx9uH9b+37lMqM3w3wRvt3ZL6d4aFfdZiZQP336lEm3Z1aOOO/RqPS/VJCoWDSiXTqvw747xIyK87Lj9VsaAzezCVghACwDWPbHtLm944OKrHzp5SU+armbjyA1PTlV8J+fbze/Tqe11uX4ZntPzxPV1/RqNrr08IAeCaIz3ZQafXLpqt02bVD/u4KZGgzp87bbwua8LJL1ZWBZWQo73Z98Sq807Q8Q2R8r6YT6qvq9HRrh55sRQSCft11TknquuwcztH20UIAeAaa7zH0pOmaenJhIxyyS/bXgVjQqz3xLJTZmh+rLasr+XzSbFYvdrbj8p4MIT4fFJNKCA3604MTAXgGmvmSyTMr6JyClXRYmXWe4IxQN7ATz4A1+Q3pwtRlC2naqmEpDNGvblxK8yG8gZCCADXMP12fITzlZDKDiGJ3PtBYl0YryCEAHBFxpj+0jsfOGVlLVZW6d0x3bnVcUMBX74LCRMbf8sAXJFI8a/e8VIte8cwHsR7CCEAXGF1xfh90qQgv4rKKb93TIVP0aV7znv4yQfgCusDJxIKyOdzb8VGLwhWycBUQoj3EEIAuIKN6caPVQlJVviYkHwIoTvGMwghAFzBv3rHjzUmJF3plRAGKnsOk/MBjLsdbx/W5x/dKUmKhvk1VG7BXCXkhT2H9KlHXpKU3bwtGAooneqrmBXLOxMpSbwnvIS/aQDj7mc7/5z/8wlTy7w/CHR8bvO/rt4+/fHdyt8cjveEdxBCAIy77t5s2f2SppjWLm9y+WomvnNOaNAPbmjWwe5U/0GfNGVyRIePJCpq87Zw0Kfm901x+zIwTgghAMZdd67v/4NNMdUwCLHsfD6f3t9YP+CYtzdvQ2VgYCqAccegVAASIQSAC+K55bmZngt4GyEEwLijEgJAIoQAcIG1HkSE8SCApxFCAIwrY0y+EkJ3DOBthBAA46o3nZG1jxrdMYC3EUIAjCurK0aiOwbwOkIIgHHVv3uuX352zwU8jRACYFx152fGsFYi4HX8FgBQFsYY/f0vX9Pv3zpcdLw3t508g1IBEEIAlMXBeEpP/897w35/Xqx2HK8GQCUihAAoi+6CsR//cu2ZRd/z+XxaMIMQAngdIQRAWSRyIaRuUlCnHTfZ5asBUIkYmAqgLLpT2f1hmIYLYDiEEABlwaqoAEZCCAFQFmxSB2AkhBAAZZFfD4TuGADDIIQAKAsqIQBGYnt2TEdHh7761a9q69atCgQCuvLKK3XHHXcoGCw+1apVq/Tiiy8WHYvH47r++ut19913j+2qAVQ8a4+YWlZGBTAM278dVq9ercbGRm3atEnt7e266aab9PDDD2vVqlVFj/vOd75T9PXGjRv1rW99S7fccsvYrhhAVejfI4ZKCICh2eqO2bNnj7Zu3ao1a9YoEolozpw5am1t1YYNG475vDfeeEP33HOPHnjgAc2cOXNMFwygOjA7BsBIbFVC2tra1NDQoMbGxvyxefPmaf/+/Tpy5IgmTx56QaK77rpLK1asUEtLi+0LLMcmm9Y5vbqBp9fbL3EPxqP98dw6IdFJgYq8z7wHiv/vRV6/B+Vqv53z2Qoh3d3dikQiRcesr+Px+JAhZNu2bdqxY4ceeOABOy+VN316fUnPc/vc1cDr7ZfKdw+6e9O69l83a09H9zEf5/P59NdLTtDiE6fqyz97WT25cRQTQU86I0lqnFarWKxy32te/znwevsl7oGb7bcVQqLRqBKJRNEx6+va2qH3gfjxj3+sj3zkI5oxY0ZJF9jRcVTGlPTUYfl82ZtejnNXA6+3Xyr/Pdi2t1P/8+cjo3rsT7bt094DXeroTjp/IS4L+H06PhpUe/tRty9lEK//HHi9/RL3oFztt847GrZCSFNTkzo7O9Xe3q5YLCZJ2rVrl2bNmqX6+sEvmE6n9Zvf/Eb//M//bOdlihijsr05ynnuauD19kvluwfWGhlNM2r1D1eeOuRj3j3aq88/ulPxZF9+/MRNS+fqQwtLC+x2+HzS1Km1OnSou6zvgfpJQU2JhCr6feb1nwOvt1/iHrjZflshZO7cuVq8eLHuu+8+3X333Tp06JDWr1+vlStXDvn41157Tb29vTr77LMduVigWlibt02JhHR8Q2TIx9Tlpq72pDPqSmbHT8yeUjPs453k80mx6bWqNRlP//IF4C7bi5WtW7dO6XRay5Yt03XXXacLL7xQra2tkqTm5mY9+eST+cfu27dPU6ZM0aRJk5y7YqAKdKdGXi00UjBrpL0r2xXDwl4AvMT2OiGxWEzr1q0b8nvbt28v+vqyyy7TZZddVtqVAVVsNKuFhgM+Bfw+9WWM2nPjQZjOCsBLWLYdKIN4rnvlWKHC5/Plv9/NEucAPIgQApTBaDdvG/h9VhcF4CWEEKAMRrt528Dv0x0DwEsIIUAZJFKjCyEDQwfdMQC8hBAClMFou2MGdr/QHQPASwghQBmU0h0TCfnl9+omFgA8yfYUXQDDS2eMMhmTr4TUho/9I1bYHRMd4bEAMNHwWw9wyM79R3TrxpcVL9iEbuRKSP+PIINSAXgN3TGAQ7bt7SwKILHasObFosd8TssJDQr6s10w58+dWtbrA4BKQyUEcIjVBfPxs47TLReepJpQIB8whvPBpph+e8sH1GfMiF03ADDR8FsPcIg1LbchElLdpNH/aNUwIwaAR9EdAzjEWqp9pGm5AIAsQgjgEPZ/AQB7CCGAQ0a7NggAIIsQAjjEmhnDVFsAGB1CCOAQumMAwB5CCOCQxCj3iwEAZBFCAIfE8zvnMvMdAEaDEAI4wBhDdwwA2MQ/2eAZnYmUUn0ZSZLPJ/WFQzrY1Stjxn7uVJ9RXyZ7IgamAsDoEELgCT/bsV//73+8Pi6vFWFMCACMCiEEnvDSW4clST5J/tx+Lj5JDhRBilwyP6bACPvFAACyCCHwhEQq2w3z5eVNuvrM4+TzSbFYvdrbjzrSHQMAsI+BqfAE9nUBgMpDCIEnMHMFACoPIQSewL4uAFB5CCHwhAT7ugBAxSGEwBOs7himzwJA5SCEYMIzxlAJAYAKRAjBhNeTzii3mCn7ugBABSGEYMKzBqX6JNWEeMsDQKXgNzImvHjBeBC/j9VMAaBSUJvGhNCT6tO+zsSQ39tzMHuc6bkAUFkIIah6xhh9asN2vdkRP+bjCCEAUFkIIah6yT6TDyDToiH5huhy8fukq888brwvDQBwDIQQVD1rXxhJevpz57GLLQBUCQamourFc2uA1AT9BBAAqCKEEFQ99oUBgOpECEHVI4QAQHUihKDqWfvCRNkXBgCqCiEEVc+qhLAvDABUF0IIql5/dwyTvQCgmhBCUPWs2TERumMAoKoQQlD16I4BgOpECEHV62Z2DABUJTrRUTXau3r15sHB+8PsPZQ9RggBgOpCCEFV6En16bqHX9TR3vSwj6E7BgCqCyEEVaG9O6mjvWn5JJ00PTro+1NqgrqkKTb+FwYAKBkhBFUhkZsBMzUa0o8/3eLy1QAAnMDAVFQFlmYHgImHEIKqwNLsADDxEEJQFVgLBAAmHkIIqoK1KipLswPAxEEIQVWwKiEszQ4AEwchBFWB7hgAmHgIIagKLM0OABMPIQRVIZEihADAREMIQVWIJ7PLtTNFFwAmDqYawHHGGL301mEdiqeGfUx9TVAtcxoU8PvyxzrjKb30VqcyJveYSUGddly9XtzXqT2HEpKohADAREIIgeOe331Iq3/2yoiPu+ejC3XZ+2fmv/7y//mjtu3tLHpMTdCvnnQm/3X9JN6yADBR8BsdjnsrV7WYGgkNudnc3kMJtXcn9VZnYsjnLZxZp4PxpN7rSuYDyNxpETXNqNMHTppW5qsHAIwXQggcZy0sdsHJ0/T/XHbKoO8/+Owu/fuLb+cHm1qsr+/+6EL94o/v6vtb9uW/d9PSufrgghllvGoAwHhjYCocN9Jmc9bgUmvaraU7vyCZf9CiZIwFAYCJhxACx40YQnLH4wUhJJnOKJ0bkVobDg5alIyVUgFg4iGEwHHdqWPveFs7RAgp/HMkHBgUYGrZMwYAJhxCCByXSB57sznreLxgTIj150lBv4J+36Dn0h0DABMPIQSOG2mfF6trZahKiFU9iYaK35qEEACYeAghcFx+gOkwwWGo7phua0XU3PcGVkLYuA4AJh5CCBwXT2UDRe0wY0KsoGEFj+xzigezFlY+gn6fQgHeqgAw0fCbHY5LjHJ2TCKVGfQcq+JRWPmgCgIAExMhBI7rHuU6IfFkWsaYoudY40UKp+ROCvI2BYCJyPZv946ODrW2tqqlpUVLlizRvffeq3Q6PeRjt27dqmuvvVbNzc266KKL9NBDD435glH5rK6V4SoYVjjpM9Kj2/dr4+/3a/PuQ0XPofoBABOf7RCyevVqRaNRbdq0SRs3btTmzZv18MMPD3rcrl279NnPflZ/9Vd/pZdeekkPPfSQvve97+mXv/ylE9eNCpXqyyjVl61uDLfAWDQcUDC3e+4Dv92lr/3mdf36tQOSpMk1IUkqGgPSEAmV85IBAC6xtQLUnj17tHXrVj333HOKRCKaM2eOWltb9fWvf12rVq0qeuy///u/a9myZbr66qslSQsXLtSPfvQj1dXVOXf1qDiFM16Gq2b4fT59+dIm/febB4uOTwr69Ymz35f/+q6PnKL/euOgPn7WceW5WACAq2yFkLa2NjU0NKixsTF/bN68edq/f7+OHDmiyZMn54/v3LlTH/jAB/S3f/u3+u///m9NmzZNn/70p3X99dfbukCfz9bDbZ2zHOeuBuVsv7UJXTjgU+gYYzmuOnOWrjpz1jHPdflpjbr8tMZjPqZUvAeK/+9FXr8HXm+/xD0oV/vtnM9WCOnu7lYkEik6Zn0dj8eLQsjhw4f1gx/8QA8++KD+4R/+Qdu3b9fnPvc5TZkyRZdddtmoX3P69Ho7l2hLOc9dDcrR/o7c8KC6mpBiscq/v7wHvN1+iXvg9fZL3AM3228rhESjUSUSiaJj1te1tbVFx8PhsJYtW6aLL75YknTOOefoqquu0i9+8QtbIaSj46hyEygc4/Nlb3o5zl0Nytn+t987IkmKBP1qbz/q7MkdxHvA2+2XuAdeb7/EPShX+63zjoatENLU1KTOzk61t7crFotJyg5AnTVrlurri19w3rx5SiaTRcf6+vryUzJHyxiV7c1RznNXg3K0P97bP9W2Gu4t7wFvt1/iHni9/RL3wM3225odM3fuXC1evFj33Xefurq6tG/fPq1fv14rV64c9NhPfOIT+s1vfqMnnnhCxhj97ne/089//nNdddVVjl08Kk936thrhAAAYLE9RXfdunVKp9NatmyZrrvuOl144YVqbW2VJDU3N+vJJ5+UJJ1//vlav369fvCDH2jx4sX68pe/rDvuuEPLli1ztgWoKPEBe8AAADAcW90xkhSLxbRu3bohv7d9+/airy+66CJddNFFpV0ZqtJIO+gCAGBhPWw4ygoh0WEWKgMAwEIIgaMG7oYLAMBwCCFwVHyEzesAALDYHhNS7ZLpjH7+h3eU9PkVj/fampY0pyGiD79/ZvkuzgHGGP2f/3lX7xzpHfYxPp8UjU6y3f6A36cPLZyh903JLlD3Rke3nm3rUKbgJDvezq4TQncMAGAkngshW/Yc0v3/8XrJzz85FlXTjMrd/2bn/iO665d/Ktv5//Dno3pgxWmSpP/1qz/p5T8PvSDZ1CibzgEAjs1zIWTxnAb9X+edoHhG6ulJjvyEnN+2dagzkdKBrqSaZpTxAsfoQFe2TbHasC6cN23Yx9XUhG21/50jvdq8+5AOdPc/573ca13SFFNDpP+t1BAJadmCCr5JAICK4LkQEg0HdNMFcxWL1au9ffRL1e7u+L22v53Kb9BWqayBoafMrNNXli8Y8jE+n2y3/8V9ndq8+5ASBbvkWveidelczZ0eHduFAwA8h4GpoxTJDbTsTlZ4CEn2L5vuJOt83bnFyIwx+XsRYRAqAKAEhJBRioayRaN4lYQQpxcLs2a7WJWWZJ9RX8aU5bUAAN5ACBkl64O20kNId5mmyBa23xiTX55dcr7qAgDwBkLIKA2sBFSqRJkWC7POlzFSbzqTvw81Qb8Cfp+jrwUA8AZCyChFqqQSkt9ArkxjQqRsEGNRMgDAWBFCRqk2ZIWQ9AiPdFe5umP8Pp8ioezbJZ4khAAAxo4QMkrRKpkdU67umOw5+wfn5veIYTwIAKBEhJBRilZNd0x5ZscUnrOwEsLMGABAqQgho2T9i7/SFyvrLtM6IYXn7E71sUYIAGDMPLdiaqmsSsjLfz6qQ/GkpkbDLl9RvydfeUdtB7olSe8ezW5cV44KhXUPNv5+f3+3T4i3EACgNHyCjFKsrj90PP7yO7pxyQkuXk2/d4706J5fDd6wblqt8yEpljvnf71xMH9sei0b1QEASkMIGaWTp9eqIRJSZyKlrt7KmSHT1Wt1v/j1ibPfJ0maN71Wx02ucfy1br5wrk6aFlUqk5EkTQr6ddXpsxx/HQCANxBCbLjy9Fn6we/2KZ0Z5a5v4yDZlw0Ek2tCar3gpLK+1vumRPSZD5xY1tcAAHgHA1NtCObuVl8FhZBULoSEAqxaCgCoLoQQG6zlySupEmJdS8jPXyUAoLrwyWVDMPdBX0mVkCSVEABAlSKE2GBVQiophKT6cpWQAH+VAIDqwieXDZXYHWONCQlTCQEAVBlCiA2VXAkJUgkBAFQZPrlsCFohxFRSCGFMCACgOhFCbKjMSojVHcNfJQCguvDJZUPQV4ljQnLdMUzRBQBUGVZMtaFcA1Pf7Ihrw7a31JuralguPHmaPrRw5jGfm8pdSzhIdwwAoLoQQmwIlqk75pFt+/TkK+8OOr5pV8fIIcQaE0IlBABQZQghNpRrTEhnIrsh3qULZuiM2fXqTvbp28/vUXeyT8YY+XzDVzmsEBJkYCoAoMrwz2cbytUdE09ld8K9eP50/dXi43V98+z890YKPNaYEAamAgCqDZ9cNpSrEhJPZkNIJByQVLz6abLv2K/Fsu0AgGpFCLGhXGNC4slsd0ztECEkNWCw6kBplm0HAFQpPrlsCJRpsTKrEhLNhZCAT7LqGqkRAg+VEABAtSKE2GBVQtIjdJHYZY0JiYayIcTn8ykczP7VjFQJsUIKs2MAANWGTy4bAj7nKyHGmEGVEKk/8KRGCDxpqxIS5K8SAFBd+OSywZoG6+TsmN50RtbpCkOINcYjOUIlxBq4GvLTHQMAqC6EEBvKMTumO1cFkaRIqD+EhK3AM1J3DHvHAACqFJ9cNgTKsHdMomA8iL9gUbJgwBoTMlJ3TG7vGAamAgCqDCHEhnJWQiIFXTFSfyVk5O4Ya3YMf5UAgOrCsu02lGOdEGtQau2AEGKFiq//f69rRt2kYZ/fdqBbUn9oAQCgWhBCbOhftv3Y1Qk7rO6YmgGzW6wQsqs9rl3t8RHPM7N++KACAEAlIoTYUI5KiDXmY9LAEFIw2yVWG9YtF5407Dka6ydp4cw6x64JAIDxQAixoTwhxNoFd2AlpD+EzKgL6/LTGh17TQAAKgGjGW3oX7Y9u8iYE1K5rp2B63wUDjQtnLoLAMBEQQixIVAQFJyqhqTS2fOEhxkTIhUvYgYAwERBCLGhMIQ4tVaIVQkJDqiEFM52GThzBgCAiYAQYkOwYJM4p/aPsQamDlzxNEglBAAwwRFCbChLd0x+sbEBY0IKXisaYvwwAGDiIYTYUJgTHOuOyS+7XvxXUThGhO4YAMBERAixwefz5YOI05WQQd0xBZWQgUu6AwAwERBCbLIqFk6FkGSuEjKwOybMmBAAwARHCLHJ6Z100/nZMcMvVlbLOiEAgAmIEGJT//4xDlVC0lZ3THElhNkxAICJjhBik1WhsMZyjFUqY3XHFP9VHN9Qk//znKkRR14LAIBKwtxPm6LhgA7GU4on+xw5X3qYKbqXLZyp902JqDYc0NxpUUdeCwCASkIIscnaxyWeciaE9A9MLa6E+Hw+nTl7siOvAQBAJaI7xiZrzQ6nKiHDLVYGAMBERwixyRok2u1YCBm6EgIAwETHJ59N1hLqVEIAABgbQohNjnfHZIbewA4AgImOTz6bIo53xwy9WBkAABMdn3w2WWNCEg7NjkkNs2w7AAATHSHEJmsJ9Xgy7cj5htvADgCAiY5PPpucnx3DwFQAgDcRQmyKOr5OSLY7JkglBADgMXzy2RR1cMXUHW8f1jtHeyUN3sAOAICJjhBiU00oe8t602PfwO6ZVw/k/9xYP2nM5wMAoJoQQmzy+7IVi77c+h5jkcyNB7m+ebYm14TGfD4AAKqJ7RDS0dGh1tZWtbS0aMmSJbr33nuVTg89U2TVqlU644wz1NzcnP/vueeeG/NFuyngz4aQjBl7CLEGpc6sowoCAPAe27vorl69Wo2Njdq0aZPa29t100036eGHH9aqVasGPfaVV17Rd7/7XZ177rmOXGwlCDhYCcmvERKkIAUA8B5bn3579uzR1q1btWbNGkUiEc2ZM0etra3asGHDoMfu27dPhw8f1qmnnurYxVYCf64S0jf2DJLvjgn5GZQKAPAeWyGkra1NDQ0NamxszB+bN2+e9u/fryNHjhQ99uWXX1Ztba1uu+02nXfeebriiiu0ceNGZ67aRdYklowDlZB0htVSAQDeZas7pru7W5FIpOiY9XU8HtfkyZPzx5PJpBYtWqTbbrtNTU1N2rJli2699VbV1tbqIx/5yKhf01eGz2frnKWcu3BMyFivLb9aatBflnYOZyztnyi8fg+83n6Je+D19kvcg3K13875bIWQaDSqRCJRdMz6ura2tuj4ihUrtGLFivzXF1xwgVasWKFf/OIXtkLI9On1di7RllLOPT2ZrV4Yn0+x2NiuzeQ2rZvWEB3zuUpRzntbLbx+D7zefol74PX2S9wDN9tvK4Q0NTWps7NT7e3tisVikqRdu3Zp1qxZqq8vbsTGjRsHVT2SyaQmTbI3E6Sj46gcmIhSxOfL3vRSzn3kcFySlEpn1N5+dEzXkehJSZJ64r1jPpcdY2n/ROH1e+D19kvcA6+3X+IelKv91nlHw1YImTt3rhYvXqz77rtPd999tw4dOqT169dr5cqVgx7b1dWlb3zjGzrxxBO1cOFCPffcc3rqqaf03e9+185LyhiV7c1RyrmtdUIyxoz5uvJLtvv9rvwAlPPeVguv3wOvt1/iHni9/RL3wM32256iu27dOt19991atmyZ/H6/VqxYodbWVklSc3Oz7rrrLl155ZX6m7/5G8Xjcd1yyy3q6OjQnDlz9LWvfU0tLS2ON2I8WRNZnFysjNkxAAAvsh1CYrGY1q1bN+T3tm/fnv+zz+dTa2trPqBMFE4uVmbNjgmzeR0AwIP49LOpP4SM/VzJ3P4zTNEFAHgRIcQma0xI2okVU/PrhPDXAADwHj79bHJ0sTJrTAghBADgQXz62WQt224kmTGOC8kPTKU7BgDgQYQQm/wFS8GNdf+Y/AZ2VEIAAB7Ep59NwYLptGPpkskYw94xAABPI4TYVFgJGcs03XRBGYUpugAAL+LTz6bCdcXGMkMmlcnk/xxksTIAgAcRQmwK+J2phKTS/c9lTAgAwIv49LOpKIRkjvHAEViVkICv+JwAAHgFIcSm4tkxY6iEWJvXUQUBAHgUn4AlyC9YNoYQYq0RwqBUAIBX8QlYAmvBsrHspJvuY3ouAMDbCCElsLpkxtIdk2TJdgCAx/EJWAJrSu1YBqb2pPskSZOC/BUAALyJT8ASOFEJSSSzCaY2HHDkmgAAqDaEkBL4HRiY2p1MS5IiIUIIAMCbCCElCDgwMDWezHbHRKmEAAA8ihBSAqs7ZixjQuKpbAihOwYA4FWEkBLkKyFj6I6hEgIA8DpCSAmcWKzMCiGMCQEAeBUhpAROLFZGdwwAwOsIISVwYopud747JujINQEAUG0IISUIOLBYWYIxIQAAjyOElCDgRCXE6o5hTAgAwKMIISWwFitLpu2XQqzn5AemUgkBAHgUIaQEVnfM3z7+B6X6Rh9Efrf3kJZ+87/0v7fuUzy3YioDUwEAXkUIKUFhL8zug/FRP+9/PdMmSfrWpjeV7MuehA3sAABexSdgCXoLqh81wdFXMqz1RaT+6b1WVQUAAK8hhJSgt2AsSDAw+hBRGDjSVgjxEUIAAN5ECClBT25mi2Rv1VR/QeCgEgIA8DpCSAkKKyF2ZukWBg4rhAQJIQAAjyKElKC4EjL651EJAQCgHyGkBH0FwSNjI4UU5o10brlVKiEAAK8ihIxRRqMPIcEhumOohAAAvIoQMkYld8fknkclBADgVYSQMTJ2ZscMETiohAAAvIoQMkZ2KiFDLSlCCAEAeBUhZIwGVkKO9KTUdqBLhxOpQY/1D7EwGYuVAQC8Kuj2BVS7wkrI4URKV/7bVsVTfaoJ+vXkZ87V1Gg4//2hqh7BADkQAOBNfAKW4MGrT8v/ubASsq8zoXhuDZGedEZ7DyWKnjdUCLGx6jsAABMKIaQEF5w8Xe+bUiOpeM2QeLKv6HHxVPHXA/NGwCf56I4BAHgUIaREVlWjsBIyKIQM+HpgJYRBqQAALyOElMiKD4VjQgZWPrpHCCFBP7cfAOBdfAqWyJrpUriL7sDQMbAS4hOVEAAALISQEllDOcwxxoQkBlRGMgOm8xJCAABeRggp0VCVkJG6YwaGEJZsBwB4GSGkRKOphAz8ui9DJQQAAAshpET5SogKZ8ekJUn1k4JFX1sGLvFOCAEAeBkhpERWfshk+o9ZlY9YbXaV1HgqU/ScPrpjAADII4SU6FhjQqbX5ULIgEoI3TEAAPQjhJQoXwnJ5YoDXb16/s1DkqQZViWEgakAAAyLEFIia7l1Y4wSqT5d+/1t+e/NqJskaYjZMQMrISzZDgDwMEJIifKVEEkH48l84Ljg5Gk698QGSVKyb+CYkOJz0B0DAPAyQkiJCishqXQ2XUyuCerBq0/Pz45JDUgddMcAANCPEFKiwjEhqdwUGStUhALZ/6cGVkIYmAoAQB4hpESFlZBkruIRDmRvZyj3/4GVEEIIAAD9CCElsm5cnzFK5yoeVgVkuEoIi5UBANCPEFIiv9+qhPQPQLUqIOF8JYTFygAAGA4hpET9Y0JMvtvFCiEhf/b/faa4C2ZgdwwhBADgZYSQEvWvmKqCEJLrjgn2h4t0QfAYODuG7hgAgJcRQkpkxQdjTL7bZWAlRCrukmGxMgAA+hFCSlRUCclN0Q3lKhvBQH+4KAwhAxcrK3wcAABeQwgpkVXEKFysLBzM3k6/z5cf75HsO0Z3DJUQAICHEUJKZFVC0hnpxbc6JRUPNB04TberN60DXcmiczAmBADgZUG3L6BaWfnhZzv3a1d7XFL/mBApO003kcoonauE3PTozkHnmBQkAwIAvIsQUiKrEmIFEEkKF4zxCOYCibWGyKvvdeW/d97cqfL7pCtPnzUelwoAQEUihJRoqOEcwaJKSK47ZuAyqZJu/+B8zZkaKdu1AQBQDegPKJF/iBQSKhoTkls1NZ0Z9Dg/dx0AAEJIqYYaUxouGONhDVK1pu8WYlYMAACEkJL5hggSQX/xwFRp8E660tBVFAAAvIYQUqIhKyGBoafopgdsZOdnai4AAPZDSEdHh1pbW9XS0qIlS5bo3nvvVTqdPuZz/vSnP+mss87Sli1bSr7QSjNUJaRQqKAS0p3sK/oeC6UCAFBCCFm9erWi0ag2bdqkjRs3avPmzXr44YeHfXwikdAXv/hF9fT0jOU6K85QxYzCzeqsSkiyL6N4akAIoRICAIC9ELJnzx5t3bpVa9asUSQS0Zw5c9Ta2qoNGzYM+5y77rpLl1566ZgvtNIMNa4jWdDtYlVC0n1G8QGVEMaEAABgc52QtrY2NTQ0qLGxMX9s3rx52r9/v44cOaLJkycXPf7xxx/Xnj17dO+992r9+vUlXWA5Pq+tc47l3EMFiXTG5M+Z747JZJQYUAkJ+n1laddoOdH+auf1e+D19kvcA6+3X+IelKv9ds5nK4R0d3crEileZMv6Oh6PF4WQXbt26cEHH9QPf/hDBQIBOy9TZPr0+pKfW85z10bDg44FQkHFYtlz1uW+H64JKxgpfuyMGfWqCZV+T5xSzntbLbx+D7zefol74PX2S9wDN9tvK4REo1ElEomiY9bXtbW1+WO9vb267bbb9JWvfEWzZ88e0wV2dByVGTzLdUx8vuxNH8u5e3tSg44d7e5Ve/tRSZJJZ6sfm157Vy+8fqDocZ0Hu4pWVx1vTrS/2nn9Hni9/RL3wOvtl7gH5Wq/dd7RsBVCmpqa1NnZqfb2dsViMUnZisesWbNUX9//gi+//LJ2796ttWvXau3atfnjn//853XVVVfp7//+70f9msaobG+OsZx7qHLT+6bU5M8XyVU6ftvWMcRzfRXxhi/nva0WXr8HXm+/xD3wevsl7oGb7bcVQubOnavFixfrvvvu0913361Dhw5p/fr1WrlyZdHjWlpatHNn8a6xp5xyiv71X/9VS5YsGftVVwCfilPIzLqwbmg5Pv/1dYtmqzuZ1ov7Duvdo73542uXNzEwFQAAlTBFd926dUqn01q2bJmuu+46XXjhhWptbZUkNTc368knn3T8IivRwFm2ty+bXzTOY+70qO76yEKde0JD/tilC2JaceZx43SFAABUNtu76MZiMa1bt27I723fvn3Y57322mt2X6qiDVz1dLgxHqGC426OAwEAoNLwqViigZWQ0DALkIUKlkcNs1QqAAB5hJASDVy2PTyKSkiISggAAHl8KpZo4I0LDVPlCBVtasftBgDAwqdiiQbOcBnNmJDhumwAAPAiQkiJBs6yHbY7xl9YCSGEAABgIYSUaGAlZPjuGMaEAAAwFD4VSzSwEjJcwCCEAAAwND4VSxQYdSWE7hgAAIZCCCnRoEqIf+hbGaYSAgDAkPhULNHox4QUVEKYHQMAQB4hpESFGcTvkyYFh76VhVN3w8M8BgAAL+JTsUSFlZBIKDBoBVVL4VLtQSohAADkEUJKVJgnasOBYR9XOFaEMSEAAPTjU7FEhZWP6LFCSLBwAztuNwAAFj4VS1RYCYmGg8M+rrASEmSKLgAAeYSQEhWOCYmGhr+NhbNjqIQAANCPT8USjboSUrROCJUQAAAshJASjXpMSNEuutxuAAAsfCqWaLSzYwqn6BYOUgUAwOsIISUauE7IcIJUQgAAGBKfiiXyFY0JOdY6If0PJIMAANCPj8US+dUfLo65WFlBJcSYsl4SAABVhRBSorqa/hkx06PhYR9XOCakftLws2gAAPAaPhVLtOSEBq354HylMxld3BQb9nHBgF/f+vgZSvZlNCUSGscrBACgshFCShQM+HVd8+xRPXbJ3KllvhoAAKoP3TEAAMAVhBAAAOAKQggAAHAFIQQAALiCEAIAAFxBCAEAAK4ghAAAAFcQQgAAgCsIIQAAwBWEEAAA4ApCCAAAcAUhBAAAuIIQAgAAXFHxu+j6fOU7ZznOXQ283n6Je+D19kvcA6+3X+IelKv9ds7nM8YYZ18eAABgZHTHAAAAVxBCAACAKwghAADAFYQQAADgCkIIAABwBSEEAAC4ghACAABcQQgBAACuIIQAAABXeCqEdHR0qLW1VS0tLVqyZInuvfdepdNpty+rLA4ePKjly5dry5Yt+WM7duzQtddeq+bmZn3wgx/UT37yk6LnPPbYY1q+fLkWLVqka665Rtu3bx/vyx6zV199VTfeeKPOPfdcLV26VLfffrsOHjwoyRvtl6TNmzfr2muv1dlnn62lS5fqnnvuUU9PjyTv3ANJ6uvr0yc/+Undeeed+WNeaf/TTz+tU089Vc3Nzfn/1qxZI8k796Czs1O33367lixZonPOOUetra167733JE38e/Dkk08W/d03Nzfr9NNP1+mnny6pwtpvPOSGG24wX/ziF008Hjd79+41l19+ufm3f/s3ty/Lcdu2bTOXXnqpWbBggXnhhReMMcZ0dnaac8891zzyyCMmlUqZ559/3jQ3N5sdO3YYY4x54YUXTHNzs9m2bZtJJpPm+9//vlmyZImJx+NuNsWWRCJhli5dar75zW+a3t5ec/DgQfOZz3zGfO5zn/NE+40xpqOjw5xxxhnmpz/9qenr6zPvvvuuueKKK8w3v/lNz9wDyz/90z+ZhQsXmjvuuMMY442fAcv9999v7rzzzkHHvXQPbrjhBnPzzTebw4cPm6NHj5pbbrnFfPazn/XUPbC88847ZunSpebxxx+vuPZ7phKyZ88ebd26VWvWrFEkEtGcOXPU2tqqDRs2uH1pjnrsscf0pS99SbfddlvR8WeeeUYNDQ3667/+awWDQZ1//vn62Mc+lm//T37yE11++eVavHixQqGQPv3pT2vq1Kl6+umn3WhGSfbv36+FCxfq5ptvVjgc1tSpU3X99dfrd7/7nSfaL0nTpk3T888/r2uuuUY+n0+dnZ3q7e3VtGnTPHMPpGw16JlnntGHPvSh/DEvtf/ll1/O/6u3kFfuwSuvvKIdO3bo/vvv1+TJk1VXV6d77rlHX/rSlzxzDyzGGK1Zs0YXX3yxrrrqqoprv2dCSFtbmxoaGtTY2Jg/Nm/ePO3fv19Hjhxx8cqcdcEFF+jXv/61PvrRjxYdb2tr04IFC4qOzZ8/X6+++qok6fXXXz/m96vBySefrO985zsKBAL5Y7/61a902mmneaL9lrq6OknSRRddpI997GOaMWOGrrnmGs/cg46ODq1du1b/+I//qEgkkj/ulfZnMhn94Q9/0LPPPqtLLrlEf/EXf6GvfvWrOnz4sGfuwc6dOzV//nw9+uijWr58uS644AJ97Wtf04wZMzxzDyxPPPGEXn/99Xy3ZKW13zMhpLu7u+gXkqT81/F43I1LKosZM2YoGAwOOj5U+2tqavJtH+n71cYYowcffFC//e1vtXbtWs+1X8r+q/e5556T3+/XF77wBU/cg0wmozVr1ujGG2/UwoULi77nhfZL2fFgp556qj784Q/r6aef1o9+9CPt3r1ba9as8cw9OHz4sF577TXt3r1bjz32mB5//HG9++67uuOOOzxzD6Tsz8O//Mu/6POf/3z+HyeV1n7PhJBoNKpEIlF0zPq6trbWjUsaV5FIJD840dLT05Nv+0jfryZdXV36whe+oJ///Od65JFHdMopp3iq/Zaamho1NjZqzZo12rRpkyfuwUMPPaRwOKxPfvKTg77nhfZLUiwW04YNG7Ry5UpFIhHNnj1ba9as0XPPPSdjjCfuQTgcliStXbtWdXV1isViWr16tf7zP//TM/dAkrZs2aL33ntPK1euzB+rtJ8Dz4SQpqYmdXZ2qr29PX9s165dmjVrlurr6128svGxYMECtbW1FR17/fXX1dTUJCl7f471/Wqxd+9effzjH1dXV5c2btyoU045RZJ32v/SSy/psssuUzKZzB9LJpMKhUKaP3/+hL8HTzzxhLZu3aqWlha1tLToqaee0lNPPaWWlhbPvAdeffVVPfDAAzLG5I8lk0n5/X6deeaZnrgH8+fPVyaTUSqVyh/LZDKSpPe///2euAdStjt6+fLlikaj+WMV93NQluGuFeov//IvzW233WaOHj2anx2zbt06ty+rbApnxxw8eNC0tLSY73//+yaZTJrNmzeb5uZms3nzZmOMyY+Q3rx5c35E9DnnnGMOHTrkYgvs6ezsNBdffLG58847TV9fX9H3vNB+Y4zp6uoyF110kbnvvvtMb2+veeutt8zKlSvN3/3d33nmHhS644478rNjvNL+P//5z2bRokXm29/+tkmlUubtt9821113nfnKV77imXuQTCbN8uXLza233mq6urpMR0eH+dSnPmVuvvlmz9wDY4y54oorzKOPPlp0rNLa76kQcuDAAXPrrbeac88915x33nnm/vvvN+l02u3LKpvCEGKMMTt37jTXX3+9aW5uNsuWLTM//elPix7/+OOPmw9/+MNm0aJFZuXKleb3v//9eF/ymHzve98zCxYsMGeddZZZtGhR0X/GTPz2W9ra2syNN95oWlpazCWXXGK+8Y1vmN7eXmOMd+6BpTCEGOOd9m/ZsiXfzvPOO8/cc889pqenxxjjnXvwzjvvmNWrV5ulS5ealpYWc/vtt5vDhw8bY7xzDxYtWmSeffbZQccrqf0+YwpqdgAAAOPEM2NCAABAZSGEAAAAVxBCAACAKwghAADAFYQQAADgCkIIAABwBSEEAAC4ghACAABcQQgBAACuIIQAAABXEEIAAIArCCEAAMAV/z9SPZE6D9pn6wAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(0, 700), y=hist1.history['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(0, 700), y=hist2.history['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[3] iris 데이터 셋을 사용하여 Multi-Classification 모델을 Kears로  2층 신경망모델을 구현하여\n",
    "    Accuracy를 구하고 3층신경망 모델과 비교하여 보세요.\n",
    "   하나의 소스에 2층과 3층 두개 모델을 구현하여 Accuracy를비교하여 보세요. 학습 결과 시각화도 구현한다\n",
    "   (iris는 데이터 특성상 정확도는 2층 3층 모두 1.0임)\n",
    "\n",
    "* 파라메터 설정 예시\n",
    "  [2층 신경망]\n",
    "  첫번째 층 출력 : [None,20],   활성화 함수 : 'relu',\n",
    "  optimizer='adam', loss: 'categorical_crossentropy', metrics:['accuracy']\n",
    "   학습 epoch : 700\n",
    "\n",
    "  [3층 신경망]\n",
    "  첫번째 층 출력 : [Non,40],   활성화 함수 : 'relu',\n",
    "  두번째 층 출력 : [Non,20],   활성화 함수 : 'relu',\n",
    "  optimizer='adam', loss: 'categorical_crossentropy', metrics:['accuracy']\n",
    "  학습 epoch : 700\n",
    "\n",
    "  [one-hot 인코딩]\n",
    "  y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  \\\n",
      "0             1           5.1          3.5           1.4          0.2   \n",
      "1             2           4.9          3.0           1.4          0.2   \n",
      "2             3           4.7          3.2           1.3          0.2   \n",
      "3             4           4.6          3.1           1.5          0.2   \n",
      "4             5           5.0          3.6           1.4          0.2   \n",
      "..          ...           ...          ...           ...          ...   \n",
      "145         146           6.7          3.0           5.2          2.3   \n",
      "146         147           6.3          2.5           5.0          1.9   \n",
      "147         148           6.5          3.0           5.2          2.0   \n",
      "148         149           6.2          3.4           5.4          2.3   \n",
      "149         150           5.9          3.0           5.1          1.8   \n",
      "\n",
      "       Species  \n",
      "0       setosa  \n",
      "1       setosa  \n",
      "2       setosa  \n",
      "3       setosa  \n",
      "4       setosa  \n",
      "..         ...  \n",
      "145  virginica  \n",
      "146  virginica  \n",
      "147  virginica  \n",
      "148  virginica  \n",
      "149  virginica  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\n",
    "    'C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\ai\\\\.ipynb_checkpoints\\\\01_tensorflow_basic\\\\data_set\\\\iris.csv')\n",
    "print(train_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  \\\n0             1           5.1          3.5           1.4          0.2   \n1             2           4.9          3.0           1.4          0.2   \n2             3           4.7          3.2           1.3          0.2   \n3             4           4.6          3.1           1.5          0.2   \n4             5           5.0          3.6           1.4          0.2   \n..          ...           ...          ...           ...          ...   \n145         146           6.7          3.0           5.2          2.3   \n146         147           6.3          2.5           5.0          1.9   \n147         148           6.5          3.0           5.2          2.0   \n148         149           6.2          3.4           5.4          2.3   \n149         150           5.9          3.0           5.1          1.8   \n\n       Species  \n0       setosa  \n1       setosa  \n2       setosa  \n3       setosa  \n4       setosa  \n..         ...  \n145  virginica  \n146  virginica  \n147  virginica  \n148  virginica  \n149  virginica  \n\n[150 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sepal.Length</th>\n      <th>Sepal.Width</th>\n      <th>Petal.Length</th>\n      <th>Petal.Width</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>146</td>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>147</td>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>148</td>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>150</td>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\n",
    "    'C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\ai\\\\.ipynb_checkpoints\\\\01_tensorflow_basic\\\\data_set\\\\iris.csv')\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "((150, 5), (150, 3))"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_df.iloc[ :, :-1 ].to_numpy()\n",
    "y_train = pd.get_dummies(train_df.iloc[ :, -1 ]).to_numpy()\n",
    "x_train.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 20)                120       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183\n",
      "Trainable params: 183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Dense(units=20, activation='relu', use_bias=True, input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(units=3, activation='sigmoid', use_bias=True)\n",
    "])\n",
    "\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 35.3560 - accuracy: 0.3333\n",
      "Epoch 2/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 33.1337 - accuracy: 0.3333\n",
      "Epoch 3/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.9098 - accuracy: 0.3333\n",
      "Epoch 4/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 28.6381 - accuracy: 0.3333\n",
      "Epoch 5/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26.6140 - accuracy: 0.3333\n",
      "Epoch 6/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.4824 - accuracy: 0.3333\n",
      "Epoch 7/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 22.4813 - accuracy: 0.3333\n",
      "Epoch 8/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 20.3483 - accuracy: 0.3333\n",
      "Epoch 9/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.4170 - accuracy: 0.3333\n",
      "Epoch 10/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.4888 - accuracy: 0.3333\n",
      "Epoch 11/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 14.5518 - accuracy: 0.3400\n",
      "Epoch 12/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12.6630 - accuracy: 0.3467\n",
      "Epoch 13/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10.9053 - accuracy: 0.3533\n",
      "Epoch 14/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.0111 - accuracy: 0.3667\n",
      "Epoch 15/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2379 - accuracy: 0.4267\n",
      "Epoch 16/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6541 - accuracy: 0.5467\n",
      "Epoch 17/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2474 - accuracy: 0.6400\n",
      "Epoch 18/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 2.8521 - accuracy: 0.5800\n",
      "Epoch 19/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5062 - accuracy: 0.6467\n",
      "Epoch 20/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.9668 - accuracy: 0.4200\n",
      "Epoch 21/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 1.1986 - accuracy: 0.4533\n",
      "Epoch 22/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2311 - accuracy: 0.4467\n",
      "Epoch 23/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0493 - accuracy: 0.4733\n",
      "Epoch 24/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8915 - accuracy: 0.5667\n",
      "Epoch 25/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8792 - accuracy: 0.4867\n",
      "Epoch 26/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8769 - accuracy: 0.5000\n",
      "Epoch 27/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8375 - accuracy: 0.5800\n",
      "Epoch 28/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8296 - accuracy: 0.6467\n",
      "Epoch 29/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8165 - accuracy: 0.6267\n",
      "Epoch 30/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7980 - accuracy: 0.6333\n",
      "Epoch 31/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.7877 - accuracy: 0.6533\n",
      "Epoch 32/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7830 - accuracy: 0.6133\n",
      "Epoch 33/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7722 - accuracy: 0.6267\n",
      "Epoch 34/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7624 - accuracy: 0.6600\n",
      "Epoch 35/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.6667\n",
      "Epoch 36/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7447 - accuracy: 0.6667\n",
      "Epoch 37/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6667\n",
      "Epoch 38/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.6667\n",
      "Epoch 39/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.6667\n",
      "Epoch 40/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.6667\n",
      "Epoch 41/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.6667\n",
      "Epoch 42/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.6667\n",
      "Epoch 43/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.6667\n",
      "Epoch 44/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6851 - accuracy: 0.6667\n",
      "Epoch 45/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.6667\n",
      "Epoch 46/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.6667\n",
      "Epoch 47/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6667\n",
      "Epoch 48/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6667\n",
      "Epoch 49/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6667\n",
      "Epoch 50/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6468 - accuracy: 0.6667\n",
      "Epoch 51/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.6667\n",
      "Epoch 52/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6667\n",
      "Epoch 53/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6667\n",
      "Epoch 54/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6211 - accuracy: 0.6667\n",
      "Epoch 55/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.6667\n",
      "Epoch 56/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6667\n",
      "Epoch 57/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6667\n",
      "Epoch 58/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.6667\n",
      "Epoch 59/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.6667\n",
      "Epoch 60/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.6667\n",
      "Epoch 61/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6667\n",
      "Epoch 62/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.6667\n",
      "Epoch 63/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.6667\n",
      "Epoch 64/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.6800\n",
      "Epoch 65/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.6800\n",
      "Epoch 66/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.5030 - accuracy: 0.7267\n",
      "Epoch 67/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.4729 - accuracy: 0.8000\n",
      "Epoch 68/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8400\n",
      "Epoch 69/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8400\n",
      "Epoch 70/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8600\n",
      "Epoch 71/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8600\n",
      "Epoch 72/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8533\n",
      "Epoch 73/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8600\n",
      "Epoch 74/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8400\n",
      "Epoch 75/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3534 - accuracy: 0.8533\n",
      "Epoch 76/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8533\n",
      "Epoch 77/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8533\n",
      "Epoch 78/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8733\n",
      "Epoch 79/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8733\n",
      "Epoch 80/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8600\n",
      "Epoch 81/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3354 - accuracy: 0.8733\n",
      "Epoch 82/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8733\n",
      "Epoch 83/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8800\n",
      "Epoch 84/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8667\n",
      "Epoch 85/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8800\n",
      "Epoch 86/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8867\n",
      "Epoch 87/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8867\n",
      "Epoch 88/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8600\n",
      "Epoch 89/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8733\n",
      "Epoch 90/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8800\n",
      "Epoch 91/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8933\n",
      "Epoch 92/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3072 - accuracy: 0.8933\n",
      "Epoch 93/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8933\n",
      "Epoch 94/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.8800\n",
      "Epoch 95/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8867\n",
      "Epoch 96/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8867\n",
      "Epoch 97/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8933\n",
      "Epoch 98/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2952 - accuracy: 0.8867\n",
      "Epoch 99/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2938 - accuracy: 0.8933\n",
      "Epoch 100/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.8867\n",
      "Epoch 101/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8933\n",
      "Epoch 102/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8867\n",
      "Epoch 103/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.8933\n",
      "Epoch 104/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.9067\n",
      "Epoch 105/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8933\n",
      "Epoch 106/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.9133\n",
      "Epoch 107/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8933\n",
      "Epoch 108/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.8933\n",
      "Epoch 109/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8933\n",
      "Epoch 110/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.9067\n",
      "Epoch 111/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8867\n",
      "Epoch 112/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.9000\n",
      "Epoch 113/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2747 - accuracy: 0.9000\n",
      "Epoch 114/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2716 - accuracy: 0.9067\n",
      "Epoch 115/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.8867\n",
      "Epoch 116/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.9000\n",
      "Epoch 117/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8933\n",
      "Epoch 118/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.9133\n",
      "Epoch 119/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.9067\n",
      "Epoch 120/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.8933\n",
      "Epoch 121/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8933\n",
      "Epoch 122/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8933\n",
      "Epoch 123/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.9067\n",
      "Epoch 124/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.9000\n",
      "Epoch 125/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.8867\n",
      "Epoch 126/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8933\n",
      "Epoch 127/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8867\n",
      "Epoch 128/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.8933\n",
      "Epoch 129/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9000\n",
      "Epoch 130/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.9000\n",
      "Epoch 131/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.9067\n",
      "Epoch 132/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.9133\n",
      "Epoch 133/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.9000\n",
      "Epoch 134/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8933\n",
      "Epoch 135/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.9000\n",
      "Epoch 136/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.9067\n",
      "Epoch 137/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9067\n",
      "Epoch 138/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.9133\n",
      "Epoch 139/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9000\n",
      "Epoch 140/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9000\n",
      "Epoch 141/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9067\n",
      "Epoch 142/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.9067\n",
      "Epoch 143/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9133\n",
      "Epoch 144/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2367 - accuracy: 0.9133\n",
      "Epoch 145/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.8933\n",
      "Epoch 146/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9067\n",
      "Epoch 147/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9133\n",
      "Epoch 148/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2365 - accuracy: 0.9133\n",
      "Epoch 149/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9067\n",
      "Epoch 150/700\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9133\n",
      "Epoch 151/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9200\n",
      "Epoch 152/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9133\n",
      "Epoch 153/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2294 - accuracy: 0.9067\n",
      "Epoch 154/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9067\n",
      "Epoch 155/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9133\n",
      "Epoch 156/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9133\n",
      "Epoch 157/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9200\n",
      "Epoch 158/700\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9133\n",
      "Epoch 159/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9133\n",
      "Epoch 160/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9067\n",
      "Epoch 161/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9067\n",
      "Epoch 162/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9067\n",
      "Epoch 163/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.9200\n",
      "Epoch 164/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9133\n",
      "Epoch 165/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9200\n",
      "Epoch 166/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2156 - accuracy: 0.9267\n",
      "Epoch 167/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.9133\n",
      "Epoch 168/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9133\n",
      "Epoch 169/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9133\n",
      "Epoch 170/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9267\n",
      "Epoch 171/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9267\n",
      "Epoch 172/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9267\n",
      "Epoch 173/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9200\n",
      "Epoch 174/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9133\n",
      "Epoch 175/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9267\n",
      "Epoch 176/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9333\n",
      "Epoch 177/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.9200\n",
      "Epoch 178/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9133\n",
      "Epoch 179/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2050 - accuracy: 0.9267\n",
      "Epoch 180/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2037 - accuracy: 0.9267\n",
      "Epoch 181/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.9267\n",
      "Epoch 182/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9200\n",
      "Epoch 183/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9400\n",
      "Epoch 184/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9333\n",
      "Epoch 185/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9267\n",
      "Epoch 186/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9333\n",
      "Epoch 187/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9333\n",
      "Epoch 188/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9267\n",
      "Epoch 189/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9333\n",
      "Epoch 190/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9333\n",
      "Epoch 191/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9333\n",
      "Epoch 192/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9400\n",
      "Epoch 193/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9333\n",
      "Epoch 194/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9333\n",
      "Epoch 195/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.9267\n",
      "Epoch 196/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9333\n",
      "Epoch 197/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9333\n",
      "Epoch 198/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9333\n",
      "Epoch 199/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9333\n",
      "Epoch 200/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9267\n",
      "Epoch 201/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9333\n",
      "Epoch 202/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9333\n",
      "Epoch 203/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9333\n",
      "Epoch 204/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9400\n",
      "Epoch 205/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9400\n",
      "Epoch 206/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1861 - accuracy: 0.9467\n",
      "Epoch 207/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9400\n",
      "Epoch 208/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9467\n",
      "Epoch 209/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9467\n",
      "Epoch 210/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9467\n",
      "Epoch 211/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9467\n",
      "Epoch 212/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9333\n",
      "Epoch 213/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9333\n",
      "Epoch 214/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9400\n",
      "Epoch 215/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9400\n",
      "Epoch 216/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9400\n",
      "Epoch 217/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9467\n",
      "Epoch 218/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9400\n",
      "Epoch 219/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9400\n",
      "Epoch 220/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9467\n",
      "Epoch 221/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9467\n",
      "Epoch 222/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9400\n",
      "Epoch 223/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9467\n",
      "Epoch 224/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9467\n",
      "Epoch 225/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1736 - accuracy: 0.9467\n",
      "Epoch 226/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9467\n",
      "Epoch 227/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.9467\n",
      "Epoch 228/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9333\n",
      "Epoch 229/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9400\n",
      "Epoch 230/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1680 - accuracy: 0.9467\n",
      "Epoch 231/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9467\n",
      "Epoch 232/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1669 - accuracy: 0.9467\n",
      "Epoch 233/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9533\n",
      "Epoch 234/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9400\n",
      "Epoch 235/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9533\n",
      "Epoch 236/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9400\n",
      "Epoch 237/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1640 - accuracy: 0.9467\n",
      "Epoch 238/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1649 - accuracy: 0.9533\n",
      "Epoch 239/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1625 - accuracy: 0.9533\n",
      "Epoch 240/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9467\n",
      "Epoch 241/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9467\n",
      "Epoch 242/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9533\n",
      "Epoch 243/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1603 - accuracy: 0.9533\n",
      "Epoch 244/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9600\n",
      "Epoch 245/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9533\n",
      "Epoch 246/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9667\n",
      "Epoch 247/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9467\n",
      "Epoch 248/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9600\n",
      "Epoch 249/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9600\n",
      "Epoch 250/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1562 - accuracy: 0.9600\n",
      "Epoch 251/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1573 - accuracy: 0.9467\n",
      "Epoch 252/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9600\n",
      "Epoch 253/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9533\n",
      "Epoch 254/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1540 - accuracy: 0.9667\n",
      "Epoch 255/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1543 - accuracy: 0.9533\n",
      "Epoch 256/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1532 - accuracy: 0.9600\n",
      "Epoch 257/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1530 - accuracy: 0.9600\n",
      "Epoch 258/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9533\n",
      "Epoch 259/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9467\n",
      "Epoch 260/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9600\n",
      "Epoch 261/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1523 - accuracy: 0.9600\n",
      "Epoch 262/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9667\n",
      "Epoch 263/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9533\n",
      "Epoch 264/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9600\n",
      "Epoch 265/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9600\n",
      "Epoch 266/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9733\n",
      "Epoch 267/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9533\n",
      "Epoch 268/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9533\n",
      "Epoch 269/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1453 - accuracy: 0.9600\n",
      "Epoch 270/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9600\n",
      "Epoch 271/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9533\n",
      "Epoch 272/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9667\n",
      "Epoch 273/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1435 - accuracy: 0.9667\n",
      "Epoch 274/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9733\n",
      "Epoch 275/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9667\n",
      "Epoch 276/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9600\n",
      "Epoch 277/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9600\n",
      "Epoch 278/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9667\n",
      "Epoch 279/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9667\n",
      "Epoch 280/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9733\n",
      "Epoch 281/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1405 - accuracy: 0.9600\n",
      "Epoch 282/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1378 - accuracy: 0.9667\n",
      "Epoch 283/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9667\n",
      "Epoch 284/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9600\n",
      "Epoch 285/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9667\n",
      "Epoch 286/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9667\n",
      "Epoch 287/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9667\n",
      "Epoch 288/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1351 - accuracy: 0.9733\n",
      "Epoch 289/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9733\n",
      "Epoch 290/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9667\n",
      "Epoch 291/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9667\n",
      "Epoch 292/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9733\n",
      "Epoch 293/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9667\n",
      "Epoch 294/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9667\n",
      "Epoch 295/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9733\n",
      "Epoch 296/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9667\n",
      "Epoch 297/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9733\n",
      "Epoch 298/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9733\n",
      "Epoch 299/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9600\n",
      "Epoch 300/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9733\n",
      "Epoch 301/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9733\n",
      "Epoch 302/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9733\n",
      "Epoch 303/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9733\n",
      "Epoch 304/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9733\n",
      "Epoch 305/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9667\n",
      "Epoch 306/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9733\n",
      "Epoch 307/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9800\n",
      "Epoch 308/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1253 - accuracy: 0.9733\n",
      "Epoch 309/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9533\n",
      "Epoch 310/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9733\n",
      "Epoch 311/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1245 - accuracy: 0.9800\n",
      "Epoch 312/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9733\n",
      "Epoch 313/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1229 - accuracy: 0.9733\n",
      "Epoch 314/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9800\n",
      "Epoch 315/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9800\n",
      "Epoch 316/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1212 - accuracy: 0.9733\n",
      "Epoch 317/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1205 - accuracy: 0.9733\n",
      "Epoch 318/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1225 - accuracy: 0.9733\n",
      "Epoch 319/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9800\n",
      "Epoch 320/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9800\n",
      "Epoch 321/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1190 - accuracy: 0.9800\n",
      "Epoch 322/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9800\n",
      "Epoch 323/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1209 - accuracy: 0.9800\n",
      "Epoch 324/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1185 - accuracy: 0.9733\n",
      "Epoch 325/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9800\n",
      "Epoch 326/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9800\n",
      "Epoch 327/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9800\n",
      "Epoch 328/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9800\n",
      "Epoch 329/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9667\n",
      "Epoch 330/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9800\n",
      "Epoch 331/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9800\n",
      "Epoch 332/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9733\n",
      "Epoch 333/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9800\n",
      "Epoch 334/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9800\n",
      "Epoch 335/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9800\n",
      "Epoch 336/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9867\n",
      "Epoch 337/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9733\n",
      "Epoch 338/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9667\n",
      "Epoch 339/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9667\n",
      "Epoch 340/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9667\n",
      "Epoch 341/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9800\n",
      "Epoch 342/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9800\n",
      "Epoch 343/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9800\n",
      "Epoch 344/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9800\n",
      "Epoch 345/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9867\n",
      "Epoch 346/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.9800\n",
      "Epoch 347/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9800\n",
      "Epoch 348/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9867\n",
      "Epoch 349/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9800\n",
      "Epoch 350/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9867\n",
      "Epoch 351/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1066 - accuracy: 0.9867\n",
      "Epoch 352/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9800\n",
      "Epoch 353/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9867\n",
      "Epoch 354/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1047 - accuracy: 0.9867\n",
      "Epoch 355/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9867\n",
      "Epoch 356/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9800\n",
      "Epoch 357/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9800\n",
      "Epoch 358/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9867\n",
      "Epoch 359/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1037 - accuracy: 0.9867\n",
      "Epoch 360/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1054 - accuracy: 0.9867\n",
      "Epoch 361/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9867\n",
      "Epoch 362/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9867\n",
      "Epoch 363/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1012 - accuracy: 0.9867\n",
      "Epoch 364/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1013 - accuracy: 0.9800\n",
      "Epoch 365/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9800\n",
      "Epoch 366/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9867\n",
      "Epoch 367/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9800\n",
      "Epoch 368/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0994 - accuracy: 0.9867\n",
      "Epoch 369/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1003 - accuracy: 0.9867\n",
      "Epoch 370/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9800\n",
      "Epoch 371/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9867\n",
      "Epoch 372/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0989 - accuracy: 0.9867\n",
      "Epoch 373/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0975 - accuracy: 0.9867\n",
      "Epoch 374/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9867\n",
      "Epoch 375/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9867\n",
      "Epoch 376/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9867\n",
      "Epoch 377/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0965 - accuracy: 0.9800\n",
      "Epoch 378/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0968 - accuracy: 0.9867\n",
      "Epoch 379/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9867\n",
      "Epoch 380/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9800\n",
      "Epoch 381/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9867\n",
      "Epoch 382/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 1.0000\n",
      "Epoch 383/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9800\n",
      "Epoch 384/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9867\n",
      "Epoch 385/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9867\n",
      "Epoch 386/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9933\n",
      "Epoch 387/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0929 - accuracy: 0.9933\n",
      "Epoch 388/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9867\n",
      "Epoch 389/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0924 - accuracy: 0.9867\n",
      "Epoch 390/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9933\n",
      "Epoch 391/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 1.0000\n",
      "Epoch 392/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9867\n",
      "Epoch 393/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9867\n",
      "Epoch 394/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9867\n",
      "Epoch 395/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9933\n",
      "Epoch 396/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9933\n",
      "Epoch 397/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9867\n",
      "Epoch 398/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 1.0000\n",
      "Epoch 399/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0890 - accuracy: 0.9933\n",
      "Epoch 400/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 1.0000\n",
      "Epoch 401/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9933\n",
      "Epoch 402/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9933\n",
      "Epoch 403/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9933\n",
      "Epoch 404/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9933\n",
      "Epoch 405/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9933\n",
      "Epoch 406/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0872 - accuracy: 0.9933\n",
      "Epoch 407/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 1.0000\n",
      "Epoch 408/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 1.0000\n",
      "Epoch 409/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0857 - accuracy: 0.9933\n",
      "Epoch 410/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0863 - accuracy: 0.9933\n",
      "Epoch 411/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0840 - accuracy: 1.0000\n",
      "Epoch 412/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0889 - accuracy: 0.9800\n",
      "Epoch 413/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.9933\n",
      "Epoch 414/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9933\n",
      "Epoch 415/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9933\n",
      "Epoch 416/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0833 - accuracy: 1.0000\n",
      "Epoch 417/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 1.0000\n",
      "Epoch 418/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0855 - accuracy: 1.0000\n",
      "Epoch 419/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9933\n",
      "Epoch 420/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9933\n",
      "Epoch 421/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0827 - accuracy: 0.9867\n",
      "Epoch 422/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 1.0000\n",
      "Epoch 423/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 424/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9933\n",
      "Epoch 425/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0799 - accuracy: 1.0000\n",
      "Epoch 426/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9867\n",
      "Epoch 427/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0793 - accuracy: 0.9933\n",
      "Epoch 428/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0813 - accuracy: 0.9933\n",
      "Epoch 429/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 430/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9867\n",
      "Epoch 431/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 1.0000\n",
      "Epoch 432/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 1.0000\n",
      "Epoch 433/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 1.0000\n",
      "Epoch 434/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 1.0000\n",
      "Epoch 435/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9933\n",
      "Epoch 436/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 437/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 1.0000\n",
      "Epoch 438/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 439/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 1.0000\n",
      "Epoch 440/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 1.0000\n",
      "Epoch 441/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 1.0000\n",
      "Epoch 442/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 1.0000\n",
      "Epoch 443/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 1.0000\n",
      "Epoch 444/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 445/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 1.0000\n",
      "Epoch 446/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 1.0000\n",
      "Epoch 447/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 448/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 1.0000\n",
      "Epoch 449/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 450/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 1.0000\n",
      "Epoch 451/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 452/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 1.0000\n",
      "Epoch 453/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 1.0000\n",
      "Epoch 454/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 1.0000\n",
      "Epoch 455/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 1.0000\n",
      "Epoch 456/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 1.0000\n",
      "Epoch 457/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "Epoch 458/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 1.0000\n",
      "Epoch 459/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 460/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 1.0000\n",
      "Epoch 461/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 1.0000\n",
      "Epoch 462/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 1.0000\n",
      "Epoch 463/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 464/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 1.0000\n",
      "Epoch 465/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 1.0000\n",
      "Epoch 466/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 467/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 468/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 469/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 1.0000\n",
      "Epoch 470/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 471/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 1.0000\n",
      "Epoch 472/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 473/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 1.0000\n",
      "Epoch 474/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 1.0000\n",
      "Epoch 475/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 1.0000\n",
      "Epoch 476/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 1.0000\n",
      "Epoch 477/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 1.0000\n",
      "Epoch 478/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 479/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 1.0000\n",
      "Epoch 480/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 1.0000\n",
      "Epoch 481/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 1.0000\n",
      "Epoch 482/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 1.0000\n",
      "Epoch 483/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 1.0000\n",
      "Epoch 484/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 1.0000\n",
      "Epoch 485/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 1.0000\n",
      "Epoch 486/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 1.0000\n",
      "Epoch 487/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 1.0000\n",
      "Epoch 488/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 1.0000\n",
      "Epoch 489/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 490/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 491/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 1.0000\n",
      "Epoch 492/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 1.0000\n",
      "Epoch 493/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 1.0000\n",
      "Epoch 494/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 1.0000\n",
      "Epoch 495/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 1.0000\n",
      "Epoch 496/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 1.0000\n",
      "Epoch 497/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 1.0000\n",
      "Epoch 498/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 499/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 1.0000\n",
      "Epoch 500/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 501/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 502/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 503/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 504/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 1.0000\n",
      "Epoch 505/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 506/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 507/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 508/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 1.0000\n",
      "Epoch 509/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0577 - accuracy: 1.0000\n",
      "Epoch 510/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 1.0000\n",
      "Epoch 511/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 1.0000\n",
      "Epoch 512/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 513/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 1.0000\n",
      "Epoch 514/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 1.0000\n",
      "Epoch 515/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 1.0000\n",
      "Epoch 516/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 1.0000\n",
      "Epoch 517/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 1.0000\n",
      "Epoch 518/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 1.0000\n",
      "Epoch 519/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0581 - accuracy: 1.0000\n",
      "Epoch 520/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 1.0000\n",
      "Epoch 521/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 1.0000\n",
      "Epoch 522/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 523/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "Epoch 524/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 1.0000\n",
      "Epoch 525/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 526/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 527/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0563 - accuracy: 1.0000\n",
      "Epoch 528/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 529/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 530/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 1.0000\n",
      "Epoch 531/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 1.0000\n",
      "Epoch 532/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0554 - accuracy: 1.0000\n",
      "Epoch 533/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 1.0000\n",
      "Epoch 534/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0532 - accuracy: 1.0000\n",
      "Epoch 535/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 536/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 1.0000\n",
      "Epoch 537/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 538/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0535 - accuracy: 1.0000\n",
      "Epoch 539/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 540/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 541/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 542/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 1.0000\n",
      "Epoch 543/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "Epoch 544/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 545/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 1.0000\n",
      "Epoch 546/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 1.0000\n",
      "Epoch 547/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 1.0000\n",
      "Epoch 548/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 549/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 550/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0516 - accuracy: 1.0000\n",
      "Epoch 551/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 552/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0512 - accuracy: 1.0000\n",
      "Epoch 553/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 1.0000\n",
      "Epoch 554/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0504 - accuracy: 1.0000\n",
      "Epoch 555/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 1.0000\n",
      "Epoch 556/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0502 - accuracy: 1.0000\n",
      "Epoch 557/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0494 - accuracy: 1.0000\n",
      "Epoch 558/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 559/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 1.0000\n",
      "Epoch 560/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 561/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 562/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 1.0000\n",
      "Epoch 563/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 564/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 565/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 1.0000\n",
      "Epoch 566/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Epoch 567/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 568/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 569/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 570/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 571/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 1.0000\n",
      "Epoch 572/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0497 - accuracy: 1.0000\n",
      "Epoch 573/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Epoch 574/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 1.0000\n",
      "Epoch 575/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0471 - accuracy: 1.0000\n",
      "Epoch 576/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 577/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0478 - accuracy: 1.0000\n",
      "Epoch 578/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 1.0000\n",
      "Epoch 579/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 1.0000\n",
      "Epoch 580/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 581/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 1.0000\n",
      "Epoch 582/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 583/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 584/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Epoch 585/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 586/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 587/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 588/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 1.0000\n",
      "Epoch 589/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 590/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 1.0000\n",
      "Epoch 591/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 1.0000\n",
      "Epoch 592/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 593/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 594/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 595/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 596/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 597/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 598/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 599/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 600/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 601/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 1.0000\n",
      "Epoch 602/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 603/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 604/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 605/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 1.0000\n",
      "Epoch 606/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 1.0000\n",
      "Epoch 607/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 608/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 609/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 1.0000\n",
      "Epoch 610/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 611/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 1.0000\n",
      "Epoch 612/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 613/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 614/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 615/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 616/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 617/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 618/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 619/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0404 - accuracy: 1.0000\n",
      "Epoch 620/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 621/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 622/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 623/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "Epoch 624/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 625/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0392 - accuracy: 1.0000\n",
      "Epoch 626/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 627/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 628/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 1.0000\n",
      "Epoch 629/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 630/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 631/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 1.0000\n",
      "Epoch 632/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 633/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 634/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 635/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 636/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 637/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 638/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 639/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "Epoch 640/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 641/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 642/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 643/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 644/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 645/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 646/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 647/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 648/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 649/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 650/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 651/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 652/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 653/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 654/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 655/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 656/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 657/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 658/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 659/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 660/700\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 661/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 662/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 663/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 664/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 665/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 666/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 667/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 668/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 669/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 670/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 671/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 672/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 673/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 674/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 675/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 676/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 677/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 678/700\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 679/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 680/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 681/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 682/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 683/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 684/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 685/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 686/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 687/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 688/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 689/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 690/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 691/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 1.0000\n",
      "Epoch 692/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 693/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 694/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 695/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 696/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 697/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 698/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 699/700\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 700/700\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0312 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model1.fit(x=x_train, y=y_train, epochs=700)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 40)                240       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,123\n",
      "Trainable params: 1,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Dense(units=40, activation='relu', use_bias=True, input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(units=20, activation='relu', use_bias=True),\n",
    "    tf.keras.layers.Dense(units=3, activation='sigmoid', use_bias=True)\n",
    "])\n",
    "\n",
    "model2.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.9723 - accuracy: 0.3333\n",
      "Epoch 2/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.4230 - accuracy: 0.3400\n",
      "Epoch 3/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.2499 - accuracy: 0.3333\n",
      "Epoch 4/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.9283 - accuracy: 0.3333\n",
      "Epoch 5/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.4493 - accuracy: 0.3000\n",
      "Epoch 6/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.2833 - accuracy: 0.3333\n",
      "Epoch 7/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.0158 - accuracy: 0.3333\n",
      "Epoch 8/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6400 - accuracy: 0.3800\n",
      "Epoch 9/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3578 - accuracy: 0.4400\n",
      "Epoch 10/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1550 - accuracy: 0.4267\n",
      "Epoch 11/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9659 - accuracy: 0.5133\n",
      "Epoch 12/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8689 - accuracy: 0.5400\n",
      "Epoch 13/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9390 - accuracy: 0.5400\n",
      "Epoch 14/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.5667\n",
      "Epoch 15/700\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8879 - accuracy: 0.5467\n",
      "Epoch 16/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.8245 - accuracy: 0.5400\n",
      "Epoch 17/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.6133\n",
      "Epoch 18/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8308 - accuracy: 0.6200\n",
      "Epoch 19/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8117 - accuracy: 0.6333\n",
      "Epoch 20/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7939 - accuracy: 0.6000\n",
      "Epoch 21/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7803 - accuracy: 0.5600\n",
      "Epoch 22/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7366 - accuracy: 0.6400\n",
      "Epoch 23/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7120 - accuracy: 0.7000\n",
      "Epoch 24/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.7000\n",
      "Epoch 25/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.7000\n",
      "Epoch 26/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7133\n",
      "Epoch 27/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.7200\n",
      "Epoch 28/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.7467\n",
      "Epoch 29/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7800\n",
      "Epoch 30/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7800\n",
      "Epoch 31/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7867\n",
      "Epoch 32/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7867\n",
      "Epoch 33/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7733\n",
      "Epoch 34/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7667\n",
      "Epoch 35/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7933\n",
      "Epoch 36/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.8067\n",
      "Epoch 37/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.8200\n",
      "Epoch 38/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.8067\n",
      "Epoch 39/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8333\n",
      "Epoch 40/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8200\n",
      "Epoch 41/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8200\n",
      "Epoch 42/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8067\n",
      "Epoch 43/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.8467\n",
      "Epoch 44/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.8400\n",
      "Epoch 45/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8133\n",
      "Epoch 46/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8067\n",
      "Epoch 47/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8333\n",
      "Epoch 48/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8400\n",
      "Epoch 49/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8133\n",
      "Epoch 50/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8400\n",
      "Epoch 51/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8267\n",
      "Epoch 52/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8533\n",
      "Epoch 53/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8467\n",
      "Epoch 54/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8267\n",
      "Epoch 55/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8133\n",
      "Epoch 56/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8200\n",
      "Epoch 57/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8333\n",
      "Epoch 58/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8133\n",
      "Epoch 59/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8333\n",
      "Epoch 60/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8533\n",
      "Epoch 61/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8400\n",
      "Epoch 62/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8533\n",
      "Epoch 63/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8533\n",
      "Epoch 64/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8400\n",
      "Epoch 65/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8467\n",
      "Epoch 66/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8600\n",
      "Epoch 67/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8533\n",
      "Epoch 68/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8467\n",
      "Epoch 69/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8533\n",
      "Epoch 70/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8533\n",
      "Epoch 71/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8667\n",
      "Epoch 72/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8733\n",
      "Epoch 73/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8533\n",
      "Epoch 74/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8600\n",
      "Epoch 75/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8733\n",
      "Epoch 76/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8600\n",
      "Epoch 77/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8733\n",
      "Epoch 78/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8667\n",
      "Epoch 79/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8667\n",
      "Epoch 80/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8800\n",
      "Epoch 81/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8800\n",
      "Epoch 82/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8867\n",
      "Epoch 83/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.8800\n",
      "Epoch 84/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8867\n",
      "Epoch 85/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9000\n",
      "Epoch 86/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8800\n",
      "Epoch 87/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9000\n",
      "Epoch 88/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8733\n",
      "Epoch 89/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8933\n",
      "Epoch 90/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.8800\n",
      "Epoch 91/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8933\n",
      "Epoch 92/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8867\n",
      "Epoch 93/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9000\n",
      "Epoch 94/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.9000\n",
      "Epoch 95/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9000\n",
      "Epoch 96/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8933\n",
      "Epoch 97/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 98/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.8933\n",
      "Epoch 99/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.8933\n",
      "Epoch 100/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.8933\n",
      "Epoch 101/700\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.2318 - accuracy: 0.9067\n",
      "Epoch 102/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.8867\n",
      "Epoch 103/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9067\n",
      "Epoch 104/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9000\n",
      "Epoch 105/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9000\n",
      "Epoch 106/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9133\n",
      "Epoch 107/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9067\n",
      "Epoch 108/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9067\n",
      "Epoch 109/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9000\n",
      "Epoch 110/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9133\n",
      "Epoch 111/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9000\n",
      "Epoch 112/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9000\n",
      "Epoch 113/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9133\n",
      "Epoch 114/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9133\n",
      "Epoch 115/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9200\n",
      "Epoch 116/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9067\n",
      "Epoch 117/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9267\n",
      "Epoch 118/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9267\n",
      "Epoch 119/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9133\n",
      "Epoch 120/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9200\n",
      "Epoch 121/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9333\n",
      "Epoch 122/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9333\n",
      "Epoch 123/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9200\n",
      "Epoch 124/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9200\n",
      "Epoch 125/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9133\n",
      "Epoch 126/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9267\n",
      "Epoch 127/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9267\n",
      "Epoch 128/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9333\n",
      "Epoch 129/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9267\n",
      "Epoch 130/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9133\n",
      "Epoch 131/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9333\n",
      "Epoch 132/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9333\n",
      "Epoch 133/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9400\n",
      "Epoch 134/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9333\n",
      "Epoch 135/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9333\n",
      "Epoch 136/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9467\n",
      "Epoch 137/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9333\n",
      "Epoch 138/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9267\n",
      "Epoch 139/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9400\n",
      "Epoch 140/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9400\n",
      "Epoch 141/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9400\n",
      "Epoch 142/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9533\n",
      "Epoch 143/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9533\n",
      "Epoch 144/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9400\n",
      "Epoch 145/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9333\n",
      "Epoch 146/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9467\n",
      "Epoch 147/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9533\n",
      "Epoch 148/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9467\n",
      "Epoch 149/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9667\n",
      "Epoch 150/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9267\n",
      "Epoch 151/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9400\n",
      "Epoch 152/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9533\n",
      "Epoch 153/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9533\n",
      "Epoch 154/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9667\n",
      "Epoch 155/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9533\n",
      "Epoch 156/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9533\n",
      "Epoch 157/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9533\n",
      "Epoch 158/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9467\n",
      "Epoch 159/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9600\n",
      "Epoch 160/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9667\n",
      "Epoch 161/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9400\n",
      "Epoch 162/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9600\n",
      "Epoch 163/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9600\n",
      "Epoch 164/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9533\n",
      "Epoch 165/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9467\n",
      "Epoch 166/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9600\n",
      "Epoch 167/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9733\n",
      "Epoch 168/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9667\n",
      "Epoch 169/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9800\n",
      "Epoch 170/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9800\n",
      "Epoch 171/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9800\n",
      "Epoch 172/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9800\n",
      "Epoch 173/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9867\n",
      "Epoch 174/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9733\n",
      "Epoch 175/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9867\n",
      "Epoch 176/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9733\n",
      "Epoch 177/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9800\n",
      "Epoch 178/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9800\n",
      "Epoch 179/700\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9867\n",
      "Epoch 180/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9733\n",
      "Epoch 181/700\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 1.0000\n",
      "Epoch 182/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9867\n",
      "Epoch 183/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9800\n",
      "Epoch 184/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9933\n",
      "Epoch 185/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9933\n",
      "Epoch 186/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 187/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9733\n",
      "Epoch 188/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9867\n",
      "Epoch 189/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9800\n",
      "Epoch 190/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9600\n",
      "Epoch 191/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9667\n",
      "Epoch 192/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9733\n",
      "Epoch 193/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9733\n",
      "Epoch 194/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9733\n",
      "Epoch 195/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 1.0000\n",
      "Epoch 196/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9733\n",
      "Epoch 197/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9867\n",
      "Epoch 198/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9933\n",
      "Epoch 199/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 1.0000\n",
      "Epoch 200/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9933\n",
      "Epoch 201/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 1.0000\n",
      "Epoch 202/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9867\n",
      "Epoch 203/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9933\n",
      "Epoch 204/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 1.0000\n",
      "Epoch 205/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9933\n",
      "Epoch 206/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 1.0000\n",
      "Epoch 207/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9867\n",
      "Epoch 208/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9867\n",
      "Epoch 209/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9800\n",
      "Epoch 210/700\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9800\n",
      "Epoch 211/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 1.0000\n",
      "Epoch 212/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9733\n",
      "Epoch 213/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 1.0000\n",
      "Epoch 214/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 1.0000\n",
      "Epoch 215/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 1.0000\n",
      "Epoch 216/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 1.0000\n",
      "Epoch 217/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 1.0000\n",
      "Epoch 218/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 1.0000\n",
      "Epoch 219/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 1.0000\n",
      "Epoch 220/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 221/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 1.0000\n",
      "Epoch 222/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 223/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 224/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 1.0000\n",
      "Epoch 225/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 1.0000\n",
      "Epoch 226/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 227/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 1.0000\n",
      "Epoch 228/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 1.0000\n",
      "Epoch 229/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 1.0000\n",
      "Epoch 230/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 231/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 232/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 1.0000\n",
      "Epoch 233/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 1.0000\n",
      "Epoch 234/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 235/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 1.0000\n",
      "Epoch 236/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 237/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Epoch 238/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 1.0000\n",
      "Epoch 239/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 1.0000\n",
      "Epoch 240/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 1.0000\n",
      "Epoch 241/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 242/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 243/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 244/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 1.0000\n",
      "Epoch 245/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 246/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
      "Epoch 247/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 1.0000\n",
      "Epoch 248/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 249/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 250/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 251/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 252/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000\n",
      "Epoch 253/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 254/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 1.0000\n",
      "Epoch 255/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 256/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 257/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 1.0000\n",
      "Epoch 258/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 259/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 260/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 261/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 262/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 263/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 264/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 1.0000\n",
      "Epoch 265/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 266/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 267/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 268/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 269/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 270/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 271/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 272/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 273/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 274/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 275/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 1.0000\n",
      "Epoch 276/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 277/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 278/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 279/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 280/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 281/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 282/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 283/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 284/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 285/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 286/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 287/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 288/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 289/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 290/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 291/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 292/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 293/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 294/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 295/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 296/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 297/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 298/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 299/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 300/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 301/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 302/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 303/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 304/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 305/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 306/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 307/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 308/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 309/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 310/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 311/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 312/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 313/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 314/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 315/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 316/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 317/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 318/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 319/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9933\n",
      "Epoch 320/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 321/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 322/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9933\n",
      "Epoch 323/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 324/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 325/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Epoch 326/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 327/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 328/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 329/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 330/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 331/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 332/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 333/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 334/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 335/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 336/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 337/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 338/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 339/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 340/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 341/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 342/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 343/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 344/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 345/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 346/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 347/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 348/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 349/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 350/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 351/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 352/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 353/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 354/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 355/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 356/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 357/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 358/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 359/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 360/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 361/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 362/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 363/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 364/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 365/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 366/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 367/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 368/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 369/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 370/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 371/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 372/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 373/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 374/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9933\n",
      "Epoch 375/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 376/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 377/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 378/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 379/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 380/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 381/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 382/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 383/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 384/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 385/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 386/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 387/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 388/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 389/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 390/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 391/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 392/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 393/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 394/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 395/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 396/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 397/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 398/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 399/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 400/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 401/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 402/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 403/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 404/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 405/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 406/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 407/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 408/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 409/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 410/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 411/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 412/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 413/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 414/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 415/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 416/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 417/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 418/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 419/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 420/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 421/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 422/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 423/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 424/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 425/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 426/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 427/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 428/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 429/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 430/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 431/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 432/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 433/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 434/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 435/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 436/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 437/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 438/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 439/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 440/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 441/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 442/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 443/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 444/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 445/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 446/700\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 447/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 448/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 449/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 450/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 451/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 452/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 453/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 454/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 455/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 456/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 457/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9933\n",
      "Epoch 458/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 459/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 460/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 461/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 462/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 463/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 464/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 465/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 466/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 467/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 468/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 469/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 470/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 471/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 472/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 473/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 474/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 475/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 476/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 477/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 478/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 479/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 480/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 481/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 482/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 483/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 484/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 485/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 486/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 487/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 488/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 489/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 490/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 491/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 492/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 493/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 494/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 495/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 496/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 497/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 498/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 499/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 500/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 501/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 502/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 503/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 504/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 505/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 506/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 507/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 508/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 509/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 510/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 511/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 512/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 513/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 514/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 515/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 516/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 517/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 518/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 519/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 520/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 521/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 522/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 523/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 524/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 525/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 526/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 527/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 528/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 529/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 530/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 531/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 532/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 533/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 534/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 535/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 536/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 537/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 538/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 539/700\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 540/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 541/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 542/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 543/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 544/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 545/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 546/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 547/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 548/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 549/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 550/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 551/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 552/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 553/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 554/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 555/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 556/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 557/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 558/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 559/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 560/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 561/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 562/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 563/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9933\n",
      "Epoch 564/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 565/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 566/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 567/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 568/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 569/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 570/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 571/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 572/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 573/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 574/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 575/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 576/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 577/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 578/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 579/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 580/700\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 581/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 582/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 583/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 584/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 585/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 586/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 587/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 588/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 589/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 590/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 591/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 592/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 593/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 594/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 595/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 596/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 597/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 598/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 599/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 600/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 601/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 602/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 603/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 604/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 605/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 606/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 607/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 608/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 609/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 610/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 611/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 612/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 613/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 614/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 615/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 616/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 617/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 618/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 619/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 620/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 621/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 622/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 623/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 624/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 625/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 626/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 627/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 628/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 629/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 630/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 631/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 632/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 633/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 634/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 635/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 636/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 637/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 638/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 639/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 640/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 641/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 642/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 643/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 644/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 645/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 646/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 647/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 648/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 649/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 650/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 651/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 652/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 653/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 654/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 655/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 656/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 657/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 658/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 659/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 660/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 661/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 662/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 663/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 664/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 665/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 666/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 667/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 668/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 669/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 670/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 671/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 672/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 673/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 674/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 675/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 676/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 677/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 678/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 679/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 680/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 681/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 682/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 683/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 684/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 685/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 686/700\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 687/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 688/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 689/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 690/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 691/700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 692/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 693/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 694/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 695/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 696/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 697/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 698/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 699/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 700/700\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist2 = model2.fit(x=x_train, y=y_train, epochs=700, batch_size = 64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(0, 700), y=hist.history[ 'accuracy' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(0, 700), y=hist2.history[ 'accuracy' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
