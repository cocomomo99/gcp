{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# multi classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# train data set :\n",
    "# x_data :  [N,4]  --> [8,4]\n",
    "x_data = [[1,2,1,1],\n",
    "          [2,1,3,2],\n",
    "          [3,1,3,4],\n",
    "          [4,1,5,5],\n",
    "          [1,7,5,5],\n",
    "          [1,2,5,6],\n",
    "          [1,6,6,6],\n",
    "          [1,7,7,7]]\n",
    "\n",
    "# y_data : [N,3] --> [8,3]\n",
    "y_data = [[0,0,1],  # [2]\n",
    "          [0,0,1],  # [2]\n",
    "          [0,0,1],  # [2]\n",
    "          [0,1,0],  # [1]\n",
    "          [0,1,0],  # [1]\n",
    "          [0,1,0],  # [1]\n",
    "          [1,0,0],  # [0]\n",
    "          [1,0,0]]  # [0]\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data, dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Variable 'weight:0' shape=(4, 3) dtype=float32, numpy=\n array([[0.40544227, 0.6630032 , 0.46134534],\n        [0.3782173 , 0.34672758, 0.7380845 ],\n        [0.8848354 , 0.68986994, 0.83316207],\n        [0.99768263, 0.9884882 , 0.8512691 ]], dtype=float32)>,\n <tf.Variable 'bias:0' shape=(1,) dtype=float32, numpy=array([0.5040651], dtype=float32)>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(np.random.random([4,3]), dtype= tf.float32, name= 'weight')\n",
    "b = tf.Variable(np.random.random([1]), dtype= tf.float32, name= 'bias')\n",
    "w, b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return tf.matmul(x, w) + b\n",
    "\n",
    "def cost(x):\n",
    "    return tf.nn.softmax(logit(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\narray([[5.6474343e-22, 6.5032459e-14, 9.9999994e-01],\n       [2.1211877e-04, 3.7583609e-03, 9.9602944e-01],\n       [1.5296125e-27, 4.8648217e-03, 9.9513507e-01],\n       [7.7361841e-20, 9.9483424e-01, 5.1658046e-03],\n       [4.2992230e-03, 9.9529690e-01, 4.0370654e-04],\n       [2.0696288e-03, 9.9793041e-01, 0.0000000e+00],\n       [9.9445552e-01, 5.5445246e-03, 2.1325811e-24],\n       [9.9990720e-01, 9.2717368e-05, 7.3361815e-32]], dtype=float32)>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(x_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def cost():\n",
    "   return tf.nn.softmax_cross_entropy_with_logits(logits= logit(x_train), labels = y_train, axis= 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=float32, numpy=\narray([0.00000000e+00, 1.69275772e-05, 2.05037868e-05, 2.16958560e-05,\n       2.38415723e-05, 1.12056105e-05, 2.89674354e-05, 0.00000000e+00],\n      dtype=float32)>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = cost()\n",
    "prob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## gradient descent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 \n",
      " cost :\n",
      " [0.0000000e+00 3.6390289e-03 4.9007060e-03 5.1379311e-03 4.8165964e-03\n",
      " 1.8632922e-03 5.6084180e-03 9.3694114e-05] ] \n",
      "  W :\n",
      " [[-26.356834    -6.966959    22.387772  ]\n",
      " [ -7.6010385   -4.3320827    9.969968  ]\n",
      " [ 24.165955    -0.37501425 -12.916306  ]\n",
      " [ -6.179399    10.997522    -3.8590896 ]] \n",
      "  b :\n",
      " [-0.87674487]\n",
      "0500 \n",
      " cost :\n",
      " [0.0000000e+00 9.9907070e-04 1.1880490e-03 1.2652018e-03 1.3288964e-03\n",
      " 6.1945803e-04 1.5981534e-03 6.6756979e-06] ] \n",
      "  W :\n",
      " [[-35.382256   -8.956934   27.653397 ]\n",
      " [ -8.311239   -4.4731393  13.436132 ]\n",
      " [ 28.145521   -1.031414  -16.843998 ]\n",
      " [ -7.17767    12.683929   -5.707991 ]] \n",
      "  b :\n",
      " [-0.79258054]\n",
      "1000 \n",
      " cost :\n",
      " [0.0000000e+00 4.0177381e-04 4.8208531e-04 5.1151542e-04 5.5262068e-04\n",
      " 2.5900823e-04 6.6865975e-04 1.0728829e-06] ] \n",
      "  W :\n",
      " [[-41.273304  -10.285779   31.158728 ]\n",
      " [ -8.803287   -4.5445237  15.781671 ]\n",
      " [ 31.022394   -1.5811803 -19.504267 ]\n",
      " [ -8.055225   13.906672   -6.9066467]] \n",
      "  b :\n",
      " [-1.1839757]\n",
      "1500 \n",
      " cost :\n",
      " [0.0000000e+00 2.1336187e-04 2.5674384e-04 2.7211779e-04 2.9642956e-04\n",
      " 1.3910756e-04 3.5923225e-04 3.5762778e-07] ] \n",
      "  W :\n",
      " [[-45.4178    -11.199016   33.61356  ]\n",
      " [ -9.150928   -4.5915117  17.418644 ]\n",
      " [ 33.06603    -1.9826877 -21.37793  ]\n",
      " [ -8.694316   14.7699795  -7.7287087]] \n",
      "  b :\n",
      " [-1.0850288]\n",
      "2000 \n",
      " cost :\n",
      " [0.00000000e+00 1.29691296e-04 1.56271155e-04 1.65567981e-04\n",
      " 1.81062511e-04 8.49926073e-05 2.19678579e-04 1.19209275e-07] ] \n",
      "  W :\n",
      " [[-48.68692   -11.915143   35.547897 ]\n",
      " [ -9.426222   -4.6280904  18.707388 ]\n",
      " [ 34.684532   -2.303968  -22.858107 ]\n",
      " [ -9.205384   15.452442   -8.37214  ]] \n",
      "  b :\n",
      " [-1.6485411]\n",
      "2500 \n",
      " cost :\n",
      " [0.00000000e+00 8.52310041e-05 1.02753125e-04 1.08832151e-04\n",
      " 1.19202181e-04 5.60267981e-05 1.44709600e-04 0.00000000e+00] ] \n",
      "  W :\n",
      " [[-51.44817   -12.514914   37.187004 ]\n",
      " [ -9.656061   -4.655291   19.79962  ]\n",
      " [ 36.05956    -2.5741622 -24.107483 ]\n",
      " [ -9.636978   16.033657   -8.910698 ]] \n",
      "  b :\n",
      " [8.246132]\n",
      "3000 \n",
      " cost :\n",
      " [0.0000000e+00 5.8768448e-05 7.0927003e-05 7.5099029e-05 8.2251026e-05\n",
      " 3.8742266e-05 1.0001159e-04 0.0000000e+00] ] \n",
      "  W :\n",
      " [[-53.890278  -13.045951   38.634567 ]\n",
      " [ -9.86328    -4.6828556  20.761305 ]\n",
      " [ 37.27411    -2.817327  -25.216074 ]\n",
      " [-10.023585   16.545034   -9.388834 ]] \n",
      "  b :\n",
      " [9.595008]\n",
      "3500 \n",
      " cost :\n",
      " [0.0000000e+00 4.1960790e-05 5.0543462e-05 5.3523538e-05 5.8768448e-05\n",
      " 2.7656171e-05 7.1403811e-05 0.0000000e+00] ] \n",
      "  W :\n",
      " [[-56.11735   -13.530624   39.95519  ]\n",
      " [-10.052547   -4.708015   21.638882 ]\n",
      " [ 38.383224   -3.0398486 -26.22821  ]\n",
      " [-10.377481   17.011946   -9.824687 ]] \n",
      "  b :\n",
      " [9.965092]\n",
      "4000 \n",
      " cost :\n",
      " [0.0000000e+00 3.0517112e-05 3.6834990e-05 3.9099883e-05 4.2795215e-05\n",
      " 2.0146166e-05 5.2093099e-05 0.0000000e+00] ] \n",
      "  W :\n",
      " [[-58.1935    -13.982636   41.187244 ]\n",
      " [-10.228713   -4.7306814  22.458025 ]\n",
      " [ 39.41892    -3.247572  -27.172577 ]\n",
      " [-10.708075   17.448061  -10.23068  ]] \n",
      "  b :\n",
      " [10.523168]\n",
      "4500 \n",
      " cost :\n",
      " [0.0000000e+00 2.2649509e-05 2.7298554e-05 2.8967435e-05 3.1828371e-05\n",
      " 1.4901049e-05 3.8623064e-05 0.0000000e+00] ] \n",
      "  W :\n",
      " [[-60.162014  -14.411545   42.354576 ]\n",
      " [-10.397434   -4.7537546  23.23297  ]\n",
      " [ 40.400158   -3.4461377 -28.069393 ]\n",
      " [-11.023573   17.860409  -10.616609 ]] \n",
      "  b :\n",
      " [9.375882]\n",
      "5000 \n",
      " cost :\n",
      " [0.00000000e+00 1.69275772e-05 2.05037868e-05 2.16958560e-05\n",
      " 2.38415723e-05 1.12056105e-05 2.89674354e-05 0.00000000e+00] ] \n",
      "  W :\n",
      " [[-62.050808  -14.823589   43.474915 ]\n",
      " [-10.560796   -4.777419   23.975641 ]\n",
      " [ 41.341778   -3.6377501 -28.931263 ]\n",
      " [-11.327568   18.255894  -10.987254 ]] \n",
      "  b :\n",
      " [7.848187]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.05)\n",
    "\n",
    "print('***** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    optimizer.minimize(loss=cost, var_list=[w, b])\n",
    "    if step % 500 == 0:\n",
    "        print('%04d' % step,'\\n', 'cost :\\n', cost().numpy(), ']', '\\n',\n",
    "              ' W :\\n', w.numpy(),'\\n', ' b :\\n', b.numpy())\n",
    "print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def pred():\n",
    "    return tf.argmax(tf.exp(logit(x_train)), axis= 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=float32, numpy=\narray([1.       , 1.0000169, 1.0000205, 1.0000217, 1.0000238, 1.0000112,\n       1.000029 , 1.       ], dtype=float32)>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(cost())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=int64, numpy=array([2, 2, 2, 1, 1, 1, 0, 0], dtype=int64)>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
