{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "((array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n (array([[[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         ...,\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]],\n  \n         [[0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          ...,\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0],\n          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]] \n",
      " [5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "print(x_train,'\\n', y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  1  2  3  4  5  6  7  8  9\n",
      "0      0  0  0  0  0  1  0  0  0  0\n",
      "1      1  0  0  0  0  0  0  0  0  0\n",
      "2      0  0  0  0  1  0  0  0  0  0\n",
      "3      0  1  0  0  0  0  0  0  0  0\n",
      "4      0  0  0  0  0  0  0  0  0  1\n",
      "...   .. .. .. .. .. .. .. .. .. ..\n",
      "59995  0  0  0  0  0  0  0  0  1  0\n",
      "59996  0  0  0  1  0  0  0  0  0  0\n",
      "59997  0  0  0  0  0  1  0  0  0  0\n",
      "59998  0  0  0  0  0  0  1  0  0  0\n",
      "59999  0  0  0  0  0  0  0  0  1  0\n",
      "\n",
      "[60000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 60000 x 28 x 28 --> 60000 x 784 로 차원변환"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "((60000, 784), (10000, 784))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "x_train.shape, x_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)\n",
    "\n",
    "print(x_train.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 신경망"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 512) (512,)\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(np.random.random([784, 512]), dtype=tf.float32, name='weight1')\n",
    "b1 = tf.Variable(np.random.random([512]), dtype=tf.float32, name='bias1')\n",
    "\n",
    "w2 = tf.Variable(np.random.random([512, 256]), dtype=tf.float32, name='weight2')\n",
    "b2 = tf.Variable(np.random.random([256]), dtype=tf.float32, name='bias2')\n",
    "\n",
    "w3 = tf.Variable(np.random.random([256, 128]), dtype=tf.float32, name='weight3')\n",
    "b3 = tf.Variable(np.random.random([128]), dtype=tf.float32, name='bias3')\n",
    "\n",
    "w4 = tf.Variable(np.random.random([128, 10]), dtype=tf.float32, name='weight4')\n",
    "b4 = tf.Variable(np.random.random([10]), dtype=tf.float32, name='bias4')\n",
    "print(w1.shape, b1.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def layer1(x):\n",
    "    return tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "def layer2(x):\n",
    "    layer1_out = layer1(x)\n",
    "    return (tf.matmul(layer1_out, w2) + b2)\n",
    "\n",
    "def layer3(x):\n",
    "    layer2_out = layer2(x)\n",
    "    return (tf.matmul(layer2_out, w3) + b3)\n",
    "\n",
    "def logits(x):\n",
    "    layer3_out = layer3(x)\n",
    "    layer4_out = tf.matmul(layer3_out, w4) + b4\n",
    "    return layer4_out\n",
    "\n",
    "###\n",
    "#\n",
    "# def layer1(x):\n",
    "#     return tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "#\n",
    "# def layer2(x):\n",
    "#     layer1_out = layer1(x)\n",
    "#     return tf.nn.relu(tf.matmul(layer1_out, w2) + b2)\n",
    "#\n",
    "# def layer3(x):\n",
    "#     layer2_out = layer2(x)\n",
    "#     return tf.nn.relu(tf.matmul(layer2_out, w3) + b3)\n",
    "#\n",
    "# def logits(x):\n",
    "#     layer3_out = layer3(x)\n",
    "#     layer4_out = tf.matmul(layer3_out, w4) + b4\n",
    "#     return layer4_out\n",
    "\n",
    "#for 1 layer DNN\n",
    "\n",
    "# def cost_func():\n",
    "    # return -tf.nn.softmax_cross_entropy_with_logits(x_train, labels= y_train)\n",
    "\n",
    "# def logits(x):\n",
    "#     return tf.cast(tf.matmul(x,w1) + b1, dtype= tf.float32)\n",
    "\n",
    "def pred(x):\n",
    "    return tf.argmax(logits(x),  axis=1)\n",
    "\n",
    "def accuracy(pred, real_y):\n",
    "    return pd.DataFrame(pred, real_y).assign(equal = pred == real_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "epoch : 1 cost : 35.52087310542406 \n",
      "\n",
      "epoch : 2 cost : 2.3394726331417366 \n",
      "\n",
      "epoch : 3 cost : 2.339916317890851 \n",
      "\n",
      "epoch : 4 cost : 2.3282972686311108 \n",
      "\n",
      "epoch : 5 cost : 2.323076129978539 \n",
      "\n",
      "epoch : 6 cost : 2.3241335438866906 \n",
      "\n",
      "epoch : 7 cost : 2.32308994908618 \n",
      "\n",
      "epoch : 8 cost : 2.318785098882822 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m         cost \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_mean(cost_i)\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cost\n\u001B[1;32m---> 20\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcost_func_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mw1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw4\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb4\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     avg_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m cost_func_batch()\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;241m/\u001B[39m total_batch\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch :\u001B[39m\u001B[38;5;124m'\u001B[39m,epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcost :\u001B[39m\u001B[38;5;124m'\u001B[39m,avg_cost,\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001B[0m, in \u001B[0;36mOptimizerV2.minimize\u001B[1;34m(self, loss, var_list, grad_loss, name, tape)\u001B[0m\n\u001B[0;32m    545\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mminimize\u001B[39m(\u001B[38;5;28mself\u001B[39m, loss, var_list, grad_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, tape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    546\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001B[39;00m\n\u001B[0;32m    547\u001B[0m \n\u001B[0;32m    548\u001B[0m \u001B[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    574\u001B[0m \n\u001B[0;32m    575\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 576\u001B[0m     grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_gradients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    577\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvar_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtape\u001B[49m\n\u001B[0;32m    578\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_gradients(grads_and_vars, name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf210gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:625\u001B[0m, in \u001B[0;36mOptimizerV2._compute_gradients\u001B[1;34m(self, loss, var_list, grad_loss, tape)\u001B[0m\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(var_list):\n\u001B[0;32m    624\u001B[0m     tape\u001B[38;5;241m.\u001B[39mwatch(var_list)\n\u001B[1;32m--> 625\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(var_list):\n\u001B[0;32m    627\u001B[0m     var_list \u001B[38;5;241m=\u001B[39m var_list()\n",
      "Cell \u001B[1;32mIn[16], line 16\u001B[0m, in \u001B[0;36mcost_func_batch\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcost_func_batch\u001B[39m():\n\u001B[1;32m---> 16\u001B[0m     cost_i \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_cross_entropy_with_logits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_xs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_ys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     cost \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_mean(cost_i)\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cost\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4044\u001B[0m, in \u001B[0;36msoftmax_cross_entropy_with_logits_v2\u001B[1;34m(labels, logits, axis, name)\u001B[0m\n\u001B[0;32m   3985\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnn.softmax_cross_entropy_with_logits\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[0;32m   3986\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[0;32m   3987\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msoftmax_cross_entropy_with_logits_v2\u001B[39m(labels, logits, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   3988\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Computes softmax cross entropy between `logits` and `labels`.\u001B[39;00m\n\u001B[0;32m   3989\u001B[0m \n\u001B[0;32m   3990\u001B[0m \u001B[38;5;124;03m  Measures the probability error in discrete classification tasks in which the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4042\u001B[0m \u001B[38;5;124;03m    not have the last dimension of `labels`.\u001B[39;00m\n\u001B[0;32m   4043\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4044\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msoftmax_cross_entropy_with_logits_v2_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4045\u001B[0m \u001B[43m      \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\deprecation.py:561\u001B[0m, in \u001B[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    553\u001B[0m         _PRINTED_WARNING[(func, arg_name)] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    554\u001B[0m       logging\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m    555\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFrom \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: calling \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m (from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) with \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is deprecated and will \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    556\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbe removed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mInstructions for updating:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    559\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min a future version\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m date \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m date),\n\u001B[0;32m    560\u001B[0m           instructions)\n\u001B[1;32m--> 561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4141\u001B[0m, in \u001B[0;36msoftmax_cross_entropy_with_logits_v2_helper\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   4139\u001B[0m \u001B[38;5;66;03m# Make precise_logits and labels into matrices.\u001B[39;00m\n\u001B[0;32m   4140\u001B[0m precise_logits \u001B[38;5;241m=\u001B[39m _flatten_outer_dims(precise_logits)\n\u001B[1;32m-> 4141\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_flatten_outer_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4143\u001B[0m \u001B[38;5;66;03m# Do the actual op computation.\u001B[39;00m\n\u001B[0;32m   4144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mis_op_determinism_enabled():\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3751\u001B[0m, in \u001B[0;36m_flatten_outer_dims\u001B[1;34m(logits)\u001B[0m\n\u001B[0;32m   3748\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Flattens logits' outer dimensions and keep its last dimension.\"\"\"\u001B[39;00m\n\u001B[0;32m   3749\u001B[0m rank \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mrank(logits)\n\u001B[0;32m   3750\u001B[0m last_dim_size \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mslice(\n\u001B[1;32m-> 3751\u001B[0m     array_ops\u001B[38;5;241m.\u001B[39mshape(logits), [\u001B[43mmath_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubtract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m], [\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m   3752\u001B[0m output \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mreshape(logits, array_ops\u001B[38;5;241m.\u001B[39mconcat([[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], last_dim_size], \u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m   3754\u001B[0m \u001B[38;5;66;03m# Set output shape if known.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\math_ops.py:548\u001B[0m, in \u001B[0;36msubtract\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmath.subtract\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubtract\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    545\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39mregister_binary_elementwise_api\n\u001B[0;32m    546\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[0;32m    547\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubtract\u001B[39m(x, y, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 548\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_math_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:11161\u001B[0m, in \u001B[0;36msub\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m  11159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m  11160\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m> 11161\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  11162\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSub\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m  11163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m  11164\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate= 0.1)\n",
    "training_epoch = 25\n",
    "batch_size = 256\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    print('***** Start Learning!!')\n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(x_train.shape[0]/batch_size)\n",
    "        for k in range(total_batch):\n",
    "            batch_xs = x_train[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "            batch_ys = y_train[0 + k*batch_size: 0 + (k+1)*batch_size]\n",
    "\n",
    "            # 비용함수\n",
    "            def cost_func_batch():\n",
    "                cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(batch_xs), labels= batch_ys)\n",
    "                cost = tf.reduce_mean(cost_i)\n",
    "                return cost\n",
    "\n",
    "            optimizer.minimize(loss=cost_func_batch, var_list=[w1, b1, w2, b2, w3, b3, w4, b4])\n",
    "            avg_cost += cost_func_batch().numpy() / total_batch\n",
    "        print('epoch :',epoch + 1,'cost :',avg_cost,'\\n', )\n",
    "    print('***** Learning Finished!!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(60000,), dtype=int64, numpy=array([9, 9, 9, ..., 9, 9, 9], dtype=int64)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(x_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10000,), dtype=int64, numpy=array([9, 9, 9, ..., 9, 9, 9], dtype=int64)>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.09915"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred(x_train), tf.argmax(y_train, axis=1))['equal'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1009"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred(x_test), y_test)['equal'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 시각화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_one_image(n):\n",
    "    image = x_train[n]\n",
    "    print(tf.argmax(y_train.iloc[1]).numpy())\n",
    "\n",
    "    plt.imshow(image,cmap='Greys')\n",
    "    return lt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_one_image(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(60000, 512), dtype=float32, numpy=\narray([[14267.773 , 13015.039 , 13953.026 , ..., 12630.1045, 12748.008 ,\n        14517.968 ],\n       [14797.572 , 16126.914 , 16220.492 , ..., 14879.62  , 15412.641 ,\n        16220.007 ],\n       [ 9919.087 ,  9480.674 , 10280.637 , ...,  9468.09  ,  9541.298 ,\n        10438.212 ],\n       ...,\n       [11838.955 , 11621.906 , 10220.276 , ..., 10651.524 , 11193.998 ,\n        11069.699 ],\n       [10311.178 , 10173.695 , 10189.388 , ...,  9674.077 , 10124.148 ,\n        10498.485 ],\n       [10935.686 , 11697.106 , 10541.614 , ..., 10177.334 , 10790.027 ,\n        10730.14  ]], dtype=float32)>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu(tf.matmul(x_train, w1) + b1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
